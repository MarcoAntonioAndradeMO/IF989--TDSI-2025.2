Prompt,,"System prompt:
Assume you are an expert professor in Software Engineering conducting a systematic literature review.

Your task is to evaluate studies based on specific criteria:
Inclusion Criteria (IC): Inclusion criteria from primary candidate study
Exclusion Criteria (EC): Exclusion criteria from primary candidate study

For scoring, use only 1 or 0: Assign a score of 1 for strong alignment with all inclusion criteria. Assign a score of 0 if any inclusion criteria are not satisfied or if any exclusion criteria are met.

You’ll score studies based on their title and abstracts.

For the response, use the following format: Response Format: Begin with ‘‘Score: X’’ followed by ‘‘Justification:’’ that explains why the study was considered relevant or not.

User prompt:
Title: Title of a primary candidate study
Abstract: abstract of a primary candidate study",,,,,,,,,,,,
LLM1: CHATGPT,,GPT‑5,,,,,,,,,,,,
LLM2: GEMINI,,2.5 Flash,,,,,,,,,,,,
Base de Dados,Autor(es),Título do artigo,Ano,URL / DOI,Resumo (abstract),Palavras-chave principais,Relevância segundo LLM 1 (Sim/Não),Relevância segundo LLM 2 (Sim/Não),Diferença entre LLM 1 e LLM 2,Justificativa da LLM 1,Justificativa da LLM 2,LLM que apresentou melhor justificativa (1 ou 2),Artigo selecionado para a próxima fase,
Scopus,"Shweta; Mohammed, A.; Mohammadi, M.; Sharma, S.; Sharma, U.; Rana, V.S.; Kumar, M.; Sood, S.; Eghlima, G.","Assessment of advancements and applications of robotics, artificial intelligence, and automated technology in the modern food sector",2025,10.1016/j.afres.2025.101261,"The global food sector is under pressure to enhance production efficiency, safety, and quality due to growing consumer demands, labour shortages, and regulatory requirements. These challenges have driven the adoption of advanced technologies like robotics and AI. The food sector includes many operations, including manufacturing, processing, shipment, distribution, formation, conservation, and food service. The review paper explores the profound influence of robotics in various segments of the food enterprises, highlighting its applications across production, processing, packaging, and service stages. The main objective of this review is to provide a comprehensive overview of how robotics, AI, and automation are transforming food industry operations and addressing key challenges across the value chain. While various studies have explored specific robotics applications in food systems, few offer a holistic, cross-sectoral perspective that links robotics, AI, and automation technologies across different food categories and processing stages. Key findings include improved production efficiency, enhanced food safety, reduced labour dependency, and strengthened quality assurance driven by robotics and AI. Notably, collaborative robots (co-bots) are redefining human-robot interaction by working safely alongside humans to optimize workflow and productivity. This convergence of technologies is driving transformation in major food sectors such as dairy, meat, seafood, beverages, fruits, and vegetables, ensuring quality standards and operational excellence throughout the supply chain. The implications of this technological shift are substantial. Robotics and AI provide effective solutions to persistent industry challenges, including labour shortages and process variability, while laying the groundwork for a more resilient, data-driven, and intelligent food system. Unlike previous works that focus on specific tools or segments, this review distinguishes itself by examining the synergistic integration of robotics, AI, and automation across multiple food sectors. As industry demands continue to evolve, these technologies will remain central to enhancing efficiency, productivity, and competitiveness in the global food landscape. © 2025 Elsevier B.V., All rights reserved.",Artificial intelligence; Automation; Co-bots; Modern industry; Robotics,Não,Não,Igual,"Although the abstract discusses the use of collaborative robots (cobots) and AI in the food sector, which is tangentially related to logistics and industrial contexts, the paper explicitly identifies itself as a review paper — violating Exclusion Criterion EC4 (reviews are excluded).

Moreover, while it covers applications and efficiency impacts, the focus remains broad and descriptive, without mention of case studies, prototypes, or empirical implementations, which conflicts with Inclusion Criterion IC2 (practical data or measurable impacts).

Therefore, despite partial thematic relevance (robots collaborating with humans in production and packaging), it fails the inclusion and exclusion criteria required for scoring a “1.”","The study does not satisfy the inclusion criteria and meets the exclusion criteria as follows:

(IC1) Focus on the Theme: The theme focuses on the food sector, which is not one of the target sectors (logistics, healthcare, or field services). Although it mentions collaborative robots (co-bots), the sector focus is a mismatch.

(IC3) Type of Publication and (EC4) Type of Publication: The abstract explicitly states, ""The review paper explores..."" and ""The main objective of this review is to provide a comprehensive overview..."", indicating it is a Review paper (survey, meta-analysis), which is an Exclusion Criterion (EC4).

(EC2) Excluded Sectors: The exclusive focus on the food sector also falls under the spirit of excluded/non-target sectors, though not explicitly listed like military or domestic robotics.

(EC3) Theoretical/Abstract Focus: As a review, it synthesizes existing literature rather than presenting a practical application, case study, or validated prototype, which aligns with the exclusion criterion against Purely theoretical or simulation-based articles (though for different reasons, the result is the same: it lacks new empirical data).",Ambas,Não,
Scopus,"Shah, R.; Arockia Doss, A.S.A.; Natrayan, N.","Advancements in AI-enhanced collaborative robotics: towards safer, smarter, and human-centric industrial automation",2025,10.1016/j.rineng.2025.105704,"Traditional industrial robots have long been central to manufacturing automation; however, limitations such as inflexible programming, safety concerns in human-robot interaction, and poor adaptability to dynamic production needs have restricted their widespread application. Collaborative robots (cobots) are reshaping this paradigm by enabling safe, efficient, and intelligent human-robot collaboration. This review examines the evolution and integration of collaborative robots (cobots) with Artificial Intelligence (AI), machine learning, and smart sensing technologies to enhance safety, adaptability, and human-centric automation. The paper explores how AI-enhanced cobots optimize production efficiency by reducing cycle times, improving product quality, and facilitating adaptive manufacturing in the automotive, healthcare, and logistics sectors. It highlights critical safety innovations like force-limiting systems, speed and separation monitoring, and ergonomic human-robot interaction. Furthermore, emerging concepts such as digital twins, blockchain for cybersecurity, and Internet of Robotic Things (IoRT) are examined for their potential to advance cobot functionality. Challenges including high initial costs, technical complexity, and cybersecurity threats are critically analyzed. Future trends, including cognitive adaptability, personalized interaction, and the shift toward Industry 5.0′s human-centered approach, are also explored. This study identifies key opportunities and challenges in collaborative robotics and proposes strategic pathways for fostering safer, smarter, and more flexible industrial environments. © 2025 Elsevier B.V., All rights reserved.",Artificial Intelligence in Robotics; Collaborative Robots (Cobots); Human-Centric Automation; Human-Robot Collaboration (HRC); Industry 5.0,Não,Não,Igual,"Although the article focuses on collaborative robots (cobots) and their integration with AI, machine learning, and smart sensing — aligning with IC1 (theme) — the abstract explicitly identifies the study as a review, which violates Exclusion Criterion EC4 (review papers are excluded).

Additionally, while it discusses industrial and logistics contexts and touches on enabling technologies and implementation challenges (which would satisfy IC2 if empirical), there is no mention of practical applications, case studies, or measured impacts — indicating a primarily conceptual and analytical approach rather than empirical validation.

Therefore, despite thematic relevance to collaborative robotics in relevant sectors, the paper fails the inclusion/exclusion criteria due to its review nature and lack of applied evidence.","The study does not satisfy Inclusion Criterion (IC3) and meets Exclusion Criterion (EC4) because the abstract explicitly states, ""This review examines the evolution and integration of collaborative robots..."" and ""This study identifies key opportunities and challenges in collaborative robotics..."", indicating that the publication is a review paper (survey/meta-analysis), which is an Excluded Type of Publication (EC4).

For completeness, while the study aligns with the other criteria:

(IC1) Focus on the Theme: Satisfied, as it focuses on collaborative robots (cobots) in healthcare and logistics sectors.

(IC2) Focus on the Research Questions: Satisfied, as it discusses HRI analysis, enabling technologies (AI, smart sensing), measured impacts (production efficiency, cycle times, product quality), and implementation challenges (high initial costs, cybersecurity).

(IC4) Language: Satisfied (English).

(IC5) Time Period: Satisfied (The paper would have been published between 2020–2025).

(EC1) Single-Task Robots: Not met (Focus is on cobots, which are multi-task/collaborative).

(EC2) Excluded Sectors: Not met (Focus includes logistics and healthcare).

(EC3) Theoretical/Abstract Focus: Not met (It discusses practical applications and impacts, though in a review context).

Since EC4 is met, the final score is 0.",Ambas,Não,
Scopus,"Duorinaah, F.X.; Rajendran, M.; Kim, T.W.; Kim, J.I.; Lee, S.; Lee, S.; Kim, M.-K.",Human and Multi-Robot Collaboration in Indoor Environments: A Review of Methods and Application Potential for Indoor Construction Sites,2025,10.3390/buildings15152794,"The integration of robotic agents into complex indoor construction environments is increasing, particularly through human–robot collaboration (HRC) and multi-robot collaboration (MRC). These collaborative frameworks hold great potential to enhance productivity and safety. However, indoor construction environments present unique challenges, such as dynamic layouts, constrained spaces, and variable lighting conditions, which complicate the safe and effective deployment of collaborative robot teams. Existing studies have primarily addressed various HRC and MRC challenges in manufacturing, logistics, and outdoor construction, with limited attention given to indoor construction settings. To this end, this review presents a comprehensive analysis of human–robot and multi-robot collaboration methods within various indoor domains and critically evaluates the potential of adopting these methods for indoor construction. This review presents three key contributions: (1) it provides a structured evaluation of current human–robot interaction techniques and safety-enhancing methods; (2) it presents a summary of state-of-the-art multi-robot collaboration frameworks, including task allocation, mapping, and coordination; and (3) it identifies major limitations in current systems and provides research directions for enabling scalable, robust, and context-aware collaboration in indoor construction. By bridging the gap between current robotic collaboration methods and the needs of indoor construction, this review lays the foundation for the development of adaptive and optimized collaborative robot deployment frameworks for indoor built environments. © 2025 Elsevier B.V., All rights reserved.",collision prevention; human–robot collaboration; human–robot interaction; indoor construction; multi-robot collaboration; reinforcement learning,Não,Não,Igual,"Although the article focuses on human–robot collaboration (HRC) and multi-robot collaboration (MRC) — which aligns well with IC1 (theme) concerning collaborative and multifunctional robots — it explicitly identifies itself as a review, thereby violating Exclusion Criterion EC4, which excludes review or survey papers.

Additionally, while the paper addresses potential applications and challenges in indoor construction environments, it does not provide empirical data, case studies, or validated prototypes, thus failing IC2 (practical applications and measured impacts).

Therefore, despite thematic relevance to collaborative robotics in work environments, the publication’s review nature and lack of applied or empirical evidence lead to a score of 0.","The study does not satisfy the Inclusion Criterion (IC3) Type of Publication and meets the Exclusion Criterion (EC4) Type of Publication.

IC3 (Type of Publication) Violation: The title and abstract explicitly state this is a ""Review"" and a ""comprehensive analysis"". The goal is to present a structured evaluation, summary, and identify limitations/research directions, which are characteristics of a review paper. The inclusion criteria specifically require peer-reviewed conference papers or journal articles that are not reviews.

EC4 (Type of Publication) Met: The study is a Review paper (surveys, meta-analyses), which is an explicitly excluded publication type.

Additional Checks (for completeness, although the above is sufficient):

IC1 (Focus on the Theme) & IC2 (Focus on the Research Questions): The article focuses on multi-robot and human-robot collaboration (HRC/MRC), which aligns with the theme of multifunctional/collaborative robots. It addresses methods and potential, which relates to enabling technologies and practical applications. However, the primary context is indoor construction sites, which is not explicitly listed in the target sectors (logistics, healthcare, field services). While field services (maintenance, inspection) might sometimes overlap, construction is typically considered a separate domain. This is a weak alignment.

EC2 (Excluded Sectors): The exclusive focus on construction is not one of the listed excluded sectors (military, space, domestic, entertainment), but it is also not one of the listed included sectors (logistics, healthcare, field services). However, the definitive exclusion is based on the publication type.

EC3 (Theoretical/Abstract Focus) Violation: While it discusses methods and potential, as a review, it is abstract and theoretical in nature without a primary case study or validated prototype from the authors themselves, failing IC2 to ""provide data on practical applications, measured impacts... or validated prototype.""

The definitive and non-negotiable reason for exclusion is that the article is a Review Paper (Survey), which meets EC4 and violates IC3.",Ambas,Não,
Scopus,"Koreis, J.; Klumpp, M.",Walk or Ride? An Empirical Study on Cobot-Assisted Traveling in Warehouse 5.0 Picker-to-Parts Order Picking Systems,2025,10.1016/j.ifacol.2025.09.369,"Order picking is a critical and labor-intensive warehouse operation, driving significant time and cost demands. Recent advancements have introduced ride-on collaborative robots (cobots) to assist human pickers, improving efficiency. These cobots autonomously follow pickers or serve as a platform for riding during longer distances. In traditional picker-to-parts systems, pickers walk or use manual industrial trucks, stepping on and of frequently. Cobots offer a middle ground, autonomously navigating to the next location while allowing pickers to choose between walking and riding. A key question arises: when should pickers transition between walking and riding to optimize performance time? To answer this, we analyzed real-world warehouse data using a mixed-effects model. Our study evaluated the impact of cobot-assisted traveling on task performance time, considering travel distances and operational dynamics. Results reveal a critical threshold of 6.4 meters, beyond which riding becomes more efficient than walking. These findings offer actionable insights for optimizing human-robot collaboration in order picking systems. Training programs can emphasize this threshold to maximize productivity, enabling dynamic adjustments during operations. The research is especially valuable for warehouses employing picker-to-parts systems with cobots, providing a data-driven approach to enhance efficiency and reduce operational costs. © 2025 Elsevier B.V., All rights reserved.",Cobots; Empirical Study; Human-Robot Collaboration; Order Picking; Retailing,Sim,Sim,Igual,"This study strongly satisfies all inclusion criteria. It focuses on collaborative robots (cobots) assisting human workers in warehouse logistics — fully aligning with IC1 (theme). The context (picker-to-parts systems in Warehouse 5.0) represents a real-world work environment involving human–robot collaboration.

It also meets IC2 (research question focus) by presenting empirical data and measured impacts on task performance time and operational efficiency, derived from real-world warehouse data and statistical analysis.

The publication appears to be a peer-reviewed empirical study (not a review or simulation-only paper), satisfying IC3–IC5 (publication type, English language, and date range 2020–2025).

No exclusion criteria are met — the study is application-oriented, non-military, and provides empirical evidence rather than theoretical discussion.

Hence, it receives a score of 1 for strong relevance and alignment with all inclusion criteria.","The study aligns strongly with all Inclusion Criteria (IC) and meets none of the Exclusion Criteria (EC).

IC1 (Focus on the Theme): The study explicitly focuses on collaborative robots (cobots) in a logistics (warehouse) context (""Warehouse 5.0 Picker-to-Parts Order Picking Systems""), fulfilling the requirement for collaborative/multifunctional robots in a target sector.

IC2 (Focus on the Research Questions): The abstract discusses ""real-world warehouse data,"" ""measured impacts"" on ""task performance time"" and ""efficiency,"" and provides ""actionable insights for optimizing human-robot collaboration (HRI analysis),"" directly addressing several required research foci.

IC3 (Type of Publication): Assumed to be a peer-reviewed conference paper or journal article based on the structure and academic rigor of the title and abstract, which is typical for systematic literature reviews.

IC4 (Language): The text is in English.

IC5 (Time Period): Assumed to be published between 2020–2025 (this is a standard assumption when screening a title and abstract within a specified time frame for an SLR).

EC1 (Single-Task Robots): The focus is on cobots that assist human pickers, which are not fixed, single-task industrial robots.

EC2 (Excluded Sectors): The context is warehousing/logistics, a target sector.

EC3 (Theoretical/Abstract Focus): The study uses a ""mixed-effects model"" to analyze ""real-world warehouse data"" and provides a validated ""critical threshold of 6.4 meters,"" indicating a practical, empirical application and not a purely theoretical or simulation-based focus.

EC4 (Type of Publication): Assumed to be a valid publication type (conference paper or journal article).

EC5 (Access): Assumed to be accessible.",LLM 2,Sim,
Scopus,"Nambiar, S.; Paul, R.C.; Ikechukwu, O.C.; Jonsson, M.; Tarkian, M.",Digital Twin-Enabled Adaptive Robotics: Leveraging Large Language Models in Isaac Sim for Unstructured Environments,2025,10.3390/machines13070620,"As industrial automation evolves towards human-centric, adaptable solutions, collaborative robots must overcome challenges in unstructured, dynamic environments. This paper extends our previous work on developing a digital shadow for industrial robots by introducing a comprehensive framework that bridges the gap between physical systems and their virtual counterparts. The proposed framework advances toward a fully functional digital twin by integrating real-time perception and intuitive human–robot interaction capabilities. The framework is applied to a hospital test lab scenario, where a YuMi robot automates the sorting of microscope slides. The system incorporates a RealSense D435i depth camera for environment perception, Isaac Sim for virtual environment synchronization, and a locally hosted large language model (Mistral 7B) for interpreting user voice commands. These components work together to achieve bi-directional synchronization between the physical and digital environments. The framework was evaluated through 20 test runs under varying conditions. A validation study measured the performance of the perception module, simulation, and language interface, with a 60% overall success rate. Additionally, synchronization accuracy between the simulated and physical robot joint movements reached 98.11%, demonstrating strong alignment between the digital and physical systems. By combining local LLM processing, real-time vision, and robot simulation, the approach enables untrained users to interact with collaborative robots in dynamic settings. The results highlight its potential for improving flexibility and usability in industrial automation. © 2025 Elsevier B.V., All rights reserved.",adaptive digital twin; adaptive robotics; human–robot collaboration (HRC),Sim,Sim,Igual,"This study clearly fulfills all inclusion criteria. It discusses the design, implementation, and evaluation of a collaborative robot (cobot) system — specifically a YuMi robot — operating in a hospital test lab, which aligns directly with IC1 (theme) and the healthcare context. The system allows human–robot interaction through voice commands interpreted by a large language model (LLM), confirming the focus on collaboration and intuitive interaction.

The paper presents empirical validation through 20 test runs, reporting quantitative performance results (e.g., 60% success rate, 98.11% synchronization accuracy), thus meeting IC2 (practical applications and measured impacts).

It is a peer-reviewed research article (not a review or theoretical paper), written in English, and published within the 2020–2025 timeframe, satisfying IC3–IC5.

No exclusion criteria are triggered — it is not single-task, not theoretical-only, and pertains to a healthcare environment (not military, domestic, or entertainment).

Therefore, the study strongly aligns with all inclusion requirements and receives a score of 1.","The study aligns strongly with all inclusion criteria and does not meet any exclusion criteria.

✅ IC1 (Focus on the Theme): The study focuses on the application and design of a robot in a work environment.

Robot Type: It uses a YuMi robot, which is a well-known type of collaborative robot (cobot) that is explicitly designed to interact with humans (HRI is a core component).

Context: The application is in a hospital test lab scenario (healthcare context), where the robot automates the sorting of microscope slides.

✅ IC2 (Focus on the Research Questions): The abstract provides data on practical applications and measured impacts/data.

Practical Application: The digital twin framework is applied to the slide-sorting task.

Data/Impact: It reports the system's performance (60% overall success rate) and the synchronization accuracy (98.11%), which are quantitative measurements of the system's effectiveness. It also involves HRI analysis by evaluating the language interface for use by untrained users.

✅ IC3 (Type of Publication): The title and abstract format strongly suggest a peer-reviewed conference paper or journal article.

✅ IC4 (Language): The text is in English.

✅ IC5 (Time Period): The current year is 2025, and the technology (LLMs, Digital Twins) and context suggest a publication within the 2020–2025 timeframe.

Exclusion Criteria Assessment:

❌ EC1 (Single-Task Robots): The YuMi is a collaborative robot (cobot) with human interaction, not a fixed, single-task industrial robot. Not excluded.

❌ EC2 (Excluded Sectors): The context is a hospital test lab (healthcare). Not excluded.

❌ EC3 (Theoretical/Abstract Focus): The study describes an application (slide sorting), a validated prototype (YuMi, Isaac Sim, LLM), and reports test results (60% success rate, 98.11% accuracy). Not excluded.

❌ EC4 (Type of Publication): It appears to be an original research article, not a review, thesis, or abstract-only publication. Not excluded.

❌ EC5 (Access): This criterion cannot be evaluated from the abstract alone but is assumed to be obtainable for the purpose of the initial scoring. Not excluded.",Ambas,Sim,
Scopus,"Urrea, C.; Kern, J.",Recent Advances and Challenges in Industrial Robotics: A Systematic Review of Technological Trends and Emerging Applications,2025,10.3390/pr13030832,"Industrial robotics has shifted from rigid, task-specific tools to adaptive, intelligent systems powered by artificial intelligence (AI), machine learning (ML), and sensor integration, revolutionizing efficiency and human–robot collaboration across manufacturing, healthcare, logistics, and agriculture. Collaborative robots (cobots) slash assembly times by 30% and boost quality by 15%, while reinforcement learning enhances autonomy, cutting errors by 30% and energy use by 20%. Yet, this review transcends descriptive summaries, critically synthesizing these trends to expose unresolved tensions in scalability, cost, and societal impact. High implementation costs and legacy system incompatibilities hinder adoption, particularly for SMEs, while interoperability gaps—despite frameworks, like OPC UA—stifle multi-vendor ecosystems. Ethical challenges, including workforce displacement and cybersecurity risks, further complicate progress, underscoring a fragmented field where innovation outpaces practical integration. Drawing on a systematic review of high-impact literature, this study uniquely bridges technological advancements with interdisciplinary applications, revealing disparities in economic feasibility and equitable access. It critiques the literature’s isolation of trends—cobots’ safety, ML’s autonomy, and perception’s precision—proposing the following cohesive research directions: cost-effective modularity, standardized protocols, and ethical frameworks. By prioritizing scalability, interoperability, and sustainability, this paper charts a path for robotics to evolve inclusively, offering actionable insights for researchers, practitioners, and policymakers navigating this dynamic landscape. © 2025 Elsevier B.V., All rights reserved.",automation; collaborative robots; ethical challenges; industrial robotics; interdisciplinary collaboration; machine learning; sensor fusion; sustainability,Não,Não,Igual,"While the article discusses collaborative robots (cobots) and AI-driven industrial robotics across several relevant sectors (including logistics and healthcare), it explicitly identifies itself as a systematic review — violating Exclusion Criterion EC4 (review papers are excluded).

Furthermore, despite offering quantitative figures and a critical synthesis of trends, the abstract does not describe practical experiments, case studies, or prototype evaluations, meaning it lacks empirical application data required by IC2 (practical applications and measured impacts).

Therefore, although the topic aligns with the theme (IC1) and time period (IC5), the paper’s review nature and absence of original empirical validation result in a score of 0.","The study does not satisfy Inclusion Criterion (IC3) and meets Exclusion Criterion (EC4).

Evaluation against Inclusion Criteria (IC):

(IC1) Focus on the Theme: Satisfied. The title and abstract discuss ""Collaborative robots (cobots)"" and mention the context of ""logistics,"" and ""healthcare,"" which are included sectors.

(IC2) Focus on the Research Questions: Satisfied. The abstract mentions ""measured impacts,"" ""human–robot collaboration,"" and ""implementation challenges.""

(IC3) Type of Publication: Not Satisfied. The abstract explicitly states, ""Yet, this review transcends descriptive summaries, critically synthesizing these trends..."" and ""Drawing on a systematic review of high-impact literature, this study uniquely bridges..."" This indicates the publication type is a Review paper (Systematic Review), which is excluded by IC3 (must be peer-reviewed conference papers or journal articles excluding reviews).

(IC4) Language: Assumed Satisfied. The text is in English.

(IC5) Time Period: Cannot be determined. The publication date is not provided, but the title's focus on ""Recent Advances..."" suggests it might fall within the 2020–2025 window. However, the failure of IC3 is sufficient for exclusion.

Evaluation against Exclusion Criteria (EC):

(EC4) Type of Publication: Met. The article is a Systematic Review, which is listed under this exclusion criterion.

Since the study is explicitly a Systematic Review, it fails IC3 and meets EC4, leading to an exclusion score of 0.The user has presented a systematic literature review task and a specific study to evaluate. I need to check the provided Title and Abstract against the Inclusion and Exclusion Criteria, and then assign a score (1 or 0) and provide a justification.

The user prompt contains an error where the title and abstract for the second study are repeated within the abstract section of the first study's evaluation. I will assume the user intends to evaluate the second title and abstract provided in the prompt, which are:

Title: Recent Advances and Challenges in Industrial Robotics: A Systematic Review of Technological Trends and Emerging Applications Abstract: Industrial robotics has shifted from rigid, task-specific tools to adaptive, intelligent systems powered by artificial intelligence (AI), machine learning (ML), and sensor integration, revolutionizing efficiency and human–robot collaboration across manufacturing, healthcare, logistics, and agriculture. Collaborative robots (cobots) slash assembly times by 30% and boost quality by 15%, while reinforcement learning enhances autonomy, cutting errors by 30% and energy use by 20%. Yet, this review transcends descriptive summaries, critically synthesizing these trends to expose unresolved tensions in scalability, cost, and societal impact. High implementation costs and legacy system incompatibilities hinder adoption, particularly for SMEs, while interoperability gaps—despite frameworks, like OPC UA—stifle multi-vendor ecosystems. Ethical challenges, including workforce displacement and cybersecurity risks, further complicate progress, underscoring a fragmented field where innovation outpaces practical integration. Drawing on a systematic review of high-impact literature, this study uniquely bridges technological advancements with interdisciplinary applications, revealing disparities in economic feasibility and equitable access. It critiques the literature’s isolation of trends—cobots’ safety, ML’s autonomy, and perception’s precision—proposing the following cohesive research directions: cost-effective modularity, standardized protocols, and ethical frameworks. By prioritizing scalability, interoperability, and sustainability, this paper charts a path for robotics to evolve inclusively, offering actionable insights for researchers, practitioners, and policymakers navigating this dynamic landscape.

I do not need to perform a search, as all the information for evaluation is contained within the prompt (the criteria and the study's title/abstract).

Evaluation:

IC1 (Focus on the Theme): Satisfied. The abstract discusses ""Collaborative robots (cobots)"" and explicitly mentions the contexts of ""healthcare,"" and ""logistics.""

IC2 (Focus on the Research Questions): Satisfied. The abstract mentions providing data on ""efficiency,"" ""human–robot collaboration,"" and ""implementation challenges"" (e.g., scalability, cost, legacy system incompatibilities).

IC3 (Type of Publication): Not Satisfied. The title explicitly states ""A Systematic Review"" and the abstract confirms this: ""Yet, this review transcends descriptive summaries..."" and ""Drawing on a systematic review of high-impact literature..."" The criteria explicitly exclude ""Review papers (surveys, meta-analyses).""

IC4 (Language): Assumed Satisfied. The text is in English.

IC5 (Time Period): Cannot be determined. The publication date is not provided, but the failure of IC3 is sufficient.

Exclusion Criteria (EC):

EC4 (Type of Publication): Met. The study is identified as a ""Systematic Review,"" which is an excluded publication type.

Since IC3 is not satisfied and EC4 is met, the score must be 0.

I will now generate the response in the required format.Score: 0 Justification: The study does not satisfy Inclusion Criterion (IC3) and meets Exclusion Criterion (EC4).

Failure of IC3 and Meeting of EC4: The title is ""Recent Advances and Challenges in Industrial Robotics: A Systematic Review...,"" and the abstract explicitly states, ""this review transcends descriptive summaries..."" and ""Drawing on a systematic review of high-impact literature..."" A Review paper (Systematic Review) is an Excluded Publication Type (EC4) and is not one of the required types (Peer-reviewed conference papers or journal articles) in IC3.

Alignment with Other Criteria: The study aligns well with IC1 (focuses on collaborative robots/cobots and mentions logistics and healthcare) and IC2 (discusses efficiency/impact and implementation challenges). However, the failure to meet the publication type criterion (IC3/EC4) is sufficient for exclusion.",Ambas,Não,
Scopus,"Crivelli, D.; Balconi, M.","Industrial Collaborative Robotics, Humanoid Cobots, and Social Embodiment: A Critical Look on Human–Robot Interaction",2025,10.1142/S0219843624300010,"Collaborative robotics combines human and robot capabilities in shared workspaces, integrating robotics, human-computer interaction, ergonomics, and psychology. In industrial settings, human–robot collaboration typically involves physical interaction with collaborative robots (cobots), designed to assist in tasks such as manufacturing and logistics. However, we discuss that cognitive and social-a®ective layers of interaction are equally crucial for enhancing collaboration. By adopting the 4E-cognition framework, we argue that the concept of social embodiment, widely used in virtual agents and service robotics, could contribute to the design and implementation of industrial cobots. While socially relevant functions are often secondary to operational e±ciency, integrating them into cobot design could enhance interaction quality, trust, and overall task performance. Focusing on cobots' social presence and their ability to engage in proactive interactions can improve their acceptance and facilitate a sense of shared intentionality and agency in human operators. Finally, we discuss the ethical and practical challenges of developing socially embodied humanoid cobots, addressing the balance between cobot autonomy and human control, adaptive learning in long-term interaction and personalization, and the implications of building trust and transparency in human–robot collaboration. A more holistic design approach could yield both operational bene¯ts and improved human well-being in collaborative environments. © 2025 Elsevier B.V., All rights reserved.",Collaborative robotics; embodiment; human–robot collaboration; inter-agency; joint-actions; social interaction,Não,Não,Igual,"Although the article discusses collaborative robots (cobots) and focuses on human–robot interaction (HRI) within industrial and logistics contexts, it does not present empirical data, case studies, or validated applications. Instead, it takes a theoretical and conceptual approach, using frameworks like 4E-cognition to discuss social embodiment and design considerations.

This violates IC2 (Focus on Research Questions), as there is no evidence of measured impacts, practical implementation, or application data. It also meets Exclusion Criterion EC3, since it is a theoretical paper without applied validation.

While the topic aligns with IC1 (theme) and the time frame (IC5), the lack of empirical results and its conceptual focus mean the study does not meet the inclusion standards for application-oriented research.

Therefore, the article receives a score of 0.","The study focuses on Collaborative Robots (Cobots) in industrial settings and logistics, discussing Human-Robot Interaction (HRI), which aligns with IC1 and IC2.

However, the abstract's discussion of a ""critical look,"" adoption of a ""4E-cognition framework,"" and argument for ""social embodiment"" strongly suggests a theoretical or conceptual focus rather than providing data on practical applications, measured impacts (ROI, efficiency), or a validated prototype as required by IC2. The abstract discusses what could contribute and ethical and practical challenges but doesn't mention an empirical study, case study, or measured application data.

Furthermore, the title's nature (""A Critical Look"") and the content's heavy emphasis on theoretical frameworks and design discussions indicate the article is likely a review paper, survey, or conceptual/theoretical piece (discussing the application of the social embodiment concept), which would meet the Exclusion Criterion (EC4) for Review papers or EC3 for Purely theoretical/Abstract Focus without application/case study/validated prototype. Without evidence of an empirical study or case study in the abstract, it is excluded.

The criteria IC3, IC4, and IC5 cannot be definitively verified from the title and abstract alone but are assumed to be satisfied unless contradicted by the abstract's content. The failure to meet IC2 (lack of data/application/measured impact) and the strong indication of meeting EC3/EC4 are sufficient for exclusion.",Ambas,Não,
Scopus,"Shen, N.; You, H.; Li, J.; Song, P.",Real-time trajectory planning for collaborative robots using incremental multi-objective optimization,2025,10.1007/s11370-024-00555-0,"Human–robot collaboration plays a crucial role in industries such as manufacturing, healthcare, and service. It enhances operational efficiency, ensures safety, and optimizes the interaction experience between humans and robots. In close-range human–robot collaboration, trajectory planning for collaborative robots needs to consider the safety, efficiency, and comfort of the trajectory, and be able to respond quickly to changes in the environment. This paper proposes an incremental multi-objective trajectory optimization algorithm. The algorithm integrates real-time human motion data into the optimization problem, ensuring real-time responsiveness to environmental changes during collaboration. Experimental results show that, compared to existing algorithms, our algorithm demonstrates superior overall performance in terms of safety, efficiency, and comfort. © 2025 Elsevier B.V., All rights reserved.",Human–robot collaboration; Multi-objective trajectory optimization; Trajectory planning,Não,Não,Igual,"While the study addresses human–robot interaction (HRI) and employs machine learning for gesture recognition relevant to collaborative robots (cobots), it does not meet the inclusion criteria (IC1 and IC2) for application within the specified work environment contexts — logistics, healthcare, or field services. The abstract suggests the research was conducted via simulation in RoboDK, with no mention of a real-world application, case study, or validated prototype, which violates IC2 and falls under Exclusion Criterion EC3 (Theoretical/Simulation-based focus).

Moreover, although the paper discusses potential applications in assistive robotics and rehabilitation, these are prospective statements rather than validated implementations. Thus, it lacks empirical data on measured impacts (ROI, efficiency) or implementation challenges.

Therefore, despite technical relevance to HRI, the study does not demonstrate applied, contextualized use in the target sectors and receives a score of 0.","The study does not fully align with the inclusion criteria, specifically IC1 and IC2, and meets the exclusion criterion EC3, based solely on the provided abstract:IC1 (Focus on the Theme): The study focuses on cobots and HRI, which is good. However, the application context is mentioned as assistive robotics, rehabilitation, and occupational ergonomics. While ""occupational ergonomics"" might suggest a work environment, the primary focus appears to be on gesture recognition (an enabling technology) rather than the application, implementation, or evaluation of a robot in the specific target sectors (logistics, healthcare, or field services). The core contribution is HRI improvement via gesture recognition, which is too general.IC2 (Focus on the Research Questions): It discusses HRI analysis and enabling technologies (machine learning for gesture recognition), which aligns, but it does not provide data on practical applications or measured impacts (ROI, efficiency) in a real-world scenario.EC3 (Theoretical/Abstract Focus): The implementation of the cobot is via simulation in RoboDK. The study focuses on a structured experimental protocol for data acquisition and model training for gesture recognition. This indicates a simulation-based or purely experimental/prototyping focus on a component (HRI technology) without a validated prototype or case study in the target application sectors. The lack of a real-world application/case study in logistics, healthcare, or field services is a significant drawback.Since the application is simulation-based and the context is too broad, it violates EC3 and does not fully satisfy IC1 and IC2. Therefore, the score is $\mathbf{0}$.Would you like me to evaluate another study using the same criteria?Score: 0Justification:The study does not fully align with the inclusion criteria, specifically IC1 and IC2, and meets the exclusion criterion EC3, based solely on the provided abstract:IC1 (Focus on the Theme): The study focuses on cobots and HRI, which is good. However, the application context is mentioned as assistive robotics, rehabilitation, and occupational ergonomics. While ""occupational ergonomics"" might suggest a work environment, the primary focus appears to be on gesture recognition (an enabling technology) rather than the application, implementation, or evaluation of a robot in the specific target sectors (logistics, healthcare, or field services). The core contribution is HRI improvement via gesture recognition, which is too general.IC2 (Focus on the Research Questions): It discusses HRI analysis and enabling technologies (machine learning for gesture recognition), which aligns, but it does not provide data on practical applications or measured impacts (ROI, efficiency) in a real-world scenario.EC3 (Theoretical/Abstract Focus): The implementation of the cobot is via simulation in RoboDK. The study focuses on a structured experimental protocol for data acquisition and model training for gesture recognition. This indicates a simulation-based or purely experimental/prototyping focus on a component (HRI technology) without a validated prototype or case study in the target application sectors. The lack of a real-world application/case study in logistics, healthcare, or field services is a significant drawback.Since the application is simulation-based and the context is too broad, it violates EC3 and does not fully satisfy IC1 and IC2. Therefore, the score is $\mathbf{0}$.",LLM 2,Não,
Scopus,"Lefranc, G.; Gatica, G.; Vásquez, E.; Peña, M.",Advanced Algorithm Combinations for Safe Human-Robot Collaboration: A Review and Research Proposal,2025,10.1016/j.procs.2025.08.018,"This paper presents a proposal for integrating Graph Convolutional Neural Network (Graph-CNN), Multimodal Transformer, Soft Actor-Critic with Reward Constrained Policy Optimisation (SAC-RCPO), and TactileGAN algorithms, which are used in human-robot collaboration. This integration addresses challenges such as adaptability, safety, intention recognition, and precise manipulation in dynamic environments. The central hypothesis is that the combination of these algorithms could lead to improvements in manipulation accuracy, collision avoidance, and training efficiency. The methodology evaluates this combination in simulated and controlled laboratory environments that replicate industrial situations. This work considers the human dimension of collaboration, emphasising the importance of interaction, user trust, and ergonomic integration. It also recognises the ethical implications related to safety, transparency, and the responsible implementation of Artificial Intelligence (AI) systems in shared workspaces. The proposed framework has potential applications in the manufacturing, healthcare, and service sectors, aiming to drive the practical adoption of safe and efficient collaborative robots. © 2025 Elsevier B.V., All rights reserved.",collaborative robotics; graph-CNN; human-robot interaction; multimodal transformers; reinforcement learning,Não,Não,Igual,"This study meets all inclusion criteria and does not violate any exclusion criteria.

(IC1 – Focus on the Theme): The paper explicitly addresses collaborative robots (cobots) interacting with humans in work environments, specifically manufacturing and logistics, which are within the target contexts. It focuses on the design and evaluation of an augmented reality (AR) platform (HumanTIX) to enhance human–robot collaboration (HRC) and safety, directly aligning with the inclusion theme.

(IC2 – Focus on the Research Questions): The abstract describes a practical application using AR tools such as HoloLens 2, evaluates their impact on safety and performance, and discusses implementation challenges and HRI improvements—fully satisfying the requirement for applied, data-driven research.

(IC3–IC5): The work is presented as a peer-reviewed article (typical for Industry 5.0/HRC research), in English, and clearly fits the 2020–2025 timeframe.

No exclusion criteria apply—this is not theoretical or simulation-only, involves human interaction, and targets industrial/logistics environments rather than excluded sectors.

Therefore, the study demonstrates a strong practical and conceptual alignment with the systematic review’s scope and earns a score of 1.","The study aligns with several inclusion criteria but fails to satisfy IC1 (Focus on the Theme) regarding the context and meets EC2 (Excluded Sectors) in its exclusive focus on manufacturing.

IC1 (Focus on the Theme): The study focuses on collaborative robots (cobots) and Human-Robot Collaboration (HRC), which is aligned. However, the context is primarily manufacturing, as stated explicitly in the abstract (""manufacturing and logistics,"" but the core application and examples are repeatedly tied to ""manufacturing,"" ""Industry 5.0,"" and production processes). While logistics is mentioned, the thrust of the paper, including the development of an AR platform, is framed around the manufacturing environment. The required contexts in the criteria are logistics, healthcare, or field services. Since the main sector is manufacturing (not listed), this criterion is not fully met.

IC2 (Focus on the Research Questions): The study provides data/evaluation on practical applications and focuses on HRI analysis (safety, AR-facilitated interaction, performance, concentration monitoring), which is aligned.

IC3/IC4/IC5 (Type, Language, Time): Assuming the article is a peer-reviewed paper in English published between 2020-2025 (as is typical for an SLR submission), these are met.

EC2 (Excluded Sectors): The exclusive focus on manufacturing (a sector not listed in the IC1 target sectors) constitutes an exclusion criterion being met.

Since the primary context is manufacturing, which is neither logistics, healthcare, nor field services, the paper does not meet IC1, and its exclusive focus meets EC2. Therefore, the score must be 0.",Ambas,Não,
Scopus,"Concha-Pérez, E.; Valle-Gutierrez, C.; Leal-Rojas, R.; Gonzalez-Hernandez, H.G.; Reyes-Avendaño, J.A.",Towards Intuitive Human-Robot Interaction: A Machine Learning Approach to Gesture Recognition,2025,10.1109/MHTC65808.2025.11086443,"This work presents a human gesture recognition system using surface electromyography signals (sEMG) in order to improve human-robot interaction (HRI). A cobot implementation via simulation in RoboDK is also proposed. A structured experimental protocol is proposed that optimizes the acquisition of sEMG and EEG signals and minimizes noise to obtain high-fidelity data before preprocessing. Three hand and arm gestures were defined to establish interaction with the robot, such as Ask, Take, and Neutral. Three machine learning models were trained and tested with raw sEMG data and preprocessed sEMG data, surpassing 96% recognition accuracy using the Bagged Trees model with preprocessed sEMG data. This approach offers promising applications in assistive robotics, rehabilitation, and occupational ergonomics. In addition, the study lays the foundation for future developments that integrate EEG signals, with the aim of improving the accuracy of the system and allowing recognition of movement intentions. © 2025 Elsevier B.V., All rights reserved.",Bagged trees; EEG; EMG; Experimental protocol; Gesture recognition; RoboDK,Não,Não,Igual,"While the study discusses collaborative robots (cobots) in human–robot collaboration (HRC) contexts relevant to manufacturing, healthcare, and service sectors, it primarily focuses on a trajectory planning algorithm tested through experiments, likely in a controlled or simulated environment. The abstract does not indicate a real-world application in operational work environments, nor does it provide data on practical implementation, ROI, or workflow impacts, which violates IC2 (Focus on Research Questions).

Furthermore, the emphasis on algorithmic optimization without explicit applied case studies or validated industrial deployment aligns with Exclusion Criterion EC3 (purely theoretical or simulation-based focus).

Although the topic is technically relevant and the paper is likely peer-reviewed and recent, the lack of demonstrated applied use in real work environments results in a score of 0.","The study aligns with many inclusion criteria:

(IC1) Focus on the Theme: It discusses collaborative robots (cobots) that interact with humans (""Human–robot collaboration"") and mentions relevant work environments like healthcare and service.

(IC2) Focus on the Research Questions: It provides data on practical applications and focuses on measurable impacts like efficiency and safety through trajectory planning. It discusses HRI analysis (""interaction experience,"" ""comfort"").

(IC4) Language: The language is English.

(IC5) Time Period: Assumed to be met as it is not explicitly contradicted (this is typically assumed for a current SLP task unless a publication date is provided).

However, a crucial Exclusion Criterion (EC3) is potentially met, leading to a score of 0:

(EC3) Theoretical/Abstract Focus: While ""Experimental results"" are mentioned, the abstract focuses entirely on algorithm development and optimization (""incremental multi-objective trajectory optimization algorithm,"" ""trajectory planning""). It is unclear if the experiments constitute a validated prototype, case study, or application in one of the target sectors (logistics, healthcare, or field services) or if it is a purely algorithmic/simulation test. Without a clearer indication in the abstract or title that the application or case study in a target sector is the main focus, it risks being too abstract/theoretical for a systematic review focused on application, implementation, design, or evaluation of the robots themselves in those environments. The core contribution seems to be the algorithm, not a deployment or detailed evaluation of a cobot system in a target work environment.

Therefore, the study is excluded based on the risk of meeting (EC3).",Ambas,Não,
Scopus,"Gao, H.; Chevallereau, C.; Caro, S.",Enhancing Safety in Collaborative Cable-Driven Parallel Robots: Contact Distinction and Management for Carrying Tasks,2025,10.1109/TASE.2025.3589966,"Cable-Driven Parallel Robots (CDPRs) have shown significant potential in industrial applications due to their large workspace, high payload capacity, and flexibility. Nonetheless, ensuring safe and efficient human-robot collaboration, particularly during carrying tasks, remains an open problem. This paper primarily contributes a cable tension-based metric for detecting contact events, combined with a frequency-domain analysis of estimated external wrenches to distinguish different contact scenarios. Building upon this framework, three common contact scenarios are then addressed: (i) payload placement and removal without rigid attachment to the moving-platform (SC1), (ii) unintentional human-cable collisions (SC2), and (iii) human-platform collisions (SC3). Specific management strategies are then proposed, including real-time mass estimation for payload handling, cable tension release for human-cable collisions, and a compliant trajectory controller for human-platform collisions. Experimental validations on a CDPR prototype demonstrate accurate scenario classification and safe contact handling without compromising overall productivity. By facilitating safer interactions, improved adaptability, and reliable handling of diverse contact events, this work expands the applicability of collaborative CDPRs in real-world industrial and logistic settings. Note to Practitioners-In many industrial applications, robots operating alongside human workers must quickly detect and respond to contact events to maintain safety and efficiency. Traditional methods often rely on force thresholds, which can introduce delays or false alarms, especially in dynamic tasks where rapid collisions must be addressed. Our work proposes an alternative approach that utilizes a frequency-domain analysis of sensed cable tensions and a weight-score system to robustly distinguish among various contact scenarios. By examining tension signals in the frequency domain, more nuanced information can be extracted, enabling faster and more accurate responses than threshold-based methods. From a practical standpoint, this technique is relatively straightforward to implement with various sensors, and it can be adapted to robots composed of different materials and link configurations by tuning the weight-score system for each new setup. Its primary benefit is improved contact distinction with high precision, which can enhance operator safety and reduce downtime without requiring extensive hardware modifications. However, like any sensor-driven control method, performance depends on adequate calibration and consistent signal quality. Future research might focus on integrating additional sensing modalities (e.g., vision or proximity sensors) and exploring broader deployment in diverse collaborative robot systems. © 2025 Elsevier B.V., All rights reserved.",human-robot collaboration; parallel robots; physical human-robot interaction; safety in HRI; Tendon/wire mechanism,Sim,Sim,Igual,"The study strongly aligns with all inclusion criteria:


(IC1) Focus on the Theme: The article directly addresses collaborative robots (cobots)—specifically, Cable-Driven Parallel Robots (CDPRs)—designed for human-robot interaction (HRI) in industrial and logistic environments. It explicitly discusses safe collaboration during carrying tasks, which falls within the “work environment” and “logistics” context specified.


(IC2) Focus on Research Questions: The paper includes experimental validations of a contact distinction and management framework, providing measured impacts on safety and productivity. It also explores implementation challenges and enabling technologies (sensors, tension-based metrics, control algorithms).


(IC3) Type of Publication: Published in Elsevier (2025), a peer-reviewed journal, satisfying this criterion.


(IC4) Language: Written in English.


(IC5) Time Period: Published in 2025, within the target window (2020–2025).


No exclusion criteria apply:


The robot is not single-task or fixed (EC1).


The sector is industrial/logistics, not military or domestic (EC2).


The study includes experimental validation, not merely simulation or theory (EC3).


It is not a review or abstract-only paper (EC4), and full text is accessible (EC5).


✅ Therefore, the study fully meets the inclusion criteria and avoids all exclusions.","The study aligns with all Inclusion Criteria (IC) and does not meet any Exclusion Criteria (EC) based on the title and abstract:

IC1 (Focus on the Theme): The title and abstract explicitly mention ""Collaborative Cable-Driven Parallel Robots"" (cobots) and discuss ""human-robot collaboration"" and ""carrying tasks."" The application is within ""real-world industrial and logistic settings,"" which satisfies the logistics context.

IC2 (Focus on the Research Questions): The study provides data on ""practical applications"" (experimental validations on a CDPR prototype) and focuses on ""HRI analysis"" (enhancing safety, contact distinction and management, human-cable/platform collisions) and ""enabling technologies"" (cable tension-based metric, frequency-domain analysis, compliant trajectory controller).

IC3 (Type of Publication): The copyright notice ""© 2025 Elsevier B.V., All rights reserved."" strongly suggests a peer-reviewed journal article or conference proceeding.

IC4 (Language): The abstract is in English.

IC5 (Time Period): The abstract indicates publication in ""2025,"" which is within the 2020–2025 window.

EC1 (Single-Task Robots): The focus is on collaborative robots (CDPRs) and human-robot collaboration, not fixed, single-task industrial robots.

EC2 (Excluded Sectors): The context is industrial and logistic settings, not military, space, domestic, or entertainment.

EC3 (Theoretical/Abstract Focus): The abstract clearly states ""Experimental validations on a CDPR prototype"" and discusses a ""real-world industrial and logistic settings"" application, indicating a validated prototype/application, not a purely theoretical or simulation-based article.

EC4 (Type of Publication): It is not explicitly stated as a review, book, thesis, etc. The structure and content suggest a primary research article.

EC5 (Access): This cannot be assessed from the abstract alone, but it is not triggered by the current information.",Ambas,Sim,
Scopus,"Alenljung, B.; Lindblom, J.",Introducing Mobile Robots on the Shop Floor: User Experience Issues,2025,10.1007/978-3-031-93982-2_1,"In Industry 4.0 and 5.0, humans and robots share physical and social spaces, making sustainable workplaces essential. While mobile, flexible, and collaborative robots offer new possibilities, challenges remain. Effective human-robot interaction relies on mutual recognition of actions and intentions for efficiency, safety, and smooth collaboration. Awareness of user experience (UX) is growing, as it influences work satisfaction, engagement, and well-being. This paper identifies UX issues when mobile robots are introduced on the shop floor alongside operators and truck drivers. The study, conducted at a large manufacturing plant, examined mobile robots delivering heavy parts to the assembly line and navigating a busy warehouse corridor and production area. Two months after field testing, a post-evaluation took place, with data collected from eight participants, four operators and four truck drivers, who had frequently interacted with the robots. Participants completed a questionnaire and an interview. Key findings show: a) differences between operators and truck drivers, b) higher UX assessments for operators, c) more and greater challenges for truck drivers, and d) neither group seeing major personal benefits but recognizing advantages for the company. Both physical and cognitive work environment problems were identified. © 2025 Elsevier B.V., All rights reserved.",human-robot interaction; User experience (UX); workplace sustainability,Sim,Sim,Igual,"The study meets all inclusion criteria:

(IC1) Focus on the Theme: The paper explicitly discusses the introduction and evaluation of mobile collaborative robots working alongside humans in an industrial environment (“shop floor,” “operators,” and “truck drivers”), fitting the target context of work environments and logistics/production areas. The focus on human-robot interaction (HRI) and collaborative work indicates strong alignment with the theme of cobots in real workplaces.

(IC2) Focus on Research Questions: The abstract mentions a field study assessing user experience (UX), safety, efficiency, and collaboration through post-evaluation, questionnaires, and interviews, providing measured qualitative and quantitative data on the practical application and impact of cobots—thus addressing implementation and human interaction challenges.

(IC3) Type of Publication: The abstract indicates publication by Elsevier B.V. (a peer-reviewed journal publisher).

(IC4) Language: The abstract is written in English.

(IC5) Time Period: Published in 2025, within the required range (2020–2025).

No exclusion criteria apply — it is not theoretical-only, not focused on excluded sectors, not a review, and clearly based on empirical field research.

✅ Conclusion: The study aligns perfectly with the inclusion criteria for collaborative robots in work environments and provides practical, evaluative insights.","The study aligns strongly with all inclusion criteria and does not appear to violate any exclusion criteria based on the provided title and abstract:

IC1 (Focus on the Theme): The title and abstract explicitly mention ""Mobile Robots"" and the context of a ""large manufacturing plant,"" ""shop floor,"" ""warehouse corridor,"" and ""production area,"" which fits the logistics context (warehouses) and inherently involves a work environment. The robots are described as working ""alongside operators and truck drivers,"" suggesting they are collaborative robots (cobots) or at least interacting with humans in a shared space. The theme is an evaluation of these robots' introduction.

IC2 (Focus on the Research Questions): The study is an ""Empirical Study"" identifying ""UX issues"" and collecting ""data from eight participants"" (operators and truck drivers) through a ""questionnaire and an interview"" after ""field testing"" and a ""post-evaluation."" This provides data on practical applications and HRI analysis (specifically User Experience), which measures implementation challenges.

IC3 (Type of Publication): The abstract includes a copyright notice (© 2025 Elsevier B.V.), which strongly suggests it is a peer-reviewed journal article or conference proceeding.

IC4 (Language): The text is in English.

IC5 (Time Period): The copyright date is 2025, which is within the 2020–2025 range.

EC1 (Single-Task Robots): The focus is on ""mobile, flexible, and collaborative robots"" interacting with humans, which excludes fixed, single-task industrial robots.

EC2 (Excluded Sectors): The context is a manufacturing plant/warehouse, which is within the logistics/work environment sector, not military, space, domestic, or entertainment.

EC3 (Theoretical/Abstract Focus): This is an empirical study with field testing and data collection from participants at a large manufacturing plant, not a purely theoretical or simulation-based article.

EC4 (Type of Publication): It appears to be an original research article, not a review, book chapter, thesis, or other excluded type.

EC5 (Access): Access cannot be confirmed from the abstract alone, but for the scoring based only on the title/abstract, we assume full text is obtainable unless information suggests otherwise.",Ambas,Sim,
Scopus,"Sileo, M.; Carriero, G.; Brancato, C.; Calzone, N.; Pierri, F.; Caccavale, F.; Mozzillo, R.",Safety Features for HumanTIX: An Augmented Reality Platform to Enhance Human–Robot Collaboration,2025,10.1007/978-3-031-72829-7_45,"The Industry 5.0 approach moves towards a sustainable, human-centric and adaptable manufacturing within companies, with a philosophy focused on meeting human needs and supporting societal values through the entire production process. Human–Robot Collaboration (HRC) emerges as a pivotal aspect of Industry 5.0, aiming to integrate robots and artificial intelligence seamlessly into workplaces alongside human workers. This integration presents challenges and opportunities for redefining job roles and enhancing productivity, while ensuring safety and workers well-being. This study focuses on the adoption of innovative technologies, such as collaborative robots (cobots) and Augmented Reality (AR) systems, to improve flexibility and safety in manufacturing and logistics for ensuring safe Human–Robot Interaction. The aim is to evaluate how AR devices, e.g., Hololens 2, could facilitate the interaction between cobots and operators, enhancing human performance and safety during robot programming and task execution, regardless of experience levels. Furthermore, the paper proposes the introduction of additional features to the existing AR platform for HRC, such as the creation of virtual walls and real-time operator concentration monitoring using gaze tracking. These improvements aim to empower operators with greater control over collaborative spaces, and enhance safety by ensuring operator focus during critical task phases. Overall, this work contributes to advancing the adoption of Industry 5.0 principles by demonstrating practical application of HRC technologies and AR systems to improve workplaces safety, productivity and Human–Robot Interaction in manufacturing environments. © 2025 Elsevier B.V., All rights reserved.",Augmented reality; Head mounted display; Human robot interaction; Robotics; Safety,Sim,Não,Diferente,"The study fully satisfies all inclusion criteria. It focuses on collaborative robots (cobots) interacting with humans in work environments (manufacturing and logistics), meeting IC1. The paper evaluates practical applications of AR-assisted HRC, including measurable impacts on safety, operator performance, and interaction efficiency, fulfilling IC2. The publication is a peer-reviewed journal article from Elsevier (2025), written in English, and thus meets IC3–IC5.

None of the exclusion criteria apply — the study is not about single-task robots, excluded sectors, or purely theoretical approaches, and it includes validated applications of enabling technologies (AR + cobots) in the target industrial context. Therefore, it earns a score of 1 (included).","The study aligns with several inclusion criteria but fails on a key aspect related to the target sectors and research focus:

(IC1) Focus on the Theme: The study focuses on collaborative robots (cobots) and discusses their application, implementation, and evaluation in work environments, specifically citing manufacturing and logistics. However, the primary focus and detailed application in the abstract is within manufacturing (""sustainable, human-centric and adaptable manufacturing,"" ""manufacturing and logistics,"" ""manufacturing environments""). While logistics is mentioned, the core content is centered on HRC, safety, and AR platforms in manufacturing, which is not one of the specified target contexts (Logistics, Healthcare, or Field Services). Logistics is mentioned, but the depth of discussion on the AR platform is heavily tilted toward factory/manufacturing-style applications (robot programming, task execution, virtual walls in collaborative spaces), making the primary theme not a strong match for the required sectors.

(IC2) Focus on the Research Questions: The study provides data on practical applications and focuses on HRI analysis and enabling technologies (cobots, AR), which aligns with this criterion.

(IC3/IC4/IC5) Publication Type, Language, Time Period: The abstract appears to be from a recent, peer-reviewed article (implied by ""© 2025 Elsevier B.V., All rights reserved""), is in English, and is within the 2020–2025 period. These are likely satisfied.

(EC2) Excluded Sectors: The explicit focus on manufacturing as the core application environment is not covered by the allowed sectors (logistics, healthcare, field services). The inclusion of manufacturing makes the study fall into a sector that is not one of the three explicitly permitted contexts, leading to an exclusion based on sector focus (unless the technology in question is a strong fit for the three target sectors, which is not strongly demonstrated in the abstract's discussion).

Conclusion: The primary application context detailed in the abstract is manufacturing, which is not explicitly listed in (IC1) (Logistics, Healthcare, or Field Services) and thus the study does not achieve strong alignment with all inclusion criteria.",LLM 1,Sim,
Scopus,"Hu, P.; Zhang, L.; Yang, H.; Yang, Y.",Model predictive-based compliance control for knee arthroplasty surgical robots; 基于模型预测的膝关节置换手术机器人柔顺控制,2024,10.13374/j.issn2095-9389.2023.12.27.001,"In response to the compliant tracking of surgical intent and adherence to safety range constraints in semi-active knee arthroplasty robots, a model predictive impedance control (MPIC) algorithm is proposed. First, to enhance this algorithm’s operational efficiency, the Stirling interpolation method is employed to linearize the dynamics model of the robotic arm as the predictive model. This method offers computational simplicity and high-precision solving accuracy. Second, based on the impedance model, the force-compliant control mechanism is used to identify the surgeon’s force intention, thereby generating the desired motion trajectory for the robotic arm. To facilitate programming implementation, the impedance model is discretized. Third, leveraging the rolling optimization and feedback correction properties of model predictive control, a virtual state enhancement is designed to improve the explicit constraint handling capability of the MPIC algorithm. This enhancement addresses the infeasibility issues encountered by traditional model predictive control near state constraint boundaries in practical applications. Transforming the model predictive problem into a quadratic programming problem reduces the difficulty of solving the model predictive problem and increases problem-solving speed. Finally, MPIC is integrated as the lower-level position-tracking controller for the robotic arm, with the impedance model serving as the upper-level task planning controller, thus forming the MPIC controller. Comparative experiments with three-loop PID (Proportional integral derivative) control are conducted on the ROKAE seven-axis collaborative robot experimental platform, confirming that the MPIC algorithm achieves better trajectory tracking accuracy and response speed, effectively realizing the desired impedance dynamics and yielding superior compliance. Additionally, further validation is conducted by installing a six-axis force sensor between the end-effector and the wrist of the robotic arm to measure human–robot interaction forces, confirming that the MPIC algorithm exhibits better compliance than traditional position-tracking control methods. Drag experiments are designed to verify the active constraint effect of MPIC on mechanically coupled robotic arms with complex system parameter structures, demonstrating that the control algorithm can actively constrain the motion of the robotic arm when it is manually manipulated to exceed the set state constraint range. Overall, the MPIC algorithm achieves better compliance and meets the safety requirements for knee arthroplasty surgery compared to traditional three-loop PID control methods. This advancement holds promise for further development and adoption of semi-active surgical robots, reducing the complexity of using surgical robots as surgeons and accelerating the widespread adoption of domestically produced surgical robots in hospitals. This paper should promote the practical application of semi-active surgical robots. © 2024 Elsevier B.V., All rights reserved.",admittance control; human–robot interaction; model predictive control; safety constraints; surgical robot,Sim,Sim,Igual,"This study presents a model predictive control approach applied to surgical robots used in knee arthroplasty. The focus is healthcare robotics with practical implementation and control optimization, directly satisfying IC1 (application in healthcare) and IC2 (implementation and design). Peer-reviewed and within 2020–2025, meeting IC3–IC5.","Justification: Strong alignment with all ICs. (IC1) Focus/Theme: Surgical robots are multifunctional/collaborative (semi-active) and the context is healthcare (knee arthroplasty). (IC2) Research Questions: Provides data on practical applications, HRI analysis (force sensor, compliance), and enabling technologies (MPIC algorithm). (IC3/IC4/IC5) Type/Language/Time: Peer-reviewed article, English abstract, Published 2024 (2020–2025). Meets all ICs and no ECs are met (EC1 is avoided as it's a semi-active surgical robot interacting with the surgeon).",Ambas,Sim,"Title: Model predictive-based compliance control for knee arthroplasty surgical robots; 基于模型预测的膝关节置换手术机器人柔顺控制
Abstract: In response to the compliant tracking of surgical intent and adherence to safety range constraints in semi-active knee arthroplasty robots, a model predictive impedance control (MPIC) algorithm is proposed. First, to enhance this algorithm’s operational efficiency, the Stirling interpolation method is employed to linearize the dynamics model of the robotic arm as the predictive model. This method offers computational simplicity and high-precision solving accuracy. Second, based on the impedance model, the force-compliant control mechanism is used to identify the surgeon’s force intention, thereby generating the desired motion trajectory for the robotic arm. To facilitate programming implementation, the impedance model is discretized. Third, leveraging the rolling optimization and feedback correction properties of model predictive control, a virtual state enhancement is designed to improve the explicit constraint handling capability of the MPIC algorithm. This enhancement addresses the infeasibility issues encountered by traditional model predictive control near state constraint boundaries in practical applications. Transforming the model predictive problem into a quadratic programming problem reduces the difficulty of solving the model predictive problem and increases problem-solving speed. Finally, MPIC is integrated as the lower-level position-tracking controller for the robotic arm, with the impedance model serving as the upper-level task planning controller, thus forming the MPIC controller. Comparative experiments with three-loop PID (Proportional integral derivative) control are conducted on the ROKAE seven-axis collaborative robot experimental platform, confirming that the MPIC algorithm achieves better trajectory tracking accuracy and response speed, effectively realizing the desired impedance dynamics and yielding superior compliance. Additionally, further validation is conducted by installing a six-axis force sensor between the end-effector and the wrist of the robotic arm to measure human–robot interaction forces, confirming that the MPIC algorithm exhibits better compliance than traditional position-tracking control methods. Drag experiments are designed to verify the active constraint effect of MPIC on mechanically coupled robotic arms with complex system parameter structures, demonstrating that the control algorithm can actively constrain the motion of the robotic arm when it is manually manipulated to exceed the set state constraint range. Overall, the MPIC algorithm achieves better compliance and meets the safety requirements for knee arthroplasty surgery compared to traditional three-loop PID control methods. This advancement holds promise for further development and adoption of semi-active surgical robots, reducing the complexity of using surgical robots as surgeons and accelerating the widespread adoption of domestically produced surgical robots in hospitals. This paper should promote the practical application of semi-active surgical robots. © 2024 Elsevier B.V., All rights reserved.
"
Scopus,"Guevara, L.; Khalid, M.; Hanheide, M.; Parsons, S.",Probabilistic model-checking of collaborative robots: A human injury assessment in agricultural applications,2024,10.1016/j.compag.2024.108987,"Current technology has made it possible to automate a number of agricultural processes that were traditionally carried out by humans and now can be entirely performed by robotic platforms. However, there are certain tasks like soft fruit harvesting, where human skills are still required. In this case, the robot's job is to cooperate/collaborate with human workers to alleviate their physical workload and improve harvesting efficiency. To accomplish that in a safe and reliable way, the robot should incorporate a safety system whose main goal is to reduce the risk of harming human co-workers during close human–robot interaction (HRI). In this context, this paper presents a theoretical study, addressing the safety risks of using collaborative robots in agricultural scenarios, especially in HRI situations when the robot's safety system is not completely reliable and a component may fail. The agricultural scenarios discussed in this paper include automatic harvesting, logistics operations, crop monitoring, and plant treatment using UV-C light. A human injury assessment is conducted based on converting the HRI in each agricultural scenario into a formal mathematical representation. This representation is later implemented in a probabilistic model-checking tool. We then use this tool to perform a sensitivity analysis that allows us to determine the probability that a human may get injured according to the occurrence of failures in the robot's safety or perception systems. Results of the sensitivity analysis show that an agricultural robot with a robust human perception system can still harm people if they are not well-trained to interact with the robot for certain scenarios. This illustrates how the probabilistic modeling methodology presented in this work can be used by safety engineers as a guideline to construct their own HRI models and then use the results of the model-checking to enhance the safety and reliability of their robot's safety system architectures and on-site safety policies. © 2024 Elsevier B.V., All rights reserved.",Agricultural robotics; HRI; PRISM; Probabilistic model-checking; Safety systems; Sensitivity analysis,Não,Não,Igual,"Despite mentioning “collaborative robots,” the scope is limited to agricultural applications, which fall outside logistics, healthcare, or field maintenance sectors (EC2). Furthermore, it relies on probabilistic model-checking with no real-world implementation, violating EC3 (theoretical-only approach).","Justification: Fails (IC3) and meets (EC3). (IC1) Focus/Theme: Collaborative robots (cobots) in agriculture (field services). (IC2) Research Questions: HRI analysis and safety. (EC3) Theoretical/Abstract Focus: The abstract explicitly states: ""this paper presents a theoretical study, addressing the safety risks... converting the HRI... into a formal mathematical representation... implemented in a probabilistic model-checking tool."" This is a purely theoretical/simulation focus without a validated prototype or case study.",Ambas,Não,"Title: Probabilistic model-checking of collaborative robots: A human injury assessment in agricultural applications
Abstract: Current technology has made it possible to automate a number of agricultural processes that were traditionally carried out by humans and now can be entirely performed by robotic platforms. However, there are certain tasks like soft fruit harvesting, where human skills are still required. In this case, the robot's job is to cooperate/collaborate with human workers to alleviate their physical workload and improve harvesting efficiency. To accomplish that in a safe and reliable way, the robot should incorporate a safety system whose main goal is to reduce the risk of harming human co-workers during close human–robot interaction (HRI). In this context, this paper presents a theoretical study, addressing the safety risks of using collaborative robots in agricultural scenarios, especially in HRI situations when the robot's safety system is not completely reliable and a component may fail. The agricultural scenarios discussed in this paper include automatic harvesting, logistics operations, crop monitoring, and plant treatment using UV-C light. A human injury assessment is conducted based on converting the HRI in each agricultural scenario into a formal mathematical representation. This representation is later implemented in a probabilistic model-checking tool. We then use this tool to perform a sensitivity analysis that allows us to determine the probability that a human may get injured according to the occurrence of failures in the robot's safety or perception systems. Results of the sensitivity analysis show that an agricultural robot with a robust human perception system can still harm people if they are not well-trained to interact with the robot for certain scenarios. This illustrates how the probabilistic modeling methodology presented in this work can be used by safety engineers as a guideline to construct their own HRI models and then use the results of the model-checking to enhance the safety and reliability of their robot's safety system architectures and on-site safety policies. © 2024 Elsevier B.V., All rights reserved.
"
Scopus,"Duan, J.; Zhuang, L.; Zhang, Q.; Zhou, Y.; Qin, J.",Multimodal perception-fusion-control and human–robot collaboration in manufacturing: a review,2024,10.1007/s00170-024-13385-2,"Collaborative robots, also known as cobots, are designed to work alongside humans in a shared workspace and provide assistance to them. With the rapid development of robotics and artificial intelligence in recent years, cobots have become faster, smarter, more accurate, and more dependable. They have found applications in a broad range of scenarios where humans require assistance, such as in the home, healthcare, and manufacturing. In manufacturing, in particular, collaborative robots combine the precision and strength of robots with the flexibility of human dexterity to replace or aid humans in highly repetitive or hazardous manufacturing tasks. However, human–robot interaction still needs improvement in terms of adaptability, decision making, and robustness to changing scenarios and uncertainty, especially in the context of continuous interaction with human operators. Collaborative robots and humans must establish an intuitive and understanding rapport to build a cooperative working relationship. Therefore, human–robot interaction is a crucial research problem in robotics. This paper provides a summary of the research on human–robot interaction over the past decade, with a focus on interaction methods in human–robot collaboration, environment perception, task allocation strategies, and scenarios for human–robot collaboration in manufacturing. Finally, the paper presents the primary research directions and challenges for the future development of collaborative robots. © 2024 Elsevier B.V., All rights reserved.",Collaborative robots; Human–robot collaboration; Manufacturing; Multimodal acquisition,Não,Não,Igual,"Although thematically relevant, this article is explicitly a review paper, not a primary study. It does not present an implementation or empirical analysis, thus excluded under EC4 (review/meta-analysis).","Justification: Fails (IC3) and meets (EC4). (EC4) Type of Publication: The title and abstract clearly indicate this is a review paper: ""...a review,"" and ""This paper provides a summary of the research on human–robot interaction over the past decade..."".",Ambas,Não,"Title: Multimodal perception-fusion-control and human–robot collaboration in manufacturing: a review
Abstract: Collaborative robots, also known as cobots, are designed to work alongside humans in a shared workspace and provide assistance to them. With the rapid development of robotics and artificial intelligence in recent years, cobots have become faster, smarter, more accurate, and more dependable. They have found applications in a broad range of scenarios where humans require assistance, such as in the home, healthcare, and manufacturing. In manufacturing, in particular, collaborative robots combine the precision and strength of robots with the flexibility of human dexterity to replace or aid humans in highly repetitive or hazardous manufacturing tasks. However, human–robot interaction still needs improvement in terms of adaptability, decision making, and robustness to changing scenarios and uncertainty, especially in the context of continuous interaction with human operators. Collaborative robots and humans must establish an intuitive and understanding rapport to build a cooperative working relationship. Therefore, human–robot interaction is a crucial research problem in robotics. This paper provides a summary of the research on human–robot interaction over the past decade, with a focus on interaction methods in human–robot collaboration, environment perception, task allocation strategies, and scenarios for human–robot collaboration in manufacturing. Finally, the paper presents the primary research directions and challenges for the future development of collaborative robots. © 2024 Elsevier B.V., All rights reserved.
"
Scopus,"Sirintuna, D.; Giammarino, A.; Ajoudani, A.",An Object Deformation-Agnostic Framework for Human-Robot Collaborative Transportation,2024,10.1109/TASE.2023.3259162,"In this study, an adaptive object deformability-agnostic human-robot collaborative transportation framework is presented. The proposed framework enables to combine the haptic information transferred through the object with the human kinematic information obtained from a motion capture system to generate reactive whole-body motions on a mobile collaborative robot. Furthermore, it allows rotating the objects in an intuitive and accurate way during co-transportation based on an algorithm that detects the human rotation intention using the torso and hand movements. First, we validate the framework with the two extremities of the object deformability range (i.e., purely rigid aluminum rod and highly deformable rope) by utilizing a mobile manipulator which consists of an Omni-directional mobile base and a collaborative robotic arm. Next, its performance is compared with an admittance controller during a co-carry task of a partially deformable object in a 12-subjects user study. Quantitative and qualitative results of this experiment show that the proposed framework can effectively handle the transportation of objects regardless of their deformability and provides intuitive assistance to human partners. Finally, we have demonstrated the potential of our framework in a different scenario, where the human and the robot co-transport a manikin using a deformable sheet. Note to Practitioners - Transportation of objects which requires the cooperation of multiple partners, is a common task in industrial settings such as factories and warehouses. The existing human-robot collaboration solutions for this task have focused only on purely rigid objects, although deformable objects need to be carried frequently in real-world applications. In this paper, we introduce a human-robot collaborative transportation framework that can handle objects with different deformability ranging from purely rigid to highly deformable. In particular, the proposed framework generates whole-body movements on a mobile collaborative robot by combining of the haptic information transmitted through the object and the human motion information obtained from a motion capture system. Moreover, the framework includes an intuitive way to rotate the object during the execution based on human hand and torso motion. The results of the experiments where objects with various deformability characteristics were transported in collaboration with a mobile manipulator demonstrated the high potential of the proposed approach in a laboratory setting. In the future, we plan to employ a less expensive vision-based human motion tracking system instead of the IMU-based system used in this study. With this change, we will be able to eliminate the need for wearable sensors from the framework presented, which would enhance its usability in real-world scenarios. © 2024 Elsevier B.V., All rights reserved.",collaborative object transportation; deformable materials; mobile manipulation; Physical humana-robot interaction; whole-body control,Sim,Sim,Igual,"Proposes a novel applied framework for collaborative transportation tasks between humans and robots. The context aligns with industrial logistics and focuses on physical HRI and control design, meeting IC1 and IC2 with practical contribution.","Justification: Strong alignment with all ICs. (IC1) Focus/Theme: Focuses on a mobile collaborative robot (cobot) for co-transportation in industrial settings like factories and warehouses (logistics). (IC2) Research Questions: Provides data on practical applications and HRI analysis (user study). (IC3/IC4/IC5) Type/Language/Time: Peer-reviewed article, English, Published 2024. Meets all ICs and no ECs are met.",Ambas,Sim,"Title: An Object Deformation-Agnostic Framework for Human-Robot Collaborative Transportation
Abstract: In this study, an adaptive object deformability-agnostic human-robot collaborative transportation framework is presented. The proposed framework enables to combine the haptic information transferred through the object with the human kinematic information obtained from a motion capture system to generate reactive whole-body motions on a mobile collaborative robot. Furthermore, it allows rotating the objects in an intuitive and accurate way during co-transportation based on an algorithm that detects the human rotation intention using the torso and hand movements. First, we validate the framework with the two extremities of the object deformability range (i.e., purely rigid aluminum rod and highly deformable rope) by utilizing a mobile manipulator which consists of an Omni-directional mobile base and a collaborative robotic arm. Next, its performance is compared with an admittance controller during a co-carry task of a partially deformable object in a 12-subjects user study. Quantitative and qualitative results of this experiment show that the proposed framework can effectively handle the transportation of objects regardless of their deformability and provides intuitive assistance to human partners. Finally, we have demonstrated the potential of our framework in a different scenario, where the human and the robot co-transport a manikin using a deformable sheet. Note to Practitioners - Transportation of objects which requires the cooperation of multiple partners, is a common task in industrial settings such as factories and warehouses. The existing human-robot collaboration solutions for this task have focused only on purely rigid objects, although deformable objects need to be carried frequently in real-world applications. In this paper, we introduce a human-robot collaborative transportation framework that can handle objects with different deformability ranging from purely rigid to highly deformable. In particular, the proposed framework generates whole-body movements on a mobile collaborative robot by combining of the haptic information transmitted through the object and the human motion information obtained from a motion capture system. Moreover, the framework includes an intuitive way to rotate the object during the execution based on human hand and torso motion. The results of the experiments where objects with various deformability characteristics were transported in collaboration with a mobile manipulator demonstrated the high potential of the proposed approach in a laboratory setting. In the future, we plan to employ a less expensive vision-based human motion tracking system instead of the IMU-based system used in this study. With this change, we will be able to eliminate the need for wearable sensors from the framework presented, which would enhance its usability in real-world scenarios. © 2024 Elsevier B.V., All rights reserved.
"
Scopus,"Rollo, F.; Raiola, G.; Tsagarakis, N.; Roveri, M.; Mingo Hoffman, E.M.; Ajoudani, A.",Semantic-Based Loco-Manipulation for Human-Robot Collaboration in Industrial Environments,2024,10.1007/978-3-031-76428-8_11,"Robots with a high level of autonomy are increasingly requested by smart industries. A way to reduce the workers’ stress and effort is to optimize the working environment by taking advantage of autonomous collaborative robots. A typical task for Human-Robot Collaboration (HRC) which improves the working setup in an industrial environment is the “bring me an object please” where the user asks the collaborator to search for an object while he/she is focused on something else. As often happens, science fiction is ahead of the times, indeed, in the Iron Man movie, the robot Dum-E helps its creator, Tony Stark, to create its famous armours. The ability of the robot to comprehend the semantics of the environment and engage with it is valuable for the human execution of more intricate tasks. In this work, we reproduce this operation to enable a mobile robot with manipulation and grasping capabilities to leverage its geometric and semantic understanding of the environment for the execution of the Bring Me action, thereby assisting a worker autonomously. Results are provided to validate the proposed workflow in a simulated environment populated with objects and people. This framework aims to take a step forward in assistive robotics autonomy for industries and domestic environments. © 2025 Elsevier B.V., All rights reserved.",Assistive Robotics e; Human-Robot Collaboration; Semantic Loco-manipulation; Semantic Mapping,Sim,Não,Diferente,"Focuses on integrating semantic reasoning with locomotion and manipulation for HRI in industrial contexts. This fits IC1 (industrial collaboration) and IC2 (enabling technologies and implementation challenges), providing applied insights.","Justification: Fails (IC2) and meets (EC3). (IC1) Focus/Theme: Autonomous collaborative robots in industrial environments. (IC2) Research Questions: The application is described as being validated in a ""simulated environment"" without a case study or validated prototype in the target sectors, which fails the requirement for data on practical applications/implementation. (EC3) Theoretical/Abstract Focus: ""Results are provided to validate the proposed workflow in a simulated environment..."".",LLM 2,Sim,"Title: Semantic-Based Loco-Manipulation for Human-Robot Collaboration in Industrial Environments
Abstract: Robots with a high level of autonomy are increasingly requested by smart industries. A way to reduce the workers’ stress and effort is to optimize the working environment by taking advantage of autonomous collaborative robots. A typical task for Human-Robot Collaboration (HRC) which improves the working setup in an industrial environment is the “bring me an object please” where the user asks the collaborator to search for an object while he/she is focused on something else. As often happens, science fiction is ahead of the times, indeed, in the Iron Man movie, the robot Dum-E helps its creator, Tony Stark, to create its famous armours. The ability of the robot to comprehend the semantics of the environment and engage with it is valuable for the human execution of more intricate tasks. In this work, we reproduce this operation to enable a mobile robot with manipulation and grasping capabilities to leverage its geometric and semantic understanding of the environment for the execution of the Bring Me action, thereby assisting a worker autonomously. Results are provided to validate the proposed workflow in a simulated environment populated with objects and people. This framework aims to take a step forward in assistive robotics autonomy for industries and domestic environments. © 2025 Elsevier B.V., All rights reserved.
"
Scopus,"Pietrantoni, L.; Favilla, M.; Fraboni, F.; Mazzoni, E.; Morandini, S.; Benvenuti, M.; De Angelis, M.","Integrating collaborative robots in manufacturing, logistics, and agriculture: Expert perspectives on technical, safety, and human factors",2024,10.3389/frobt.2024.1342130,"This study investigates the implementation of collaborative robots across three distinct industrial sectors: vehicle assembly, warehouse logistics, and agricultural operations. Through the SESTOSENSO project, an EU-funded initiative, we examined expert perspectives on human-robot collaboration using a mixed-methods approach. Data were collected from 31 technical experts across nine European countries through an online questionnaire combining qualitative assessments of specific use cases and quantitative measures of attitudes, trust, and safety perceptions. Expert opinions across the use cases emphasized three primary concerns: technical impacts of cobot adoption, social and ethical considerations, and safety issues in design and deployment. In vehicle assembly, experts stressed the importance of effective collaboration between cobots and exoskeletons to predict and prevent collisions. For logistics, they highlighted the need for adaptable systems capable of handling various object sizes while maintaining worker safety. In agricultural settings, experts emphasized the importance of developing inherently safe applications that can operate effectively on uneven terrain while reducing workers’ physical strain. Results reveal sector-specific challenges and opportunities: vehicle assembly operations require sophisticated sensor systems for cobot-exoskeleton integration; warehouse logistics demand advanced control systems for large object handling; and agricultural applications need robust navigation systems for uneven terrain. Quantitative findings indicate generally positive attitudes toward cobots, particularly regarding societal benefits, moderate to high levels of trust in cobot capabilities and favorable safety perceptions. The study highlights three key implications: (1) the need for comprehensive safety protocols tailored to each sector’s unique requirements, (2) the importance of user-friendly interfaces and intuitive programming methods for successful cobot integration, and (3) the necessity of addressing workforce transition and skill development concerns. These findings contribute to our understanding of human-robot collaboration in industrial settings and provide practical guidance for organizations implementing collaborative robotics while considering both technological advancement and human-centered design principles. © 2024 Elsevier B.V., All rights reserved.",collaborative robots; human-robot collaboration; industrial automation; safety perception; trust development; workforce transition,Sim,Sim,Igual,"Explores expert evaluations of cobot integration challenges across sectors, including logistics and manufacturing (IC1). The inclusion of safety and human factors reflects HRI analysis (IC2). Despite partial agricultural coverage, it remains within the scope due to mixed-sector relevance.","Justification: Strong alignment with all ICs. (IC1) Focus/Theme: Collaborative robots (cobots) in logistics (warehouse), field services (agriculture), and manufacturing. (IC2) Research Questions: Provides data/analysis on implementation challenges (technical, social, ethical, safety, human factors) and practical application use cases. (IC3/IC4/IC5) Type/Language/Time: Peer-reviewed article, English, Published 2024. Meets all ICs. This is an empirical study about implementation, not a literature review.",Ambas,Sim,"Title: Integrating collaborative robots in manufacturing, logistics, and agriculture: Expert perspectives on technical, safety, and human factors
Abstract: This study investigates the implementation of collaborative robots across three distinct industrial sectors: vehicle assembly, warehouse logistics, and agricultural operations. Through the SESTOSENSO project, an EU-funded initiative, we examined expert perspectives on human-robot collaboration using a mixed-methods approach. Data were collected from 31 technical experts across nine European countries through an online questionnaire combining qualitative assessments of specific use cases and quantitative measures of attitudes, trust, and safety perceptions. Expert opinions across the use cases emphasized three primary concerns: technical impacts of cobot adoption, social and ethical considerations, and safety issues in design and deployment. In vehicle assembly, experts stressed the importance of effective collaboration between cobots and exoskeletons to predict and prevent collisions. For logistics, they highlighted the need for adaptable systems capable of handling various object sizes while maintaining worker safety. In agricultural settings, experts emphasized the importance of developing inherently safe applications that can operate effectively on uneven terrain while reducing workers’ physical strain. Results reveal sector-specific challenges and opportunities: vehicle assembly operations require sophisticated sensor systems for cobot-exoskeleton integration; warehouse logistics demand advanced control systems for large object handling; and agricultural applications need robust navigation systems for uneven terrain. Quantitative findings indicate generally positive attitudes toward cobots, particularly regarding societal benefits, moderate to high levels of trust in cobot capabilities and favorable safety perceptions. The study highlights three key implications: (1) the need for comprehensive safety protocols tailored to each sector’s unique requirements, (2) the importance of user-friendly interfaces and intuitive programming methods for successful cobot integration, and (3) the necessity of addressing workforce transition and skill development concerns. These findings contribute to our understanding of human-robot collaboration in industrial settings and provide practical guidance for organizations implementing collaborative robotics while considering both technological advancement and human-centered design principles. © 2024 Elsevier B.V., All rights reserved.
"
Scopus,"Crnokic, B.; Peko, I.; Gotlih, J.","The Development of Assistive Robotics: A Comprehensive Analysis Integrating Machine Learning, Robotic Vision, and Collaborative Human Assistive Robots",2024,10.1007/978-3-031-62058-4_12,"With integration of collaborative robotics, robotic vision, and machine learning, the high-end frontier reached in assistive robotics is likely to help develop promising solutions to the challenges associated with the needs of aging populations and persons with disabilities. This paper examines recent developments, challenges, and opportunities that relate to the application of these technologies for human assistance. The paper will begin with an explanation of the basic concepts and the rationales driving assistive robotics, and then move on to the technological ground with basic collaborative robots, robotic vision, and machine learning, stressing how they can make human assistance better. Case studies and real-world applications will help to present the potential of integrated assistive robotics not only in healthcare and rehabilitation, but also in domains such as elder care and living on one’s own. This paper also highlights some of the critical challenges inclusive of robustness, reliability, human-robot interaction, safety, and ethical considerations along with some of the emerging trends and future research directions related to it. The paper sets up a visionary outlook, where integrated assistive robotics—realized fully through human-centered design, interdisciplinary collaboration, and innovation in technology development—could revolutionize care and support toward fostering the inclusivity, dignity, and independence of those with diverse needs. © 2024 Elsevier B.V., All rights reserved.",Assistive Robotics; Collaborative Robots; Machine Learning; Robotic Vision,Sim,Não,Diferente,"Centers on assistive robotics for healthcare, focusing on machine learning and robotic vision. It presents an integrative, applied perspective on collaborative human-assistive robots, fulfilling IC1 (healthcare focus) and IC2 (enabling technologies).","Justification: Fails (IC3) and meets (EC4). (EC4) Type of Publication: The title and abstract indicate this is a comprehensive analysis examining developments, challenges, and opportunities, making it a review paper/survey.",LLM 2,Sim,"Title: The Development of Assistive Robotics: A Comprehensive Analysis Integrating Machine Learning, Robotic Vision, and Collaborative Human Assistive Robots
Abstract: With integration of collaborative robotics, robotic vision, and machine learning, the high-end frontier reached in assistive robotics is likely to help develop promising solutions to the challenges associated with the needs of aging populations and persons with disabilities. This paper examines recent developments, challenges, and opportunities that relate to the application of these technologies for human assistance. The paper will begin with an explanation of the basic concepts and the rationales driving assistive robotics, and then move on to the technological ground with basic collaborative robots, robotic vision, and machine learning, stressing how they can make human assistance better. Case studies and real-world applications will help to present the potential of integrated assistive robotics not only in healthcare and rehabilitation, but also in domains such as elder care and living on one’s own. This paper also highlights some of the critical challenges inclusive of robustness, reliability, human-robot interaction, safety, and ethical considerations along with some of the emerging trends and future research directions related to it. The paper sets up a visionary outlook, where integrated assistive robotics—realized fully through human-centered design, interdisciplinary collaboration, and innovation in technology development—could revolutionize care and support toward fostering the inclusivity, dignity, and independence of those with diverse needs. © 2024 Elsevier B.V., All rights reserved.
"
Scopus,"Srivatsan, H.; Myagerimath, A.V.; Duffy, V.G.",A Systematic Review of Collaborative Robots in Ergonomics,2024,10.1007/978-3-031-61066-0_17,"Collaborative robots are used in various industries, such as manufacturing, healthcare, agriculture, and education. This study aims to review the ergonomics of using collaborative robots in manufacturing applications. The first step involved metadata extraction from databases such as Harzing’s Publish or Perish, Scopus, and Web of Science. This was done to generate relevant works and authors in the field. The metadata was next analyzed using content analysis methods such as NVivo, VOSViewer, and BibExcel, to highlight key authors and groups of topics. Cluster analysis was applied to the metadata using CiteSpace to obtain citation burst articles. Scite.AI was used to further understand emerging themes. The systematic review identified key research areas, such as the communication modalities and degree of collaboration in human-robot interaction, human-robot cooperation in teamwork theories, and the long-term ergonomic effects of using cobots. © 2024 Elsevier B.V., All rights reserved.",Collaborative Robots; Ergonomics; Human,Não,Não,Igual,"Labeled as a systematic review, it summarizes prior works rather than reporting new empirical data. Therefore, it violates EC4 (review type) despite thematic alignment.",Justification: Fails (IC3) and meets (EC4). (EC4) Type of Publication: The title explicitly states this is a Systematic Review.,Ambas,Não,"Title: A Systematic Review of Collaborative Robots in Ergonomics
Abstract: Collaborative robots are used in various industries, such as manufacturing, healthcare, agriculture, and education. This study aims to review the ergonomics of using collaborative robots in manufacturing applications. The first step involved metadata extraction from databases such as Harzing’s Publish or Perish, Scopus, and Web of Science. This was done to generate relevant works and authors in the field. The metadata was next analyzed using content analysis methods such as NVivo, VOSViewer, and BibExcel, to highlight key authors and groups of topics. Cluster analysis was applied to the metadata using CiteSpace to obtain citation burst articles. Scite.AI was used to further understand emerging themes. The systematic review identified key research areas, such as the communication modalities and degree of collaboration in human-robot interaction, human-robot cooperation in teamwork theories, and the long-term ergonomic effects of using cobots. © 2024 Elsevier B.V., All rights reserved.
"
Scopus,"Detesan, O.-A.; Moholea, I.F.",Beyond the Horizon: Anticipating Future Challenges in the Field of Robotics,2024,10.1007/978-3-031-59257-7_28,"This paper navigates the evolving landscape of robotics, examining current advancements, historical evolution, and anticipated challenges. Delving into technological and ethical dimensions, it provides a general overview. The current state reveals a dynamic robotics spectrum, from collaborative robots to AI-driven systems, transforming industries and daily life. Tracing the historical perspective, pivotal milestones are explored, and ongoing trends, like miniaturization and AI, shaping the future are identified. Anticipated challenges include AI integration complexities, sensing advancements, and ethical considerations in human–robot interaction. Ethical and social challenges encompass job displacement, ethical AI decision-making, and privacy concerns. Future applications show robotics in healthcare, transportation, manufacturing, space exploration, and daily life. The conclusion emphasizes the need for responsible innovation, interdisciplinary collaboration, and adaptive regulations to shape a future where robotics enriches human lives responsibly and sustainably. © 2024 Elsevier B.V., All rights reserved.",Evolution; Future challenges; Robotics,Não,Não,Igual,A conceptual or foresight paper discussing future directions without experimental or implementation data. Violates EC3 (theoretical/abstract) since no real-world validation is provided.,"Justification: Fails (IC1). (IC1) Focus on the Theme: This is a general overview of the evolving landscape of robotics, covering technological and ethical dimensions, with a broad scope beyond the specific target sectors (logistics, healthcare, field services) and lacking the specific depth of application/implementation required.",Ambas,Não,"Title: Beyond the Horizon: Anticipating Future Challenges in the Field of Robotics
Abstract: This paper navigates the evolving landscape of robotics, examining current advancements, historical evolution, and anticipated challenges. Delving into technological and ethical dimensions, it provides a general overview. The current state reveals a dynamic robotics spectrum, from collaborative robots to AI-driven systems, transforming industries and daily life. Tracing the historical perspective, pivotal milestones are explored, and ongoing trends, like miniaturization and AI, shaping the future are identified. Anticipated challenges include AI integration complexities, sensing advancements, and ethical considerations in human–robot interaction. Ethical and social challenges encompass job displacement, ethical AI decision-making, and privacy concerns. Future applications show robotics in healthcare, transportation, manufacturing, space exploration, and daily life. The conclusion emphasizes the need for responsible innovation, interdisciplinary collaboration, and adaptive regulations to shape a future where robotics enriches human lives responsibly and sustainably. © 2024 Elsevier B.V., All rights reserved.
"
Scopus,"Mendez, E.; Ochoa, O.; Olivera-Guzman, D.; Soto-Herrera, V.H.; Luna-Sanchez, J.A.; Lucas-Dophe, C.; Lugo-Del-Real, E.; Ayala-Garcia, I.N.; Pérez, M.; González, A.",Integration of Deep Learning and Collaborative Robot for Assembly Tasks,2024,10.3390/app14020839,"Human–robot collaboration has gained attention in the field of manufacturing and assembly tasks, necessitating the development of adaptable and user-friendly forms of interaction. To address this demand, collaborative robots (cobots) have emerged as a viable solution. Deep Learning has played a pivotal role in enhancing robot capabilities and facilitating their perception and understanding of the environment. This study proposes the integration of cobots and Deep Learning to assist users in assembly tasks such as part handover and storage. The proposed system includes an object classification system to categorize and store assembly elements, a voice recognition system to classify user commands, and a hand-tracking system for close interaction. Tests were conducted for each isolated system and for the complete application as used by different individuals, yielding an average accuracy of 91.25%. The integration of Deep Learning into cobot applications has significant potential for transforming industries, including manufacturing, healthcare, and assistive technologies. This work serves as a proof of concept for the use of several neural networks and a cobot in a collaborative task, demonstrating communication between the systems and proposing an evaluation approach for individual and integrated systems. © 2024 Elsevier B.V., All rights reserved.",cobots; collaborative robotics; Deep Learning; human–robot interaction; neural network,Sim,Sim,Igual,"Focused on industrial assembly using deep learning-enhanced cobots. It represents an applied study of design and implementation (IC2) in a manufacturing environment with human-robot interaction, satisfying IC1–IC3.","Justification: Strong alignment with all ICs. (IC1) Focus/Theme: Collaborative robot (cobot) for assembly tasks in manufacturing/industries (Implied as an industrial task). (IC2) Research Questions: Provides data on practical application (part handover, storage), HRI analysis (voice/hand tracking, close interaction), and enabling technologies (Deep Learning integration). (IC3/IC4/IC5) Type/Language/Time: Peer-reviewed article, English, Published 2024. Meets all ICs.",Ambas,Sim,"Title: Integration of Deep Learning and Collaborative Robot for Assembly Tasks
Abstract: Human–robot collaboration has gained attention in the field of manufacturing and assembly tasks, necessitating the development of adaptable and user-friendly forms of interaction. To address this demand, collaborative robots (cobots) have emerged as a viable solution. Deep Learning has played a pivotal role in enhancing robot capabilities and facilitating their perception and understanding of the environment. This study proposes the integration of cobots and Deep Learning to assist users in assembly tasks such as part handover and storage. The proposed system includes an object classification system to categorize and store assembly elements, a voice recognition system to classify user commands, and a hand-tracking system for close interaction. Tests were conducted for each isolated system and for the complete application as used by different individuals, yielding an average accuracy of 91.25%. The integration of Deep Learning into cobot applications has significant potential for transforming industries, including manufacturing, healthcare, and assistive technologies. This work serves as a proof of concept for the use of several neural networks and a cobot in a collaborative task, demonstrating communication between the systems and proposing an evaluation approach for individual and integrated systems. © 2024 Elsevier B.V., All rights reserved.
"
Scopus,"Mulkana, S.R.",Safe Reinforcement Learning for Collaborative Robots in Dynamic Human Environments,2024,10.1109/ACIIW63320.2024.00013,"Collaborative robots trained using Reinforcement Learning (RL) techniques to perform complex tasks have shown promising results in simulations and controlled environments. However, the actions of such autonomous robots are not always predictable in real-world settings. This poses risks of injury to humans, particularly in joint action tasks where human and robot come in close contact. Conventional safe RL models, such as reward shaping and constraint RL, prioritize safety during learning and deployment, but do not guarantee that all actions will lead to safe states. Shielded RL, which seeks to provide safety guarantees, also struggles in joint action tasks such as collaborative assembly and object handover. Improving shielded RL to account for close-contact human-robot tasks presents a potential solution to facilitate the safe application of RL-based robots in the real world. This research aims to develop safe RL models that ensure safe robot motion in human-robot joint action tasks. Additionally, it investigates how these models affect human-robot interaction to identify human-preferred robot motions for collaborative tasks. The outcomes of this research aim to significantly advance the integration of safe collaborative robots in social, healthcare, and industrial environments. © 2025 Elsevier B.V., All rights reserved.",cognitive safety; Collaborative robots; dynamic environment; human-robot interaction; physical safety; robot motion; safe reinforcement learning,Sim,Sim,Igual,"Presents applied reinforcement learning methods for real-time adaptation in dynamic HRI settings, indicating direct implementation and evaluation. The study fits IC1 (collaborative robots with humans) and IC2 (enabling technology and safety evaluation).","Justification: Strong alignment with all ICs. (IC1) Focus/Theme: Collaborative robots for joint action tasks like collaborative assembly and object handover in social, healthcare, and industrial environments. (IC2) Research Questions: Focuses on enabling technologies (Safe RL), HRI analysis, and safety. (IC3/IC4/IC5) Type/Language/Time: Peer-reviewed article, English, Published 2025. Meets all ICs.",Ambas,Sim,"Title: Safe Reinforcement Learning for Collaborative Robots in Dynamic Human Environments
Abstract: Collaborative robots trained using Reinforcement Learning (RL) techniques to perform complex tasks have shown promising results in simulations and controlled environments. However, the actions of such autonomous robots are not always predictable in real-world settings. This poses risks of injury to humans, particularly in joint action tasks where human and robot come in close contact. Conventional safe RL models, such as reward shaping and constraint RL, prioritize safety during learning and deployment, but do not guarantee that all actions will lead to safe states. Shielded RL, which seeks to provide safety guarantees, also struggles in joint action tasks such as collaborative assembly and object handover. Improving shielded RL to account for close-contact human-robot tasks presents a potential solution to facilitate the safe application of RL-based robots in the real world. This research aims to develop safe RL models that ensure safe robot motion in human-robot joint action tasks. Additionally, it investigates how these models affect human-robot interaction to identify human-preferred robot motions for collaborative tasks. The outcomes of this research aim to significantly advance the integration of safe collaborative robots in social, healthcare, and industrial environments. © 2025 Elsevier B.V., All rights reserved.
"
Scopus,"Zapata, O.S.M.; Correa, Y.G.; Yoshioka, L.R.; Silva, J.R.",Modeling Requirements for Collaborative Robotic Services,2023,10.3390/eng4040165,"Collaborative robots have experienced low acceptance in applications, especially in industry. This fact has attracted the attention of researchers and practitioners, who point to different causes for this limited acceptance. One of the main reasons is the difficulty in converging on suitable methods for modeling collaborative interactions between robots and their surrounding context during the requirements phase. These interactions must be elicited and modeled during the requirements stage to maximize value creation through collaboration. Formal verification is necessary, taking into account the risks of human-robot interaction. However, such modeling is often absent in collaborative robot design, and choosing an appropriate approach remains an open problem. This paper addresses this problem using a model-based requirements cycle where the value creation is detached to provide direct analysis, possible optimization, and formal verification. The general process integrates with the general model-based requirements engineering of the remaining system. This service system approach relies on a goal-oriented requirements approach, and specific algorithms were developed to transfer goal-oriented diagrams into Petri Nets—to provide formal process verification. A case study illustrates the application of the proposed method on a collaborative robot used in a university hospital environment. © 2024 Elsevier B.V., All rights reserved.",collaborative robots; human–robot interaction; requirements engineering; systems design; value co-creation,Sim,Sim,Igual,"Addresses system and software modeling for service-oriented cobots. While conceptual, the paper focuses on applied modeling requirements in human-service contexts, meeting IC1 (design/application) and IC2 (implementation framework).","Justification: Strong alignment with all ICs. (IC1) Focus/Theme: Collaborative robotic services with a case study in a university hospital environment (healthcare). (IC2) Research Questions: Focuses on implementation challenges (requirements modeling, formal verification) and practical application (case study). (IC3/IC4/IC5) Type/Language/Time: Peer-reviewed article, English, Published 2024. Meets all ICs.",Ambas,Sim,"Title: Modeling Requirements for Collaborative Robotic Services
Abstract: Collaborative robots have experienced low acceptance in applications, especially in industry. This fact has attracted the attention of researchers and practitioners, who point to different causes for this limited acceptance. One of the main reasons is the difficulty in converging on suitable methods for modeling collaborative interactions between robots and their surrounding context during the requirements phase. These interactions must be elicited and modeled during the requirements stage to maximize value creation through collaboration. Formal verification is necessary, taking into account the risks of human-robot interaction. However, such modeling is often absent in collaborative robot design, and choosing an appropriate approach remains an open problem. This paper addresses this problem using a model-based requirements cycle where the value creation is detached to provide direct analysis, possible optimization, and formal verification. The general process integrates with the general model-based requirements engineering of the remaining system. This service system approach relies on a goal-oriented requirements approach, and specific algorithms were developed to transfer goal-oriented diagrams into Petri Nets—to provide formal process verification. A case study illustrates the application of the proposed method on a collaborative robot used in a university hospital environment. © 2024 Elsevier B.V., All rights reserved.
"
Scopus,"Sabeeh, S.; Al-Furati, I.S.",Issues and Research Fields of Medical Robotics: A Review,2023,10.37917/ijeee.19.2.16,"The goal for collaborative robots has always driven advancements in robotic technology, especially in the manufacturing sector. However, this is not the case in service sectors, especially in the health sector. Thus, this lack of focus has now opened more room for the design and development of service robots that can be used in the health sector to help patients with ailments, cognitive problems, and disabilities. There is currently a global effort towards the development of new products and the use of robotic medical devices and computer-assisted systems. However, the major problem has been the lack of a thorough and systematic review of robotic research into disease and epidemiology, especially from a technology perspective. Also, medical robots are increasingly being used in healthcare to perform a variety of functions that improve patient care. This scoping review is aimed at discovering the types of robots used in healthcare and where they are deployed. Moreover, the current study is an overview of various forms of robotic technology and its uses the healthcare industry. The considered technologies are the products of a partnership between the healthcare sector and academia. They demonstrate the research and testing that are necessary for the service of robot development before they can be employed in practical applications and service scenarios. The discussion also focused on the upcoming research areas in robotic systems as well as some important technologies necessary for human-robot collaboration, such as wireless sensor networks, big data, and artificial intelligence. © 2023 Elsevier B.V., All rights reserved.",Healthcare; human-robot collaboration; Medical Robotics; Robotics; WSN,Não,Não,Igual,"Explicitly described as a review, summarizing challenges and open issues without presenting applied case studies or prototypes. Excluded under EC4 (review publication).","Justification: Fails (IC3) and meets (EC4). (EC4) Type of Publication: The title and abstract indicate this is a review (""...A Review,"" ""scoping review..."").",Ambas,Não,"Title: Issues and Research Fields of Medical Robotics: A Review
Abstract: The goal for collaborative robots has always driven advancements in robotic technology, especially in the manufacturing sector. However, this is not the case in service sectors, especially in the health sector. Thus, this lack of focus has now opened more room for the design and development of service robots that can be used in the health sector to help patients with ailments, cognitive problems, and disabilities. There is currently a global effort towards the development of new products and the use of robotic medical devices and computer-assisted systems. However, the major problem has been the lack of a thorough and systematic review of robotic research into disease and epidemiology, especially from a technology perspective. Also, medical robots are increasingly being used in healthcare to perform a variety of functions that improve patient care. This scoping review is aimed at discovering the types of robots used in healthcare and where they are deployed. Moreover, the current study is an overview of various forms of robotic technology and its uses the healthcare industry. The considered technologies are the products of a partnership between the healthcare sector and academia. They demonstrate the research and testing that are necessary for the service of robot development before they can be employed in practical applications and service scenarios. The discussion also focused on the upcoming research areas in robotic systems as well as some important technologies necessary for human-robot collaboration, such as wireless sensor networks, big data, and artificial intelligence. © 2023 Elsevier B.V., All rights reserved.
"
Scopus,"Jacob, F.; Grosse, E.H.; Morana, S.; König, C.J.",Picking with a robot colleague: A systematic literature review and evaluation of technology acceptance in human–robot collaborative warehouses,2023,10.1016/j.cie.2023.109262,"Just-in-time delivery, shorter product life cycles, demographic changes, and the Covid-19 pandemic have driven the industrial application of collaborative robots in warehouses. These robots work alongside humans, increasing their productivity and relieving them of repetitive or strenuous tasks. However, human workers can be reluctant to collaborate with robots owing to certain fears; for example, they may be concerned about job loss, stress, expected effort, or risk to physical integrity. These concerns can negatively impact the acceptance of human–robot collaboration (HRC). As the literature on this topic is fragmented, this study analyzes HRC acceptance in warehouses based on the Unified Theory of Acceptance and Use of Technology. We identify, classify, and analyze studies examining HRC acceptance in warehouses using a systematic literature review methodology. A framework is established to guide the analysis of performance expectancy, effort expectancy, (perceived) occupational safety, psychosocial, and legal and privacy factors. The results indicate the importance of corporate infrastructure and consideration of cognitive factors in particular. The findings of this study will support future research on HRC in warehouses and provide guidance for managers regarding HRC applicability. © 2023 Elsevier B.V., All rights reserved.",Acceptance; Cobot; Human–Robot Collaboration; Systematic Literature Review; Warehousing 4.0,Não,Não,Igual,"Despite targeting logistics warehouses and human-robot collaboration, the study is a systematic literature review rather than an empirical or design study, which violates EC4.",Justification: Fails (IC3) and meets (EC4). (EC4) Type of Publication: The title explicitly states this is a systematic literature review.,Ambas,Não,"Title: Picking with a robot colleague: A systematic literature review and evaluation of technology acceptance in human–robot collaborative warehouses
Abstract: Just-in-time delivery, shorter product life cycles, demographic changes, and the Covid-19 pandemic have driven the industrial application of collaborative robots in warehouses. These robots work alongside humans, increasing their productivity and relieving them of repetitive or strenuous tasks. However, human workers can be reluctant to collaborate with robots owing to certain fears; for example, they may be concerned about job loss, stress, expected effort, or risk to physical integrity. These concerns can negatively impact the acceptance of human–robot collaboration (HRC). As the literature on this topic is fragmented, this study analyzes HRC acceptance in warehouses based on the Unified Theory of Acceptance and Use of Technology. We identify, classify, and analyze studies examining HRC acceptance in warehouses using a systematic literature review methodology. A framework is established to guide the analysis of performance expectancy, effort expectancy, (perceived) occupational safety, psychosocial, and legal and privacy factors. The results indicate the importance of corporate infrastructure and consideration of cognitive factors in particular. The findings of this study will support future research on HRC in warehouses and provide guidance for managers regarding HRC applicability. © 2023 Elsevier B.V., All rights reserved.
"
Scopus,"Gervasi, R.; Barravecchia, F.; Mastrogiacomo, L.; Franceschini, F.",Applications of affective computing in human-robot interaction: State-of-art and challenges for manufacturing,2023,10.1177/09544054221121888,"The introduction of collaborative robots aims to make production more flexible, promoting a greater interaction between humans and robots also from physical point of view. However, working closely with a robot may lead to the creation of stressful situations for the operator, which can negatively affect task performance. In Human-Robot Interaction (HRI), robots are expected to be socially intelligent, that is, capable of understanding and reacting accordingly to human social and affective clues. This ability can be exploited implementing affective computing, which concerns the development of systems able to recognize, interpret, process, and simulate human affects. Social intelligence is essential for robots to establish a natural interaction with people in several contexts, including the manufacturing sector with the emergence of Industry 5.0. In order to take full advantage of the human-robot collaboration, the robotic system should be able to perceive the psycho-emotional and mental state of the operator through different sensing modalities (e.g. facial expressions, body language, voice, or physiological signals) and to adapt its behavior accordingly. The development of socially intelligent collaborative robots in the manufacturing sector can lead to a symbiotic human-robot collaboration, arising several research challenges that still need to be addressed. The goals of this paper are the following: (i) providing an overview of affective computing implementation in HRI; (ii) analyzing the state-of-art on this topic in different application contexts (e.g. healthcare, service applications, and manufacturing); (iii) highlighting research challenges for the manufacturing sector. © 2023 Elsevier B.V., All rights reserved.",affective computing; collaborative robot; human affective state; Human-robot interaction; Industry 5.0; manufacturing,Sim,Não,Diferente,"Focuses on applied HRI in manufacturing, emphasizing affective computing as an enabling technology for cobots. This aligns with IC1 (industrial HRC) and IC2 (technology and HRI focus), providing practical implications.","Justification: Fails (IC3) and meets (EC4). (EC4) Type of Publication: The abstract states its goals are to provide an overview and analyze the state-of-art on the topic, clearly indicating a review paper.",LLM 2,Sim,"Title: Applications of affective computing in human-robot interaction: State-of-art and challenges for manufacturing
Abstract: The introduction of collaborative robots aims to make production more flexible, promoting a greater interaction between humans and robots also from physical point of view. However, working closely with a robot may lead to the creation of stressful situations for the operator, which can negatively affect task performance. In Human-Robot Interaction (HRI), robots are expected to be socially intelligent, that is, capable of understanding and reacting accordingly to human social and affective clues. This ability can be exploited implementing affective computing, which concerns the development of systems able to recognize, interpret, process, and simulate human affects. Social intelligence is essential for robots to establish a natural interaction with people in several contexts, including the manufacturing sector with the emergence of Industry 5.0. In order to take full advantage of the human-robot collaboration, the robotic system should be able to perceive the psycho-emotional and mental state of the operator through different sensing modalities (e.g. facial expressions, body language, voice, or physiological signals) and to adapt its behavior accordingly. The development of socially intelligent collaborative robots in the manufacturing sector can lead to a symbiotic human-robot collaboration, arising several research challenges that still need to be addressed. The goals of this paper are the following: (i) providing an overview of affective computing implementation in HRI; (ii) analyzing the state-of-art on this topic in different application contexts (e.g. healthcare, service applications, and manufacturing); (iii) highlighting research challenges for the manufacturing sector. © 2023 Elsevier B.V., All rights reserved.
"
Scopus,"Ochoa, O.; Mendez, E.; Lucas-Dophe, C.; Luna-Sanchez, J.A.; Soto-Herrera, V.H.; Olivera-Guzman, D.; Pérez, M.; Lugo-Del-Real, E.; Ayala-Garcia, I.N.; González, A.",Flexible Human-Robot Interaction: Collaborative Robot Integrated with Hand Tracking,2023,10.1109/COMRob60035.2023.10349712,"The rising demand for adaptable and user-friendly forms of interaction in the field of manufacturing and assembly tasks has led to increased attention on human-robot collaboration. Collaborative robots (cobots) have emerged as a promising solution to address this demand. In this study, we propose the integration and application of cobots along with a pre-trained deep learning model to assist users in assembly activities, specifically part handover and storage. The human-robot interaction is facilitated through a hand tracking system that enables a close approach to the user's hand. Testing on the system yielded 99% accuracy. The incorporation of deep learning models in cobot applications holds substantial potential for industry transformation, with implications spanning manufacturing, healthcare, and assistive technologies. This research serves as a compelling proof of concept, showcasing the effective implementation of deep learning models to facilitate close human-robot interactions. © 2024 Elsevier B.V., All rights reserved.",Collaborative robot; Deep learning; Human-robot collaboration,Sim,Sim,Igual,"Describes integration of hand-tracking technology in HRC systems, indicating applied design and implementation aspects. Fits IC1–IC2, emphasizing intuitive interfaces and real-world applicability.","Justification: Strong alignment with all ICs. (IC1) Focus/Theme: Collaborative robot (cobot) for assembly activities in manufacturing (Implied as an industrial task). (IC2) Research Questions: Provides data on practical application (part handover, storage) and HRI analysis (hand tracking, close interaction), and enabling technologies (Deep Learning model). (IC3/IC4/IC5) Type/Language/Time: Peer-reviewed article, English, Published 2024. Meets all ICs.",Ambas,Sim,"Title: Flexible Human-Robot Interaction: Collaborative Robot Integrated with Hand Tracking
Abstract: The rising demand for adaptable and user-friendly forms of interaction in the field of manufacturing and assembly tasks has led to increased attention on human-robot collaboration. Collaborative robots (cobots) have emerged as a promising solution to address this demand. In this study, we propose the integration and application of cobots along with a pre-trained deep learning model to assist users in assembly activities, specifically part handover and storage. The human-robot interaction is facilitated through a hand tracking system that enables a close approach to the user's hand. Testing on the system yielded 99% accuracy. The incorporation of deep learning models in cobot applications holds substantial potential for industry transformation, with implications spanning manufacturing, healthcare, and assistive technologies. This research serves as a compelling proof of concept, showcasing the effective implementation of deep learning models to facilitate close human-robot interactions. © 2024 Elsevier B.V., All rights reserved.
"
Scopus,"Doulgeri, Z.; Dimeas, F.",Human-Robot collaboration: Unlocking the potential for industrial applications,2023,,"Human-robot collaboration (HRC) is a widely studied research topic that investigates how humans and robots can work together and achieve a common goal. Over the past few years, HRC has created exciting new applications for robots that can revolutionize manufacturing and introduce them to entirely different domains such as healthcare and agriculture. It is an interdisciplinary research area comprising robotics, artificial intelligence, design and cognitive sciences. Industrial applications of human-robot collaboration involve collaborative robots which physically interact with humans in shared workspaces to complete tasks such as collaborative manipulation or object handovers. However, in industry to date, HRC has been adopted at a slower pace than expected as collaborative robots need to be safe for interaction with humans. At the same time, they need to be easily programmed by non-experts and to operate in an intelligent and adaptive way. In this book we present some of the latest state-of-the-art advances in the area of human-robot collaboration, aiming at future industrial applications. The book will be useful for advanced students, researchers, engineers, developers and entrepreneurs interested in human-robot collaboration research and technologies. © 2023 Elsevier B.V., All rights reserved.",,Não,Não,Igual,"Investigates collaborative robotics in industrial environments, focusing on potential benefits, implementation cases, and integration challenges—meeting IC1 (industrial) and IC2 (measured impacts and challenges).","Justification: Fails (IC4) and meets (EC4). (EC4) Type of Publication: The abstract explicitly states, ""In this book we present some of the latest state-of-the-art advances in the area,"" indicating this is a book or book chapter, which is excluded.",Ambas,Não,"Title: Human-Robot collaboration: Unlocking the potential for industrial applications
Abstract: Human-robot collaboration (HRC) is a widely studied research topic that investigates how humans and robots can work together and achieve a common goal. Over the past few years, HRC has created exciting new applications for robots that can revolutionize manufacturing and introduce them to entirely different domains such as healthcare and agriculture. It is an interdisciplinary research area comprising robotics, artificial intelligence, design and cognitive sciences. Industrial applications of human-robot collaboration involve collaborative robots which physically interact with humans in shared workspaces to complete tasks such as collaborative manipulation or object handovers. However, in industry to date, HRC has been adopted at a slower pace than expected as collaborative robots need to be safe for interaction with humans. At the same time, they need to be easily programmed by non-experts and to operate in an intelligent and adaptive way. In this book we present some of the latest state-of-the-art advances in the area of human-robot collaboration, aiming at future industrial applications. The book will be useful for advanced students, researchers, engineers, developers and entrepreneurs interested in human-robot collaboration research and technologies. © 2023 Elsevier B.V., All rights reserved.
"
Scopus,"Borboni, A.; Karna, K.V.V.; Elamvazhuthi, I.; Al-Quraishi, M.S.; Elango, E.; Ali, S.S.",The Expanding Role of Artificial Intelligence in Collaborative Robots for Industrial Applications: A Systematic Review of Recent Works,2023,10.3390/machines11010111,"A collaborative robot, or cobot, enables users to work closely with it through direct communication without the use of traditional barricades. Cobots eliminate the gap that has historically existed between industrial robots and humans while they work within fences. Cobots can be used for a variety of tasks, from communication robots in public areas and logistic or supply chain robots that move materials inside a building, to articulated or industrial robots that assist in automating tasks which are not ergonomically sound, such as assisting individuals in carrying large parts, or assembly lines. Human faith in collaboration has increased through human–robot collaboration applications built with dependability and safety in mind, which also enhances employee performance and working circumstances. Artificial intelligence and cobots are becoming more accessible due to advanced technology and new processor generations. Cobots are now being changed from science fiction to science through machine learning. They can quickly respond to change, decrease expenses, and enhance user experience. In order to identify the existing and potential expanding role of artificial intelligence in cobots for industrial applications, this paper provides a systematic literature review of the latest research publications between 2018 and 2022. It concludes by discussing various difficulties in current industrial collaborative robots and provides direction for future research. © 2023 Elsevier B.V., All rights reserved.",artificial intelligence; cobots; collaborative robots; deep learning; human–robot interaction; machine learning; reinforcement learning,Não,Não,Igual,"As a systematic review, it compiles previous research instead of contributing empirical data, excluded under EC4.",Justification: Fails (IC3) and meets (EC4). The title explicitly states this is a Systematic Review. (EC4) Type of Publication is excluded.,Ambas,Não,"Title: The Expanding Role of Artificial Intelligence in Collaborative Robots for Industrial Applications: A Systematic Review of Recent Works
Abstract: A collaborative robot, or cobot, enables users to work closely with it through direct communication without the use of traditional barricades. Cobots eliminate the gap that has historically existed between industrial robots and humans while they work within fences. Cobots can be used for a variety of tasks, from communication robots in public areas and logistic or supply chain robots that move materials inside a building, to articulated or industrial robots that assist in automating tasks which are not ergonomically sound, such as assisting individuals in carrying large parts, or assembly lines. Human faith in collaboration has increased through human–robot collaboration applications built with dependability and safety in mind, which also enhances employee performance and working circumstances. Artificial intelligence and cobots are becoming more accessible due to advanced technology and new processor generations. Cobots are now being changed from science fiction to science through machine learning. They can quickly respond to change, decrease expenses, and enhance user experience. In order to identify the existing and potential expanding role of artificial intelligence in cobots for industrial applications, this paper provides a systematic literature review of the latest research publications between 2018 and 2022. It concludes by discussing various difficulties in current industrial collaborative robots and provides direction for future research. © 2023 Elsevier B.V., All rights reserved.
"
Scopus,"Hameed, A.; Ordys, A.; Możaryn, J.; Sibilska-Mroziewicz, A.",Control System Design and Methods for Collaborative Robots: Review,2023,10.3390/app13010675,"Collaborative robots cooperate with humans to assist them in undertaking simple-to-complex tasks in several fields, including industry, education, agriculture, healthcare services, security, and space exploration. These robots play a vital role in the revolution of Industry 4.0, which defines new standards of manufacturing and the organization of products in the industry. Incorporating collaborative robots in the workspace improves efficiency, but it also introduces several safety risks. Effective safety measures then become indispensable to ensure safe and robust interaction. This paper presents the review of low-level control methodologies of a collaborative robot to assess the current status of human–robot collaboration over the last decade. First, we discuss the classification of human–robot collaboration, architectures of systems and the complex requirements on control strategies. The most commonly used control approaches were presented and discussed. Several methods of control, reported in industrial applications, are elaborated upon with a prime focus on HR-collaborative assembly operations. Since the physical HRC is a critical control problem for the co-manipulation task, this article identifies key control challenges such as the prediction of human intentions, safety, and human-caused disturbances in motion synchronization; the proposed solutions were analyzed afterwards. The discussion at the end of the paper summarizes the features of the control systems that should be incorporated within the systematic framework to allow the execution of a robotic task from global task planning to low-level control implementation for safe and robust interactions. © 2023 Elsevier B.V., All rights reserved.",collaborative control; collaborative robots; human–robot collaboration; literature review; modeling and control methodologies,Não,Não,Igual,"Explicitly a review article, not an applied or experimental study. Therefore, excluded according to EC4.",Justification: Fails (IC3) and meets (EC4). The title explicitly states this is a Review. (EC4) Type of Publication is excluded.,Ambas,Não,"Title: Control System Design and Methods for Collaborative Robots: Review
Abstract: Collaborative robots cooperate with humans to assist them in undertaking simple-to-complex tasks in several fields, including industry, education, agriculture, healthcare services, security, and space exploration. These robots play a vital role in the revolution of Industry 4.0, which defines new standards of manufacturing and the organization of products in the industry. Incorporating collaborative robots in the workspace improves efficiency, but it also introduces several safety risks. Effective safety measures then become indispensable to ensure safe and robust interaction. This paper presents the review of low-level control methodologies of a collaborative robot to assess the current status of human–robot collaboration over the last decade. First, we discuss the classification of human–robot collaboration, architectures of systems and the complex requirements on control strategies. The most commonly used control approaches were presented and discussed. Several methods of control, reported in industrial applications, are elaborated upon with a prime focus on HR-collaborative assembly operations. Since the physical HRC is a critical control problem for the co-manipulation task, this article identifies key control challenges such as the prediction of human intentions, safety, and human-caused disturbances in motion synchronization; the proposed solutions were analyzed afterwards. The discussion at the end of the paper summarizes the features of the control systems that should be incorporated within the systematic framework to allow the execution of a robotic task from global task planning to low-level control implementation for safe and robust interactions. © 2023 Elsevier B.V., All rights reserved.
"
Scopus,"Adriaensen, A.; Berx, N.; Pintelon, L.; Costantino, F.; Di Gravio, G.; Patriarca, R.",Interdependence Analysis in collaborative robot applications from a joint cognitive functional perspective,2022,10.1016/j.ergon.2022.103320,"This paper sets up a framework to assess co-agency in human-robot interactions, and applies it specifically to the socio-technical safety analysis of collaborative robots. We also examine to what extent the concept of Situation Awareness can be applied to assess collaborative robots as efficient team members in socio-technical systems. We explain some theoretical concerns with traditional concepts of Situation Awareness and defend why the concept of Joint Cognitive Systems, which maps the conceptualization of the cognitive system onto the work system as a whole, is best suited for issues of distributed cognition and controllability in human-robot interaction. Thereafter we present a five-step methodology specifically conceived for cobot applications serving the aim of goal coordination between multiple agents by functional interactions. The proposed framework merges two existing safety and resilience analysis methods, being the Functional Resonance Analysis Method and Interdependence Analysis. These methods are used in combination to assess shared control in safe and efficient human-robot interaction from a systems-thinking perspective. This allows to describe the systemic conditions for Distributed Situation Awareness in terms of observable system interactions and as an emergent object of distributed cognition. Instead of looking at undesirable safety outcomes, we have imposed the focus of co-agency as the unit of analysis in line with the Joint Cognitive Systems perspective. The theoretical insights from this paper are additionally applied to a hypothetical but credible demonstration case study with collaborative warehouse robots. © 2022 Elsevier B.V., All rights reserved.",Cobots; Collaborative robots; FRAM; Interdependence Analysis; JCS; Situation awareness; Socio-technical analysis,Sim,Sim,Igual,Examines the cognitive and functional interdependence between humans and cobots in real applications. The analysis suggests an applied framework validated within collaborative contexts—meeting IC1–IC2.,"Justification: Strong alignment with all ICs. (IC1) Focus/Theme: Collaborative robots (cobots) with a demonstration case study on collaborative warehouse robots (logistics). (IC2) Research Questions: Focuses on HRI analysis (co-agency, joint cognitive systems, safety) and implementation challenges. (IC3/IC4/IC5) Type/Language/Time: Peer-reviewed article, English, Published 2022. Meets all ICs.",LLM 2,Sim,"Title: Interdependence Analysis in collaborative robot applications from a joint cognitive functional perspective
Abstract: This paper sets up a framework to assess co-agency in human-robot interactions, and applies it specifically to the socio-technical safety analysis of collaborative robots. We also examine to what extent the concept of Situation Awareness can be applied to assess collaborative robots as efficient team members in socio-technical systems. We explain some theoretical concerns with traditional concepts of Situation Awareness and defend why the concept of Joint Cognitive Systems, which maps the conceptualization of the cognitive system onto the work system as a whole, is best suited for issues of distributed cognition and controllability in human-robot interaction. Thereafter we present a five-step methodology specifically conceived for cobot applications serving the aim of goal coordination between multiple agents by functional interactions. The proposed framework merges two existing safety and resilience analysis methods, being the Functional Resonance Analysis Method and Interdependence Analysis. These methods are used in combination to assess shared control in safe and efficient human-robot interaction from a systems-thinking perspective. This allows to describe the systemic conditions for Distributed Situation Awareness in terms of observable system interactions and as an emergent object of distributed cognition. Instead of looking at undesirable safety outcomes, we have imposed the focus of co-agency as the unit of analysis in line with the Joint Cognitive Systems perspective. The theoretical insights from this paper are additionally applied to a hypothetical but credible demonstration case study with collaborative warehouse robots. © 2022 Elsevier B.V., All rights reserved.
"
Scopus,"Jefroy, N.; Azarian, M.; Yu, H.",Moving from Industry 4.0 to Industry 5.0: What Are the Implications for Smart Logistics?,2022,10.3390/logistics6020026,"Background: Given the importance of human centricity, resilience, and sustainability, the emerging concept of Industry 5.0 has pushed forward the research frontier of the technology-focused Industry 4.0 to a smart and harmonious socio-economic transition driven by both humans and tech-nologies, where the role of the human in the technological transformation is predominantly focused on. Several studies discuss the impacts of disruptive technologies on smart logistics operations in Industry 4.0. However, since Industry 5.0 is a new concept and still in its infancy, its implications for smart logistics have not been discussed. Methods: To fill this gap, this paper presents a comparative bibliometric analysis to show the connection and differences between Industry 4.0 and Industry 5.0 and their implications for smart logistics. A thorough content analysis is then given to illustrate the features of smart logistics in Industry 5.0 concerning four areas, namely intelligent automation, intelligent devices, intelligent systems, and intelligent materials. Results: The results show that, compared with Industry 4.0, the research of smart logistics in Industry 5.0 puts more focus on the interaction between humans and technology in the digital transition, with the increasing adoption of collaborative technologies, e.g., human-machine systems, collaborative robots, and human-robot collaboration. Conclusions: Finally, a research agenda is proposed for identifying future research directions of smart logistics in Industry 5.0. © 2024 Elsevier B.V., All rights reserved.",bibliometric analysis; Industry 4.0; Industry 5.0; literature review; smart logistics; sustainable logistics,Sim,Não,Diferente,Discusses smart logistics with a focus on human-centric collaboration and integration of cobots under Industry 5.0 principles. The context (logistics) and collaboration focus fulfill IC1–IC2.,"Justification: Fails (IC3) and meets (EC4). The methodology includes a comparative bibliometric analysis and a thorough content analysis to illustrate features, indicating a review or survey type of publication focused on conceptual/trend analysis rather than primary empirical/technical research.",LLM 2,Sim,"Title: Moving from Industry 4.0 to Industry 5.0: What Are the Implications for Smart Logistics?
Abstract: Background: Given the importance of human centricity, resilience, and sustainability, the emerging concept of Industry 5.0 has pushed forward the research frontier of the technology-focused Industry 4.0 to a smart and harmonious socio-economic transition driven by both humans and tech-nologies, where the role of the human in the technological transformation is predominantly focused on. Several studies discuss the impacts of disruptive technologies on smart logistics operations in Industry 4.0. However, since Industry 5.0 is a new concept and still in its infancy, its implications for smart logistics have not been discussed. Methods: To fill this gap, this paper presents a comparative bibliometric analysis to show the connection and differences between Industry 4.0 and Industry 5.0 and their implications for smart logistics. A thorough content analysis is then given to illustrate the features of smart logistics in Industry 5.0 concerning four areas, namely intelligent automation, intelligent devices, intelligent systems, and intelligent materials. Results: The results show that, compared with Industry 4.0, the research of smart logistics in Industry 5.0 puts more focus on the interaction between humans and technology in the digital transition, with the increasing adoption of collaborative technologies, e.g., human-machine systems, collaborative robots, and human-robot collaboration. Conclusions: Finally, a research agenda is proposed for identifying future research directions of smart logistics in Industry 5.0. © 2024 Elsevier B.V., All rights reserved.
"
Scopus,"Bermúdez i Badia, S.; Silva, P.A.; Branco, D.; Pinto, A.; Carvalho, C.; Menezes, P.; Almeida, J.; Pilacinski, A.",Virtual Reality for Safe Testing and Development in Collaborative Robotics: Challenges and Perspectives,2022,10.3390/electronics11111726,"Collaborative robots (cobots) could help humans in tasks that are mundane, dangerous or where direct human contact carries risk. Yet, the collaboration between humans and robots is severely limited by the aspects of the safety and comfort of human operators. In this paper, we outline the use of extended reality (XR) as a way to test and develop collaboration with robots. We focus on virtual reality (VR) in simulating collaboration scenarios and the use of cobot digital twins. This is specifically useful in situations that are difficult or even impossible to safely test in real life, such as dangerous scenarios. We describe using XR simulations as a means to evaluate collaboration with robots without putting humans at harm. We show how an XR setting enables combining human behavioral data, subjective self-reports, and biosignals signifying human comfort, stress and cognitive load during collaboration. Several works demonstrate XR can be used to train human operators and provide them with augmented reality (AR) interfaces to enhance their performance with robots. We also provide a first attempt at what could become the basis for a human–robot collaboration testing framework, specifically for designing and testing factors affecting human– robot collaboration. The use of XR has the potential to change the way we design and test cobots, and train cobot operators, in a range of applications: from industry, through healthcare, to space operations. © 2022 Elsevier B.V., All rights reserved.",acceptability; augmented reality; collaborative robotics; extended reality; uncanny valley; user experience; virtual reality,Sim,Não,Diferente,"Presents applied use of VR environments for safety testing of collaborative robots. While addressing challenges, it targets real-world development, fitting IC1 (collaborative robotics) and IC2 (implementation and safety analysis).","Justification: Fails (IC2) and meets (EC3). While the theme (cobots in healthcare/industry) is right, the core focus is on the methodology of using Virtual Reality for simulating collaboration scenarios. The abstract emphasizes using simulations for testing. (EC3) Theoretical/Abstract Focus: This is a study about a simulation/testing methodology (VR/XR), without presenting the actual application data, case study, or validated prototype results of a cobot in a target sector.",LLM 2,Sim,"Title: Virtual Reality for Safe Testing and Development in Collaborative Robotics: Challenges and Perspectives
Abstract: Collaborative robots (cobots) could help humans in tasks that are mundane, dangerous or where direct human contact carries risk. Yet, the collaboration between humans and robots is severely limited by the aspects of the safety and comfort of human operators. In this paper, we outline the use of extended reality (XR) as a way to test and develop collaboration with robots. We focus on virtual reality (VR) in simulating collaboration scenarios and the use of cobot digital twins. This is specifically useful in situations that are difficult or even impossible to safely test in real life, such as dangerous scenarios. We describe using XR simulations as a means to evaluate collaboration with robots without putting humans at harm. We show how an XR setting enables combining human behavioral data, subjective self-reports, and biosignals signifying human comfort, stress and cognitive load during collaboration. Several works demonstrate XR can be used to train human operators and provide them with augmented reality (AR) interfaces to enhance their performance with robots. We also provide a first attempt at what could become the basis for a human–robot collaboration testing framework, specifically for designing and testing factors affecting human– robot collaboration. The use of XR has the potential to change the way we design and test cobots, and train cobot operators, in a range of applications: from industry, through healthcare, to space operations. © 2022 Elsevier B.V., All rights reserved.
"
Scopus,"Felip, J.; Gonzalez-Aguirre, D.; Nachman, L.",Intuitive & Efficient Human-robot Collaboration via Real-time Approximate Bayesian Inference,2022,10.1109/IROS47612.2022.9982251,"The combination of collaborative robots and end-to-end AI, promises flexible automation of human tasks in factories and warehouses. However, such promise seems a few breakthroughs away. In the meantime, humans and cobots will collaborate helping each other. For these collaborations to be effective and safe, robots need to model, predict and exploit human's intents for responsive decision making processes. Approximate Bayesian Computation (ABC) is approach to perform probabilistic predictions upon uncertain quantities. ABC includes priors conveniently, leverages sampling algorithms for inference and is flexible to benefit from complex models, e.g. via simulators. However, ABC is known to be computationally too intensive to run at interactive frame rates required for effective human-robot collaboration tasks. In this paper, we formulate human intent prediction as an ABC problem and describe two key performance innovations which allow computations at interactive rates. Our real-world experiments with a collaborative robot set-up, demonstrate the viability of our proposed approach. Experimental evaluations convey the advantages and value of human intent prediction for packing cooperative tasks. Qualitative results show how anticipating human's intent improves human-robot collaboration without compromising safety. Quantitative task fluency metrics confirm the qualitative claims. © 2025 Elsevier B.V., All rights reserved.",,Sim,Sim,Igual,"Proposes a real-time probabilistic inference method to improve cobot collaboration efficiency, validated in dynamic interaction scenarios. Satisfies IC1 (human–robot interaction) and IC2 (enabling technologies).","Justification: Strong alignment with all ICs. (IC1) Focus/Theme: Collaborative robot (cobot) for cooperative tasks in factories and warehouses (logistics and industry). (IC2) Research Questions: Provides data on practical applications, HRI analysis (intent prediction), and enabling technologies (ABC/Bayesian Inference). The abstract mentions real-world experiments and quantitative/qualitative results. (IC3/IC4/IC5) Type/Language/Time: Peer-reviewed article, English, Published 2025. Meets all ICs.",Ambas,Sim,"Title: Intuitive & Efficient Human-robot Collaboration via Real-time Approximate Bayesian Inference
Abstract: The combination of collaborative robots and end-to-end AI, promises flexible automation of human tasks in factories and warehouses. However, such promise seems a few breakthroughs away. In the meantime, humans and cobots will collaborate helping each other. For these collaborations to be effective and safe, robots need to model, predict and exploit human's intents for responsive decision making processes. Approximate Bayesian Computation (ABC) is approach to perform probabilistic predictions upon uncertain quantities. ABC includes priors conveniently, leverages sampling algorithms for inference and is flexible to benefit from complex models, e.g. via simulators. However, ABC is known to be computationally too intensive to run at interactive frame rates required for effective human-robot collaboration tasks. In this paper, we formulate human intent prediction as an ABC problem and describe two key performance innovations which allow computations at interactive rates. Our real-world experiments with a collaborative robot set-up, demonstrate the viability of our proposed approach. Experimental evaluations convey the advantages and value of human intent prediction for packing cooperative tasks. Qualitative results show how anticipating human's intent improves human-robot collaboration without compromising safety. Quantitative task fluency metrics confirm the qualitative claims. © 2025 Elsevier B.V., All rights reserved.
"
Scopus,"Pinto, A.; Sousa, S.; Simões, A.; Santos, J.","A Trust Scale for Human-Robot Interaction: Translation, Adaptation, and Validation of a Human Computer Trust Scale",2022,10.1155/2022/6437441,"Recently there has been an increasing demand for technologies (automated and intelligent machines) that brings benefits to organizations and society. Similar to the widespread use of personal computers in the past, today's needs are towards facilitating human-machine technology appropriation, especially in highly risky and regulated industries like robotics, manufacturing, automation, military, finance, or healthcare. In this context, trust can be used as a critical element to instruct how human-machine interaction should occur. Considering the context-dependency and multidimensional trust, this study seeks to find a way to measure the effects of perceived trust in a collaborative robot (cobot), regardless of its literal credibility as a real person. This article aims at translating, adapting, and validating a Human-Computer Trust Scale (HCTM) in human-robot interaction (HRI) context and its application to cobots. The Human-Robot Interaction Trust Scale (HRITS) involved 239 participants and included eleven items. The 2nd order CFA with a general factor called ""trust""have proven to be empirically robust (CFI=.94; TLI=.93; SRMR=.04; and RMSEA=.05) [CR=.84; AVE=.58, and MaxRH=.92]; results indicated a good measurement of the general factor trust, and the model satisfied the criteria for measure trust. An analysis of the differences in perceptions of trust by gender was conducted using a t-test. This analysis showed that statistical differences by gender exist (p=.04). This study's results allowed for a better understanding of trust in HRI, specifically regarding cobots. The validation of a Portuguese scale for trust assessment in HRI can give a valuable contribution to designing collaborative environments between humans and robots. © 2022 Elsevier B.V., All rights reserved.",,Sim,Sim,Igual,"Empirical validation of a trust measurement tool in HRI. Though not limited to a single domain, it provides applied human-factor evaluation in robotics, satisfying IC2 (HRI analysis).","Justification: Strong alignment with all ICs. (IC1) Focus/Theme: Collaborative robot (cobot) trust in high-risk sectors including healthcare and manufacturing (Implied context). (IC2) Research Questions: Provides data on HRI analysis (Trust Scale validation) with a significant number of participants. (IC3/IC4/IC5) Type/Language/Time: Peer-reviewed article, English, Published 2022. Meets all ICs.",Ambas,Sim,"Title: A Trust Scale for Human-Robot Interaction: Translation, Adaptation, and Validation of a Human Computer Trust Scale
Abstract: Recently there has been an increasing demand for technologies (automated and intelligent machines) that brings benefits to organizations and society. Similar to the widespread use of personal computers in the past, today's needs are towards facilitating human-machine technology appropriation, especially in highly risky and regulated industries like robotics, manufacturing, automation, military, finance, or healthcare. In this context, trust can be used as a critical element to instruct how human-machine interaction should occur. Considering the context-dependency and multidimensional trust, this study seeks to find a way to measure the effects of perceived trust in a collaborative robot (cobot), regardless of its literal credibility as a real person. This article aims at translating, adapting, and validating a Human-Computer Trust Scale (HCTM) in human-robot interaction (HRI) context and its application to cobots. The Human-Robot Interaction Trust Scale (HRITS) involved 239 participants and included eleven items. The 2nd order CFA with a general factor called ""trust""have proven to be empirically robust (CFI=.94; TLI=.93; SRMR=.04; and RMSEA=.05) [CR=.84; AVE=.58, and MaxRH=.92]; results indicated a good measurement of the general factor trust, and the model satisfied the criteria for measure trust. An analysis of the differences in perceptions of trust by gender was conducted using a t-test. This analysis showed that statistical differences by gender exist (p=.04). This study's results allowed for a better understanding of trust in HRI, specifically regarding cobots. The validation of a Portuguese scale for trust assessment in HRI can give a valuable contribution to designing collaborative environments between humans and robots. © 2022 Elsevier B.V., All rights reserved.
"
Scopus,,"5th EAI International Conference on Management of Manufacturing Systems, MMS 2020",2022,,"The proceedings contain 38 papers. The special focus in this conference is on Management of Manufacturing Systems. The topics include: Possibilities of Using Data Envelope Analysis for Quality Management of Public Services at the Local Level; Methodology Proposal for Proactive Detection of Network Anomalies in e-Learning System During the COVID-19 Scenario; The Effect of Non-Wi-Fi Interference on the Throughput of IEEE 802.11 Based Wireless Networks; assistive Technologies in Function of Visual Impaired Person Mobility Increases in Smart Shopping Environment; small Parts Recognition by Convolutional Neural Networks with Implementation to Virtual Reality Devices for Assisted Assembly Tasks; dynamic Measurement of the Surface After Process of Turning with Application of Laser Displacement Sensors; Design and Evaluation of Production of a Robotic Angle Arm for Collaborative Robot Using the WorkNC CAM Application; Use Cases for C-ITS Testing of Autonomous Vehicles; development of Optical Networking for5G Smart Infrastructures; technology Transfer and Foreign Direct Investment in the Light of Innovation Management on the Example of Poland; enhancing the Aircraft Maintenance Management Process for Increasing Safety; architecture of IoT System for Smart Monitoring and Management of Traffic Noise; the Benefits of Open Data in Urban Traffic Network; case Study in Logistics: Purchase Planning of Goods for Large Retail Chains, Taking into Account Sale Marketing Campaigns; methods of Increasing Warehouse Capacity in an Enterprise: Case Study; the Use of Telematics Systems in Transport and Forwarding Management; mobile Picking Robots: A First Study of the Effects of Human-Robot Interactions in Conventional Order Picking Systems. © 2021 Elsevier B.V., All rights reserved.",,Não,Não,Igual,"Represents an entire conference proceedings rather than a specific study. Lacks title/abstract for evaluation and fails IC1–IC2, excluded under EC4 (not an article).","Justification: Fails (IC3) and meets (EC4). This is a set of Conference Proceedings (a collection of papers). While the individual papers within it might qualify, the proceedings themselves are a collection/volume and are typically excluded under (EC4) (often overlapping with ""Books"" or ""Book Chapters"" in SLR exclusions). Moreover, the entry is a list of topics, not a single article's abstract.",Ambas,Não,"Title: 5th EAI International Conference on Management of Manufacturing Systems, MMS 2020
Abstract: The proceedings contain 38 papers. The special focus in this conference is on Management of Manufacturing Systems. The topics include: Possibilities of Using Data Envelope Analysis for Quality Management of Public Services at the Local Level; Methodology Proposal for Proactive Detection of Network Anomalies in e-Learning System During the COVID-19 Scenario; The Effect of Non-Wi-Fi Interference on the Throughput of IEEE 802.11 Based Wireless Networks; assistive Technologies in Function of Visual Impaired Person Mobility Increases in Smart Shopping Environment; small Parts Recognition by Convolutional Neural Networks with Implementation to Virtual Reality Devices for Assisted Assembly Tasks; dynamic Measurement of the Surface After Process of Turning with Application of Laser Displacement Sensors; Design and Evaluation of Production of a Robotic Angle Arm for Collaborative Robot Using the WorkNC CAM Application; Use Cases for C-ITS Testing of Autonomous Vehicles; development of Optical Networking for5G Smart Infrastructures; technology Transfer and Foreign Direct Investment in the Light of Innovation Management on the Example of Poland; enhancing the Aircraft Maintenance Management Process for Increasing Safety; architecture of IoT System for Smart Monitoring and Management of Traffic Noise; the Benefits of Open Data in Urban Traffic Network; case Study in Logistics: Purchase Planning of Goods for Large Retail Chains, Taking into Account Sale Marketing Campaigns; methods of Increasing Warehouse Capacity in an Enterprise: Case Study; the Use of Telematics Systems in Transport and Forwarding Management; mobile Picking Robots: A First Study of the Effects of Human-Robot Interactions in Conventional Order Picking Systems. © 2021 Elsevier B.V., All rights reserved.
"
Scopus,"Gbouna, Z.V.; Pang, G.; Yang, G.; Hou, Z.; Lv, H.; Yu, Z.; Pang, Z.",User-Interactive Robot Skin with Large-Area Scalability for Safer and Natural Human-Robot Collaboration in Future Telehealthcare,2021,10.1109/JBHI.2021.3082563,"With the fourth revolution of healthcare, i.e., Healthcare 4.0, collaborative robotics is spilling out from traditional manufacturing and will blend into human living or working environments to deliver care services, especially telehealthcare. Because of the frequent and seamless interaction between robots and care recipients, it poses several challenges that require careful consideration: 1) the ability of the human to collaborate with the robots in a natural manner; and 2) the safety of the human collaborating with the robot. In this regard, we have proposed a proximity sensing solution based on the self-capacitive technology to provide an extended sense of touch for collaborative robots, allowing approach and contact measurement to enhance safe and natural human-robot collaboration. The modular design of our solution enables it to scale up to form a large-area sensing system. The sensing solution is proposed to work in two operation modes: the interaction mode and the safety mode. In the interaction mode, utilizing the ability of the sensor to localize the point of action, gesture command is used for robot manipulation. In the safety mode, the sensor enables the robot to actively avoid obstacles. © 2022 Elsevier B.V., All rights reserved.",Collaborative robots; healthcare 4.0; interactivity; robot skin; safety; telehealthcare,Sim,Sim,Igual,"Applied research on tactile sensor technology for telehealthcare cobots, enabling safer HRI. Aligns strongly with IC1 (healthcare) and IC2 (implementation technology).","Justification: Strong alignment with all ICs. (IC1) Focus/Theme: Collaborative robotics in telehealthcare (healthcare). (IC2) Research Questions: Focuses on enabling technologies (proximity sensing/robot skin) and HRI analysis (safety, natural collaboration). (IC3/IC4/IC5) Type/Language/Time: Peer-reviewed article, English, Published 2022. Meets all ICs.",Ambas,Sim,"Title: User-Interactive Robot Skin with Large-Area Scalability for Safer and Natural Human-Robot Collaboration in Future Telehealthcare
Abstract: With the fourth revolution of healthcare, i.e., Healthcare 4.0, collaborative robotics is spilling out from traditional manufacturing and will blend into human living or working environments to deliver care services, especially telehealthcare. Because of the frequent and seamless interaction between robots and care recipients, it poses several challenges that require careful consideration: 1) the ability of the human to collaborate with the robots in a natural manner; and 2) the safety of the human collaborating with the robot. In this regard, we have proposed a proximity sensing solution based on the self-capacitive technology to provide an extended sense of touch for collaborative robots, allowing approach and contact measurement to enhance safe and natural human-robot collaboration. The modular design of our solution enables it to scale up to form a large-area sensing system. The sensing solution is proposed to work in two operation modes: the interaction mode and the safety mode. In the interaction mode, utilizing the ability of the sensor to localize the point of action, gesture command is used for robot manipulation. In the safety mode, the sensor enables the robot to actively avoid obstacles. © 2022 Elsevier B.V., All rights reserved.
"
Scopus,"Wagner-Hartl, V.; Pohling, K.; Rössler, M.; Strobel, S.; Maag, S.",Attitudes Towards Human-Robot Collaboration and the Impact of the COVID-19 Pandemic,2021,10.1007/978-3-030-90176-9_38,"It is expected that human-robot collaboration will increase in the future. Some people are already experiencing this in their working life, but other people are still skeptical about it. The COVID-19 pandemic has brought new challenges to the world’s population and has a strong impact on our everyday working life. The question arises, whether the perceived involvement in the current situation as well as the occupational field influence the attitudes towards human-robot collaboration. Overall, 54 men, 45 women and 1 non-binary (N = 100) aged between 18 and 71 years (M = 29.87, SD = 14.00) participated in an exploratory online study. The results of the study show that the participants’ attitudes towards the use of collaborative robots in the three different categories assembly, logistics and cleaning were rather positive. Furthermore, assembly and logistics tasks were assessed as significant more conceivable for human-robot collaboration than cleaning tasks. Interestingly, participants that were more concerned about the COVID-19 pandemic assessed the use of collaborative robots overall significant more positive than other participants did. Attitude differences due to the different occupational fields of the participants did not reach the level of significance. In addition, the participants described different functions in which they could imagine collaborative robots in the three categories assembly, logistics and cleaning. The results of the presented exploratory study shall help to get more insight in this important future field. © 2021 Elsevier B.V., All rights reserved.",COVID-19 pandemic; Human-robot collaboration; Occupational fields,Sim,Sim,Igual,"Empirical study analyzing human attitudes toward cobot adoption in workplaces during COVID-19, providing measured data (IC2) and focusing on collaborative environments (IC1).","Justification: Strong alignment with all ICs. (IC1) Focus/Theme: Collaborative robots (cobots) in logistics and assembly (industrial/manufacturing context). (IC2) Research Questions: Provides data on HRI analysis (attitudes, perception) using an exploratory online study with quantitative results. (IC3/IC4/IC5) Type/Language/Time: Peer-reviewed article, English, Published 2021. Meets all ICs.",Ambas,Sim,"Title: Attitudes Towards Human-Robot Collaboration and the Impact of the COVID-19 Pandemic
Abstract: It is expected that human-robot collaboration will increase in the future. Some people are already experiencing this in their working life, but other people are still skeptical about it. The COVID-19 pandemic has brought new challenges to the world’s population and has a strong impact on our everyday working life. The question arises, whether the perceived involvement in the current situation as well as the occupational field influence the attitudes towards human-robot collaboration. Overall, 54 men, 45 women and 1 non-binary (N = 100) aged between 18 and 71 years (M = 29.87, SD = 14.00) participated in an exploratory online study. The results of the study show that the participants’ attitudes towards the use of collaborative robots in the three different categories assembly, logistics and cleaning were rather positive. Furthermore, assembly and logistics tasks were assessed as significant more conceivable for human-robot collaboration than cleaning tasks. Interestingly, participants that were more concerned about the COVID-19 pandemic assessed the use of collaborative robots overall significant more positive than other participants did. Attitude differences due to the different occupational fields of the participants did not reach the level of significance. In addition, the participants described different functions in which they could imagine collaborative robots in the three categories assembly, logistics and cleaning. The results of the presented exploratory study shall help to get more insight in this important future field. © 2021 Elsevier B.V., All rights reserved.
"
Scopus,"Karabegović, I.; Banjanović-Mehmedović, L.","Industrial robots: Design, applications and technology",2020,,"Industrial Robots: Design, Applications and Technology is an essential reference source that explores the fundamentals of kinematics, dynamics and industrial robot control as well as a new generation of industrial robots, the collaborative robots or cobots. The tendency in Industry 4.0 towards the mass customisation of products, shorter product cycles and quality demands has led to the introduction of collaborative robot's systems capable of learning and working hand-in-hand with humans. Collaborative robots in the industry target the enhancement of production efficiency by combining the best of human operators and the industrial robots' accuracy, speed and reliability. The advances in smart sensors, artificial intelligence, digital twin, cyber-physical systems and the adoption of exoskeletons in industrial applications have opened new possibilities for technological progress in manufacturing, which led to efficient and flexible factories. This requires individuals to be educated in trends that are now focused on the design, monitoring and control of smart production processes. Featuring coverage on a wide range of topics such as new trends in human-robot collaboration, advanced vision technology and artificial intelligence, as well as application of industry robots in metal and wood industry, this book is ideally designed for electrical engineers, mechanical engineers, manufacturers, supply chain managers, logistics specialists, investors, managers, policymakers, production scientists, researchers, academicians and students at the postgraduate level. © 2022 Elsevier B.V., All rights reserved.",,Não,Não,Igual,"Focuses on traditional industrial robots (non-collaborative, single-task), violating EC1 (single-task, fixed robots). No human collaboration or contextual fit.","Justification: Fails (IC3) and meets (EC4). The title and abstract describe this as an ""essential reference source"" and a ""book"" that covers fundamentals, design, and applications across a wide range of topics. (EC4) Type of Publication excludes books.",Ambas,Não,"Title: Industrial robots: Design, applications and technology
Abstract: Industrial Robots: Design, Applications and Technology is an essential reference source that explores the fundamentals of kinematics, dynamics and industrial robot control as well as a new generation of industrial robots, the collaborative robots or cobots. The tendency in Industry 4.0 towards the mass customisation of products, shorter product cycles and quality demands has led to the introduction of collaborative robot's systems capable of learning and working hand-in-hand with humans. Collaborative robots in the industry target the enhancement of production efficiency by combining the best of human operators and the industrial robots' accuracy, speed and reliability. The advances in smart sensors, artificial intelligence, digital twin, cyber-physical systems and the adoption of exoskeletons in industrial applications have opened new possibilities for technological progress in manufacturing, which led to efficient and flexible factories. This requires individuals to be educated in trends that are now focused on the design, monitoring and control of smart production processes. Featuring coverage on a wide range of topics such as new trends in human-robot collaboration, advanced vision technology and artificial intelligence, as well as application of industry robots in metal and wood industry, this book is ideally designed for electrical engineers, mechanical engineers, manufacturers, supply chain managers, logistics specialists, investors, managers, policymakers, production scientists, researchers, academicians and students at the postgraduate level. © 2022 Elsevier B.V., All rights reserved.
"
IEE,Masashi Hamaya,Learning task-parametrized assistive strategies for exoskeleton robots by multi-task reinforcement learning,2017,10.1109/ICRA.2017.7989695,"Recent studies suggest that reinforcement learning has great potential for generating assistive strategies in exoskeletons through physical interactions between a user and a robot. Previous methods focused on a task-specific assistive strategy, where for every single task (situation/context), the user needs to interact with a robot to learn an appropriate assistive strategy. Therefore, the learned strategies cannot be generalized for a new task. Since the sampling cost is expensive for such human-in-the-loop systems as exoskeletons, generalization must be enabled. In this paper, we propose to learn task-parametrized assistive strategies for exoskeleton robots. Our method employs an assistive strategy, which depends on the task parameter and the state variable, that can be learned from multiple sets of human-robot interaction data across different tasks and generalized even for an unseen task, given the task parameter without additional learning. To alleviate the user's burden in the learning process across multiple tasks, we exploit a data-efficient multi-task reinforcement learning framework. To verify the effectiveness of our method, we developed an experimental platform with an exoskeleton robot. We conducted a series of experiments whose experimental results show that our method can learn such a task-parametrized assistive strategy and be generalized for unseen tasks to reduce the user's electromyography signals (EMGs) during tasks.","Exoskeletons
,
Learning (artificial intelligence)
,
Electromyography
,
Robot kinematics
,
Training
,
Robot sensing systems",Sim,Sim,Igual,"The study clearly aligns with inclusion criteria because it focuses on reinforcement learning applied in a robotics context (exoskeleton robots) and proposes a learning-based approach to generate and generalize assistive strategies. It is directly about multi-task RL with human-robot interaction and evaluating learned policies. There is no indication in the title or abstract that violates typical exclusion criteria (it is not purely theoretical without evaluation, not biological/medical non-computational, not unrelated to RL, not opinion based etc.). It presents experimentation with an exoskeleton platform, human-in-the-loop data, and uses RL to learn strategies that generalize. Therefore, it fits as a relevant primary study.","The study meets IC1 (exoskeleton robots) and IC2 (multi-task reinforcement learning). However, it fails to meet IC3.

The abstract's entire focus is on the effectiveness and generalization of the reinforcement learning algorithm (the ""assistive strategy""). It discusses data efficiency, generalization to unseen tasks, and validation via EMG signals. It does not mention the software architecture, the development framework, testing methodologies, or the implementation challenges associated with this human-in-the-loop system.

Therefore, the study is excluded as it meets EC1 (focuses exclusively on the algorithmic contribution).",Ambas,Sim,"Title: Learning task-parametrized assistive strategies for exoskeleton robots by multi-task reinforcement learning
Abstract: Recent studies suggest that reinforcement learning has great potential for generating assistive strategies in exoskeletons through physical interactions between a user and a robot. Previous methods focused on a task-specific assistive strategy, where for every single task (situation/context), the user needs to interact with a robot to learn an appropriate assistive strategy. Therefore, the learned strategies cannot be generalized for a new task. Since the sampling cost is expensive for such human-in-the-loop systems as exoskeletons, generalization must be enabled. In this paper, we propose to learn task-parametrized assistive strategies for exoskeleton robots. Our method employs an assistive strategy, which depends on the task parameter and the state variable, that can be learned from multiple sets of human-robot interaction data across different tasks and generalized even for an unseen task, given the task parameter without additional learning. To alleviate the user's burden in the learning process across multiple tasks, we exploit a data-efficient multi-task reinforcement learning framework. To verify the effectiveness of our method, we developed an experimental platform with an exoskeleton robot. We conducted a series of experiments whose experimental results show that our method can learn such a task-parametrized assistive strategy and be generalized for unseen tasks to reduce the user's electromyography signals (EMGs) during tasks.
"
ACM,"Zand, Manizheh; Wood, Sally; Davoudi, Fatemeh; Kyrarini, Maria",Cognitive Fatigue Assessment for Human-Robot Collaboration: Review & Open Challenges,2025,10.1145/3733155.3736596,"As Human Robot Collaboration (HRC) technologies continue to advance, robots are increasingly being deployed to assist in various settings, including manufacturing, healthcare, and home environments. A critical aspect of designing safe and adaptable HRC systems is the ability to assess and monitor an individual’s Cognitive Fatigue (CF) during interactions with robots. This is especially important in ensuring safe and effective environments, as fluctuations in CF can affect both performance and safety. Although prior research has explored cognitive workload and fatigue, a significant gap exists in understanding how to effectively measure and manage CF in real-time during HRC. This paper reviews current technologies for CF assessment in HRC systems, examining self-reported assessments, cognitive activity induction, physiological sensors, and behavioral analysis. Furthermore, it investigates the safety and effectiveness of assistive robots in supporting individuals with Activities of Daily Living (ADL), highlighting key challenges in detecting and responding to CF. This paper can potentially guide future research on developing robotics for long-term care that focuses on enhancing human well-being and autonomy within HRC systems.","Human-Robot Collaboration, Cognitive Fatigue, Assistive Robotics, Activities of Daily Living",Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.","O critério de exclusão EC4 é atendido. O título e o resumo indicam explicitamente que este artigo é uma revisão (""Review"", ""This paper reviews current technologies...""). Artigos de revisão devem ser excluídos.",Ambas,Não,"Title: Cognitive Fatigue Assessment for Human-Robot Collaboration: Review & Open Challenges
Abstract: As Human Robot Collaboration (HRC) technologies continue to advance, robots are increasingly being deployed to assist in various settings, including manufacturing, healthcare, and home environments. A critical aspect of designing safe and adaptable HRC systems is the ability to assess and monitor an individual’s Cognitive Fatigue (CF) during interactions with robots. This is especially important in ensuring safe and effective environments, as fluctuations in CF can affect both performance and safety. Although prior research has explored cognitive workload and fatigue, a significant gap exists in understanding how to effectively measure and manage CF in real-time during HRC. This paper reviews current technologies for CF assessment in HRC systems, examining self-reported assessments, cognitive activity induction, physiological sensors, and behavioral analysis. Furthermore, it investigates the safety and effectiveness of assistive robots in supporting individuals with Activities of Daily Living (ADL), highlighting key challenges in detecting and responding to CF. This paper can potentially guide future research on developing robotics for long-term care that focuses on enhancing human well-being and autonomy within HRC systems.
"
ACM,"Buason, Patipon; Joochim, Orapadee",Deep Learning-Based Multimodal Intention Retrieval for Human-Robot Collaboration,2024,10.1145/3702468.3702475,"The world is on the cusp of entering the Fifth Industrial Revolution, which will focus on integrating human creativity with the efficiency, intelligence, and precision of machines. To achieve this objective, it is necessary to have a support systems capable of handling data from diverse sources to obtain comprehensive information across all dimensions. These systems must also be adaptable to changing environments and conditions. These characteristics are the goals of this research. We proposed a system called multimodal intention retrieval, which utilizes a multimodal fusion network to transform input data from any modality into vector representations. These representations will be used in calculations for classification purposes through the k-nearest neighbor algorithm. The resulting classes are used to label the intentions of data stored in a database, enabling the system to respond to user queries, regardless of the modality of the query input. The results demonstrate the potential for integrating this system with traditional robot control systems.","Deep learning, Human-robot collaboration, Information retrieval, Multimodal fusion",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"O critério de inclusão IC1 não é satisfeito. O resumo descreve um sistema de tecnologia geral para HRC, mas não fornece contexto de aplicação nos setores-alvo (logística, saúde ou serviços de campo).",Ambas,Não,"Title: Deep Learning-Based Multimodal Intention Retrieval for Human-Robot Collaboration
Abstract: The world is on the cusp of entering the Fifth Industrial Revolution, which will focus on integrating human creativity with the efficiency, intelligence, and precision of machines. To achieve this objective, it is necessary to have a support systems capable of handling data from diverse sources to obtain comprehensive information across all dimensions. These systems must also be adaptable to changing environments and conditions. These characteristics are the goals of this research. We proposed a system called multimodal intention retrieval, which utilizes a multimodal fusion network to transform input data from any modality into vector representations. These representations will be used in calculations for classification purposes through the k-nearest neighbor algorithm. The resulting classes are used to label the intentions of data stored in a database, enabling the system to respond to user queries, regardless of the modality of the query input. The results demonstrate the potential for integrating this system with traditional robot control systems.
"
ACM,"Campagna, Giulio; Rehm, Matthias",A Systematic Review of Trust Assessments in Human–Robot Interaction,2025,10.1145/3706123,"The integration of robots into daily life has increased significantly, spanning applications from social-care to industrial settings with collaborative robots. Ensuring a safe, secure environment and equitable workload distribution in human-robot collaborations is crucial. Trust is a key factor in these environments, essential for enhancing collaboration and achieving tasks while maintaining safety. Under-trusting robots can hinder productivity, while over-trusting them can lead to accidents. A comprehensive literature review of 100 publications from 2003 to 2023 analyzes trust and its influencing factors in industrial and social-care contexts. Findings reveal that in industrial settings, robot-related factors are more influential, whereas in social-care, human and environmental factors play a significant role. Furthermore, the review delves into gauging trust through observable behavior, while also exploring various trust evaluation methodologies. Results show that trust can be gauged through human behaviors, physical cues, and physiological measurements. Concerning trust evaluation methodologies, traditional questionnaires have limitations, opening new opportunities for machine learning and sensor-based approaches to real-time trust evaluation, as trust is a dynamic cognitive value that evolves over time. Notably, 97% of the reviewed articles were published in the last decade, underscoring a growing interest in human–robot interaction and trust within the scientific community.","Trust in Human-Robot Interaction, Human-Robot Collaboration, Literature Review",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"O critério de exclusão EC4 é atendido. O título identifica claramente o artigo como uma ""Systematic Review"" (Revisão Sistemática), e o resumo confirma que se trata de uma ""comprehensive literature review"" (revisão abrangente da literatura), que é um tipo de publicação excluído.",Ambas,Não,"Title: A Systematic Review of Trust Assessments in Human–Robot Interaction
Abstract: The integration of robots into daily life has increased significantly, spanning applications from social-care to industrial settings with collaborative robots. Ensuring a safe, secure environment and equitable workload distribution in human-robot collaborations is crucial. Trust is a key factor in these environments, essential for enhancing collaboration and achieving tasks while maintaining safety. Under-trusting robots can hinder productivity, while over-trusting them can lead to accidents. A comprehensive literature review of 100 publications from 2003 to 2023 analyzes trust and its influencing factors in industrial and social-care contexts. Findings reveal that in industrial settings, robot-related factors are more influential, whereas in social-care, human and environmental factors play a significant role. Furthermore, the review delves into gauging trust through observable behavior, while also exploring various trust evaluation methodologies. Results show that trust can be gauged through human behaviors, physical cues, and physiological measurements. Concerning trust evaluation methodologies, traditional questionnaires have limitations, opening new opportunities for machine learning and sensor-based approaches to real-time trust evaluation, as trust is a dynamic cognitive value that evolves over time. Notably, 97% of the reviewed articles were published in the last decade, underscoring a growing interest in human–robot interaction and trust within the scientific community.
"
ACM,"Wongjirad, Thanatchai; Chansangdee, Supawadee; Arun, Onnalin; Phoobuaphet, Chinnaphan; Joochim, Orapadee",Development of a Mobile Manipulator Robot for Human-Robot Collaboration,2024,10.1145/3702468.3702471,"The aim of this research is to study and develop a Mobile Manipulator Robot that can work collaboratively with humans in industrial settings for reducing workload and enhance human safety. The study and development are divided into three aspects: safety, motion control of the robot's base, and manipulation capability of the robot arm. In terms of safety, the objective is to improve the safety efficiency of human-robot collaboration during work. For the motion control of the robot's base, the goal is to enable the robot to move accurately on uneven working surfaces using Mecanum Wheels. As for the manipulation capability of the robot arm, the objective is to expand the working area by utilizing the OpenMANIPULATOR-P robotic arm. All three components of the system are integrated and communicate with each other under the ROS2 framework. This research aims to contribute to the field of robotics by developing a Mobile Manipulator Robot that can effectively collaborate with humans in industrial environments, thereby reducing the workload and increasing safety.","Mecanum Wheel, Mobile Manipulator Robot, OpenMANIPULATOR-P, ROS2",Não,Sim,Diferente,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"O estudo está fortemente alinhado com todos os critérios de inclusão. IC1: Discute um ""Mobile Manipulator Robot"" colaborativo para ""industrial settings"" (ambientes industriais), o que se alinha com logística/serviços de campo. IC2: Foca no ""Development"" (desenvolvimento) e ""motion control"" (tecnologias facilitadoras). IC5: O ano (2024) está dentro do período. Nenhum critério de exclusão é atendido.",LLM 2,Sim,"Title: Development of a Mobile Manipulator Robot for Human-Robot Collaboration
Abstract: The aim of this research is to study and develop a Mobile Manipulator Robot that can work collaboratively with humans in industrial settings for reducing workload and enhance human safety. The study and development are divided into three aspects: safety, motion control of the robot's base, and manipulation capability of the robot arm. In terms of safety, the objective is to improve the safety efficiency of human-robot collaboration during work. For the motion control of the robot's base, the goal is to enable the robot to move accurately on uneven working surfaces using Mecanum Wheels. As for the manipulation capability of the robot arm, the objective is to expand the working area by utilizing the OpenMANIPULATOR-P robotic arm. All three components of the system are integrated and communicate with each other under the ROS2 framework. This research aims to contribute to the field of robotics by developing a Mobile Manipulator Robot that can effectively collaborate with humans in industrial environments, thereby reducing the workload and increasing safety.
"
ACM,"Lee, Hee Rin; Fox, Sarah; Cheon, EunJeong; Shorey, Samantha","Minding the Stop-gap: Attending to the ""Temporary,"" Unplanned, and Added Labor of Human-Robot Collaboration in Context",2025,Não disponível,"HRI scholars envision a future of work where human-robot collaboration brings mutual gains: organizations benefit from increased efficiency and productivity, and laborers benefit when tasks are redistributed between humans and robots based on their respective strengths. Yet, ironically, this collaboration in real-world contexts can lead to the opposite effect --- workers' efficiency may decrease due to the additional tasks they must undertake to manage unexpected errors caused by robots. This ''stop-gap'' labor, often viewed as temporary and naturally manageable over time, can have significant and persistent impacts on workers. Drawing from observations across multiple robot deployment sites, this paper highlights the overlooked burden of this labor, challenging idealized visions of seamless human-robot collaboration. We argue that attending to stop-gap labor presents an opportunity for the HRI community to make genuine improvements for workers as primary stakeholders within complex socio-economic networks.","case study, human-robot collaboration, inequality, labor, social justice, stop-gap labor, wage gap, workers",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"O estudo não atende ao Critério de Inclusão (IC1). O título/resumo não indica claramente um foco em robôs multifuncionais OU colaborativos (cobots) DENTRO dos setores alvo (logística, saúde, serviços de campo).",Ambas,Não,"Title: Minding the Stop-gap: Attending to the ""Temporary,"" Unplanned, and Added Labor of Human-Robot Collaboration in Context
Abstract: HRI scholars envision a future of work where human-robot collaboration brings mutual gains: organizations benefit from increased efficiency and productivity, and laborers benefit when tasks are redistributed between humans and robots based on their respective strengths. Yet, ironically, this collaboration in real-world contexts can lead to the opposite effect --- workers' efficiency may decrease due to the additional tasks they must undertake to manage unexpected errors caused by robots. This ''stop-gap'' labor, often viewed as temporary and naturally manageable over time, can have significant and persistent impacts on workers. Drawing from observations across multiple robot deployment sites, this paper highlights the overlooked burden of this labor, challenging idealized visions of seamless human-robot collaboration. We argue that attending to stop-gap labor presents an opportunity for the HRI community to make genuine improvements for workers as primary stakeholders within complex socio-economic networks.
"
ACM,"Gargioni, Luigi",Emerging approaches to human-robot collaboration in healthcare,2024,10.1145/3656650.3656747,"Collaborative robots can enhance productivity and efficiency in healthcare. This PhD project aims to investigate new methods and tools for effective interaction with these robots, focusing on programming techniques accessible to domain experts without a background in computer science or robotics. Automating repetitive tasks can allow healthcare professionals to dedicate more attention to critical procedures. For instance, this technology can enhance therapy efficiency and personalized medicine preparation, benefiting patient outcomes. The research will investigate the use of Large Language Models to simplify and optimize robot task programming, reducing the need for technical expertise.","Collaborative Robots, End-User Development, Human-Robot Collaboration, Large Language Models",Sim,Sim,Igual,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.","O estudo está alinhado com todos os critérios de inclusão. Foca em robôs (colaborativos) em um setor alvo (logística/saúde/serviços de campo), foi publicado em 2024, e o resumo indica foco em (aplicação/impacto/HRI/tecnologias/desafios) (IC1, IC2, IC5). Não atende a nenhum critério de exclusão.",Ambas,Sim,"Title: Emerging approaches to human-robot collaboration in healthcare
Abstract: Collaborative robots can enhance productivity and efficiency in healthcare. This PhD project aims to investigate new methods and tools for effective interaction with these robots, focusing on programming techniques accessible to domain experts without a background in computer science or robotics. Automating repetitive tasks can allow healthcare professionals to dedicate more attention to critical procedures. For instance, this technology can enhance therapy efficiency and personalized medicine preparation, benefiting patient outcomes. The research will investigate the use of Large Language Models to simplify and optimize robot task programming, reducing the need for technical expertise.
"
ACM,"Zhang, Yan; Ratnayake, Tharaka Sachintha; Sew, Cherie; Knibbe, Jarrod; Goncalves, Jorge; Johal, Wafa",Can you pass that tool?: Implications of Indirect Speech in Physical Human-Robot Collaboration,2025,10.1145/3706598.3713780,"Indirect speech acts (ISAs) are a natural pragmatic feature of human communication, allowing requests to be conveyed implicitly while maintaining subtlety and flexibility. Although advancements in speech recognition have enabled natural language interactions with robots through direct, explicit commands—providing clarity in communication—the rise of large language models presents the potential for robots to interpret ISAs. However, empirical evidence on the effects of ISAs on human-robot collaboration (HRC) remains limited. To address this, we conducted a Wizard-of-Oz study (N=36), engaging a participant and a robot in collaborative physical tasks. Our findings indicate that robots capable of understanding ISAs significantly improve human’s perceived robot anthropomorphism, team performance, and trust. However, the effectiveness of ISAs is task- and context-dependent, thus requiring careful use. These results highlight the importance of appropriately integrating direct and indirect requests in HRC to enhance collaborative experiences and task performance.","Human-Robot Collaboration, Language Communication, Grounding, Lab Study",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"O estudo não atende ao Critério de Inclusão (IC1). O título/resumo não indica claramente um foco em robôs multifuncionais OU colaborativos (cobots) DENTRO dos setores alvo (logística, saúde, serviços de campo).",Ambas,Não,"Title: Can you pass that tool?: Implications of Indirect Speech in Physical Human-Robot Collaboration
Abstract: Indirect speech acts (ISAs) are a natural pragmatic feature of human communication, allowing requests to be conveyed implicitly while maintaining subtlety and flexibility. Although advancements in speech recognition have enabled natural language interactions with robots through direct, explicit commands—providing clarity in communication—the rise of large language models presents the potential for robots to interpret ISAs. However, empirical evidence on the effects of ISAs on human-robot collaboration (HRC) remains limited. To address this, we conducted a Wizard-of-Oz study (N=36), engaging a participant and a robot in collaborative physical tasks. Our findings indicate that robots capable of understanding ISAs significantly improve human’s perceived robot anthropomorphism, team performance, and trust. However, the effectiveness of ISAs is task- and context-dependent, thus requiring careful use. These results highlight the importance of appropriately integrating direct and indirect requests in HRC to enhance collaborative experiences and task performance.
"
ACM,"Alzahrani, Abdullah; Nasir, Jauwairia; Tayeb, Ahmad J.; Andr'{e}, Elisabeth; Ahmad, Muneeb I.",What Do the Face and Voice Reveal? Investigating Trust Dynamics During Human-Robot Interaction,2025,Não disponível,"Existing research has shown that vocal and non-vocal human cues correlate with human trust and distrust behaviours, suggesting their potential to measure human trust in robots in real-time. However, there is a lack of research in Human-Robot Interaction that integrates vocal and non-vocal cues into a comprehensive model to measure trust. This paper aims to estimate human trust in robots by examining vocal and non-vocal cues differences between trust and distrust states across multiple sessions of collaborative game-based HRI with 40 participants. Our analysis revealed that vocal and non-vocal human cues can indeed predict trust in HRI, with certain facial expressions, facial movements, and pitch being significant factors. Random Forest classifier achieved the highest accuracy (84%) in classifying trust states, with key features such as facial expressions (fear, angry), facial blendshapes (cheekSquintRight, jawRight), and vocal characteristics (Duration, Harmonicity std) being the most predictive of trust. These findings demonstrate the importance of combining vocal and non-vocal cues for accurate trust measurement and highlight the potential for real-time trust assessment in robotic systems.","human-robot interaction, measurement, real-time, trust, vocal and non-vocal behaviours",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"O estudo não atende ao Critério de Inclusão (IC1). O título/resumo não indica claramente um foco em robôs multifuncionais OU colaborativos (cobots) DENTRO dos setores alvo (logística, saúde, serviços de campo).",Ambas,Não,"Title: What Do the Face and Voice Reveal? Investigating Trust Dynamics During Human-Robot Interaction
Abstract: Existing research has shown that vocal and non-vocal human cues correlate with human trust and distrust behaviours, suggesting their potential to measure human trust in robots in real-time. However, there is a lack of research in Human-Robot Interaction that integrates vocal and non-vocal cues into a comprehensive model to measure trust. This paper aims to estimate human trust in robots by examining vocal and non-vocal cues differences between trust and distrust states across multiple sessions of collaborative game-based HRI with 40 participants. Our analysis revealed that vocal and non-vocal human cues can indeed predict trust in HRI, with certain facial expressions, facial movements, and pitch being significant factors. Random Forest classifier achieved the highest accuracy (84%) in classifying trust states, with key features such as facial expressions (fear, angry), facial blendshapes (cheekSquintRight, jawRight), and vocal characteristics (Duration, Harmonicity std) being the most predictive of trust. These findings demonstrate the importance of combining vocal and non-vocal cues for accurate trust measurement and highlight the potential for real-time trust assessment in robotic systems.
"
ACM,"Senft, Emmanuel; Hagenow, Michael; Radwin, Robert; Zinn, Michael; Gleicher, Michael; Mutlu, Bilge",Situated Live Programming for Human-Robot Collaboration,2021,10.1145/3472749.3474773,"We present situated live programming for human-robot collaboration, an approach that enables users with limited programming experience to program collaborative applications for human-robot interaction. Allowing end users, such as shop floor workers, to program collaborative robots themselves would make it easy to “retask” robots from one process to another, facilitating their adoption by small and medium enterprises. Our approach builds on the paradigm of trigger-action programming (TAP) by allowing end users to create rich interactions through simple trigger-action pairings. It enables end users to iteratively create, edit, and refine a reactive robot program while executing partial programs. This live programming approach enables the user to utilize the task space and objects by incrementally specifying situated trigger-action pairs, substantially lowering the barrier to entry for programming or reprogramming robots for collaboration. We instantiate situated live programming in an authoring system where users can create trigger-action programs by annotating an augmented video feed from the robot’s perspective and assign robot actions to trigger conditions. We evaluated this system in a study where participants (n = 10) developed robot programs for solving collaborative light-manufacturing tasks. Results showed that users with little programming experience were able to program HRC tasks in an interactive fashion and our situated live programming approach further supported individualized strategies and workflows. We conclude by discussing opportunities and limitations of the proposed approach, our system implementation, and our study and discuss a roadmap for expanding this approach to a broader range of tasks and applications.","end-user programming, human-robot collaboration, human-robot interaction, trigger-action programming",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"O estudo é excluído por focar em setores não-alvo (como militar, espacial, doméstico ou entretenimento) sem indicação clara de aplicabilidade aos setores de logística, saúde ou serviços de campo, violando o Critério de Exclusão (EC2).",Ambas,Não,"Title: Situated Live Programming for Human-Robot Collaboration
Abstract: We present situated live programming for human-robot collaboration, an approach that enables users with limited programming experience to program collaborative applications for human-robot interaction. Allowing end users, such as shop floor workers, to program collaborative robots themselves would make it easy to “retask” robots from one process to another, facilitating their adoption by small and medium enterprises. Our approach builds on the paradigm of trigger-action programming (TAP) by allowing end users to create rich interactions through simple trigger-action pairings. It enables end users to iteratively create, edit, and refine a reactive robot program while executing partial programs. This live programming approach enables the user to utilize the task space and objects by incrementally specifying situated trigger-action pairs, substantially lowering the barrier to entry for programming or reprogramming robots for collaboration. We instantiate situated live programming in an authoring system where users can create trigger-action programs by annotating an augmented video feed from the robot’s perspective and assign robot actions to trigger conditions. We evaluated this system in a study where participants (n = 10) developed robot programs for solving collaborative light-manufacturing tasks. Results showed that users with little programming experience were able to program HRC tasks in an interactive fashion and our situated live programming approach further supported individualized strategies and workflows. We conclude by discussing opportunities and limitations of the proposed approach, our system implementation, and our study and discuss a roadmap for expanding this approach to a broader range of tasks and applications.
"
ACM,"Elias, Alex; Galvez Trigo, Maria J.; Camacho-Villa, Carolina",Analyzing Previous Human-Robot Interaction Implementation in Agriculture: What Can We Learn from the Past?,2025,Não disponível,"With the recent shift from conventional industrial robots to more collaborative Human-Robot Interaction (HRI) robots within industries such as the agriculture sector, it has become essential to understand the challenges associated with the adoption of these robots to ensure a smooth integration with minimal resistance. As with all new technologies, there is often push-back when changing approaches and initiating new pathways within company operations, which can cause hesitation and even halt the adoption process. This paper draws from interviews with agricultural companies that have previously attempted to implement robots requiring direct human interaction, focusing on individuals within those companies who had decision-making capabilities during the implementation process. From these interviews, a set of action principles has been developed based on transferable knowledge found within the participating companies. The main results of this user study highlight that previous implementation attempts, whether positive or negative, influence future adoption. The study also identifies the multitude of barriers surrounding the agricultural sector's adoption of these technologies and suggests potential actions for companies to take to minimize the issues associated with implementing HRI robots. By identifying common successes and failures and contextualizing them for other companies to follow, this study aims to utilize lessons learned from past implementation attempts to shorten the learning curve and reduce hesitation in adopting HRI robots within the agricultural sector.","adoption, agriculture, hri, integration, interaction, phri",Não,Sim,Diferente,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"O estudo está alinhado com todos os critérios de inclusão. Foca em robôs (colaborativos) em um setor alvo (logística/saúde/serviços de campo), foi publicado em 2025, e o resumo indica foco em (aplicação/impacto/HRI/tecnologias/desafios) (IC1, IC2, IC5). Não atende a nenhum critério de exclusão.",LLM 2,Sim,"Title: Analyzing Previous Human-Robot Interaction Implementation in Agriculture: What Can We Learn from the Past?
Abstract: With the recent shift from conventional industrial robots to more collaborative Human-Robot Interaction (HRI) robots within industries such as the agriculture sector, it has become essential to understand the challenges associated with the adoption of these robots to ensure a smooth integration with minimal resistance. As with all new technologies, there is often push-back when changing approaches and initiating new pathways within company operations, which can cause hesitation and even halt the adoption process. This paper draws from interviews with agricultural companies that have previously attempted to implement robots requiring direct human interaction, focusing on individuals within those companies who had decision-making capabilities during the implementation process. From these interviews, a set of action principles has been developed based on transferable knowledge found within the participating companies. The main results of this user study highlight that previous implementation attempts, whether positive or negative, influence future adoption. The study also identifies the multitude of barriers surrounding the agricultural sector's adoption of these technologies and suggests potential actions for companies to take to minimize the issues associated with implementing HRI robots. By identifying common successes and failures and contextualizing them for other companies to follow, this study aims to utilize lessons learned from past implementation attempts to shorten the learning curve and reduce hesitation in adopting HRI robots within the agricultural sector.
"
ACM,"Zhao, Yi; Loke, Lian; Reinhardt, Dagmar",Evaluating a Design Toolkit for Human-Robot Collaboration in Close-Proximity Scenarios with Robotic Arms: Group Usability Tests with Postgraduate Interaction Design Students,2025,10.1145/3736422,"The rapid development of Industry 4.0 expands industrial robots from isolated machines to collaborative agents. Recognizing this paradigm shift, design educators are increasingly aware of the need to prepare students for effectively engaging with emerging robotic technologies and shaping future human-robot collaboration (HRC) projects. However, systematic and structured resources to guide these student designers in approaching, conceptualizing, prototyping and implementing HRC remain scarce. This article introduces a novel HRC design toolkit tailored for student designers that incorporates industrial constraints, role assignment, and guided communication into a step-by-step design process. Evaluations with 13 student interaction designers showed that the proposed toolkit clarified task flows, facilitated more intuitive robot behaviors, and bridged the gap between theoretical knowledge and practical implementations. Based on participants’ feedback, we improved the toolkit with simpler visual aids and improved guidance, further lowering the threshold for creating collaborative tasks. Finally, we discussed the applications and contributions of this revised design toolkit to industrial robotics education.","Design tool, Group Usability Test, Human-robot Collaboration, Industrial Robotics Education, Industry 4.0",Não,Sim,Diferente,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"O estudo está alinhado com todos os critérios de inclusão. Foca em robôs (colaborativos) em um setor alvo (logística/saúde/serviços de campo), foi publicado em 2025, e o resumo indica foco em (aplicação/impacto/HRI/tecnologias/desafios) (IC1, IC2, IC5). Não atende a nenhum critério de exclusão.",LLM 1,Sim,"Title: Evaluating a Design Toolkit for Human-Robot Collaboration in Close-Proximity Scenarios with Robotic Arms: Group Usability Tests with Postgraduate Interaction Design Students
Abstract: The rapid development of Industry 4.0 expands industrial robots from isolated machines to collaborative agents. Recognizing this paradigm shift, design educators are increasingly aware of the need to prepare students for effectively engaging with emerging robotic technologies and shaping future human-robot collaboration (HRC) projects. However, systematic and structured resources to guide these student designers in approaching, conceptualizing, prototyping and implementing HRC remain scarce. This article introduces a novel HRC design toolkit tailored for student designers that incorporates industrial constraints, role assignment, and guided communication into a step-by-step design process. Evaluations with 13 student interaction designers showed that the proposed toolkit clarified task flows, facilitated more intuitive robot behaviors, and bridged the gap between theoretical knowledge and practical implementations. Based on participants’ feedback, we improved the toolkit with simpler visual aids and improved guidance, further lowering the threshold for creating collaborative tasks. Finally, we discussed the applications and contributions of this revised design toolkit to industrial robotics education.
"
ACM,Não disponível,HRI '24: Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,2024,Não disponível,"

Welcome one and all to the 19th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)!

We are so pleased to re-welcome the HRI community to Boulder, Colorado, where HRI 2021 would have been held, had the COVID pandemic not interfered. Following up on the successful in-person conference held last year in Sweden, this year's theme is ""HRI in the Real World,"" and focuses on advances that aim to bring human-robot interaction out of the lab and into everyday life.

One aspect of this that we are very excited about is the introduction of a robot challenge to the conference activities, where teams from around the world will showcase their research and development via actual, interactive robots in the ""real world"" of an academic conference. It is our hope that this feature will grow and develop over the coming years into a staple of the HRI conference.

This year's HRI conference saw an impressive surge in global interest, with 352 full paper submissions from around the world, marking a significant 40% increase compared to the previous year. These papers were categorized under relevant thematic subcommittees and underwent a double-blind review process, a rebuttal phase, and selective shepherding by the HRI program committee. From this process, 87 outstanding papers (24.7%) were chosen for full presentation at the conference. Reflecting our joint sponsorship with IEEE and ACM, all accepted papers will be accessible in the ACM Digital Library and IEEE Xplore.
",Não disponível,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"O estudo é excluído porque o resumo ou título indica que é um 'review paper' ou 'survey' (neste caso, ""Companion"" de uma conferência, que se enquadra em EC4), o que viola o Critério de Exclusão (EC4).",Ambas,Não,"Title: HRI '24: Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction
Abstract: 

Welcome one and all to the 19th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)!

We are so pleased to re-welcome the HRI community to Boulder, Colorado, where HRI 2021 would have been held, had the COVID pandemic not interfered. Following up on the successful in-person conference held last year in Sweden, this year's theme is ""HRI in the Real World,"" and focuses on advances that aim to bring human-robot interaction out of the lab and into everyday life.

One aspect of this that we are very excited about is the introduction of a robot challenge to the conference activities, where teams from around the world will showcase their research and development via actual, interactive robots in the ""real world"" of an academic conference. It is our hope that this feature will grow and develop over the coming years into a staple of the HRI conference.

This year's HRI conference saw an impressive surge in global interest, with 352 full paper submissions from around the world, marking a significant 40% increase compared to the previous year. These papers were categorized under relevant thematic subcommittees and underwent a double-blind review process, a rebuttal phase, and selective shepherding by the HRI program committee. From this process, 87 outstanding papers (24.7%) were chosen for full presentation at the conference. Reflecting our joint sponsorship with IEEE and ACM, all accepted papers will be accessible in the ACM Digital Library and IEEE Xplore.

"
ACM,Não disponível,HRI '24: Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,2024,Não disponível,"

Welcome one and all to the 19th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)!

We are so pleased to re-welcome the HRI community to Boulder, Colorado, where HRI 2021 would have been held, had the COVID pandemic not interfered. Following up on the successful in-person conference held last year in Sweden, this year's theme is ""HRI in the Real World,"" and focuses on advances that aim to bring human-robot interaction out of the lab and into everyday life.

One aspect of this that we are very excited about is the introduction of a robot challenge to the conference activities, where teams from around the world will showcase their research and development via actual, interactive robots in the ""real world"" of an academic conference. It is our hope that this feature will grow and develop over the coming years into a staple of the HRI conference.

This year's HRI conference saw an impressive surge in global interest, with 352 full paper submissions from around the world, marking a significant 40% increase compared to the previous year. These papers were categorized under relevant thematic subcommittees and underwent a double-blind review process, a rebuttal phase, and selective shepherding by the HRI program committee. From this process, 87 outstanding papers (24.7%) were chosen for full presentation at the conference. Reflecting our joint sponsorship with IEEE and ACM, all accepted papers will be accessible in the ACM Digital Library and IEEE Xplore.
",Não disponível,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"O estudo é excluído porque o resumo ou título indica que é um 'review paper' ou 'survey' (neste caso, ""Proceedings"", que é uma coleção de resumos/artigos, não um artigo de pesquisa primária em si), o que viola o Critério de Exclusão (EC4).",Ambas,Não,"Title: HRI '24: Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction
Abstract: 

Welcome one and all to the 19th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)!

We are so pleased to re-welcome the HRI community to Boulder, Colorado, where HRI 2021 would have been held, had the COVID pandemic not interfered. Following up on the successful in-person conference held last year in Sweden, this year's theme is ""HRI in the Real World,"" and focuses on advances that aim to bring human-robot interaction out of the lab and into everyday life.

One aspect of this that we are very excited about is the introduction of a robot challenge to the conference activities, where teams from around the world will showcase their research and development via actual, interactive robots in the ""real world"" of an academic conference. It is our hope that this feature will grow and develop over the coming years into a staple of the HRI conference.

This year's HRI conference saw an impressive surge in global interest, with 352 full paper submissions from around the world, marking a significant 40% increase compared to the previous year. These papers were categorized under relevant thematic subcommittees and underwent a double-blind review process, a rebuttal phase, and selective shepherding by the HRI program committee. From this process, 87 outstanding papers (24.7%) were chosen for full presentation at the conference. Reflecting our joint sponsorship with IEEE and ACM, all accepted papers will be accessible in the ACM Digital Library and IEEE Xplore.

"
ACM,"van Den broek, Marike Koch; Moeslund, Thomas B.",What is Proactive Human-Robot Interaction? - A Review of a Progressive Field and Its Definitions,2024,10.1145/3650117,"During the past 15 years, an increasing amount of works have investigated proactive robotic behavior in relation to Human–Robot Interaction (HRI). The works engage with a variety of research topics and technical challenges. In this article, a review of the related literature identified through a structured block search is performed. Variations in the corpus are investigated, and a definition of Proactive HRI is provided. Furthermore, a taxonomy is proposed based on the corpus and exemplified through specific works. Finally, a selection of noteworthy observations is discussed.","Proactive human–robot interaction, robot initiative, robotic behavior, anticipatory behavior",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"O estudo é excluído porque o resumo ou título indica que é um 'review paper' ou 'survey', o que viola o Critério de Exclusão (EC4).",Ambas,Não,"Title: What is Proactive Human-Robot Interaction? - A Review of a Progressive Field and Its Definitions
Abstract: During the past 15 years, an increasing amount of works have investigated proactive robotic behavior in relation to Human–Robot Interaction (HRI). The works engage with a variety of research topics and technical challenges. In this article, a review of the related literature identified through a structured block search is performed. Variations in the corpus are investigated, and a definition of Proactive HRI is provided. Furthermore, a taxonomy is proposed based on the corpus and exemplified through specific works. Finally, a selection of noteworthy observations is discussed.
"
ACM,"Nagy, Timea Noemi; Rezaei Khavas, Zahra; Kotturu, Monish Reddy; Liefooghe, Baptist; Robinette, Paul; De Graaf, Maartje",A Robot Should Compensate for Its Mistakes: An Exploration of the Dynamics of Trust Violation and Repair Strategies in Human-Robot Collaboration,2025,10.1145/3767729,"Human-robot interactions are becoming prevalent in a varied number of fields, with trust being essential for efficient collaboration between humans and robots. Robots, just like humans, are bound to make mistakes leading to a violation of trust. Research investigating how to repair this broken trust has produced mixed results. This work investigates the effects of five communicative trust repair strategies (apology, denial, explanation, compensation, and silence) on participants’ trust in the robot, following trust violations of two kinds (moral and performance violation). In an online between-subjects experiment, participants engaged in a collaborative task with a robot that repeatedly committed trust violating acts and responded with a repair message. The findings indicate the higher severity of moral violations on moral trust and willingness to collaborate in the future, with compensation showing to be the most effective repair strategy, enhancing trust and willingness to collaborate, while also reducing discomfort. This work advances the understanding of trust relationships in collaborative HRI contexts.","Human-Robot Interaction, Collaborative HRI, Trust, Trust violation, Trust repair",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"O estudo não atende ao Critério de Inclusão (IC1). O título/resumo não indica claramente um foco em robôs multifuncionais OU colaborativos (cobots) DENTRO dos setores alvo (logística, saúde, serviços de campo).",Ambas,Não,"Title: A Robot Should Compensate for Its Mistakes: An Exploration of the Dynamics of Trust Violation and Repair Strategies in Human-Robot Collaboration
Abstract: Human-robot interactions are becoming prevalent in a varied number of fields, with trust being essential for efficient collaboration between humans and robots. Robots, just like humans, are bound to make mistakes leading to a violation of trust. Research investigating how to repair this broken trust has produced mixed results. This work investigates the effects of five communicative trust repair strategies (apology, denial, explanation, compensation, and silence) on participants’ trust in the robot, following trust violations of two kinds (moral and performance violation). In an online between-subjects experiment, participants engaged in a collaborative task with a robot that repeatedly committed trust violating acts and responded with a repair message. The findings indicate the higher severity of moral violations on moral trust and willingness to collaborate in the future, with compensation showing to be the most effective repair strategy, enhancing trust and willingness to collaborate, while also reducing discomfort. This work advances the understanding of trust relationships in collaborative HRI contexts.
"
ACM,"Almohamade, Shurook; Clark, John; Law, James",Continuous User Authentication for Human-Robot Collaboration,2021,10.1145/3465481.3470025,"Human-robot collaboration is on the increase and having a major impact on areas such as manufacturing, where the abilities of the human worker, augmented by those of the robot, bring increased flexibility and performance. However, close collaboration, including physical interaction, brings with it complex safety and security issues that were previously mitigated by human-robot segregation and isolated control networks. Exoskeletons pose a particularly interesting case whereby physical coupling of the user and robot is required throughout operation. We envisage the use of continuous authentication to exoskeletons, i.e. to ensure a user is who they claim to be, and that they have sufficient authority to operate the device for the duration of its use. In this paper we demonstrate such an approach to behavioural biometrics using data acquired through wearable sensors (hand manipulations recorded by a sensorised glove) while the user performs a selection of industrial tasks, including handling loads and inserting screws. The results show that the approach can discriminate between users with a low Equal Error Rate (EER; <3% in the worst case analysed). We believe that such an approach will also benefit other applications where wearables are used in robot control, such as in tele-operation.","Behavioural biometrics, Continuous authentication, Human-Robot Collaboration, User authentication",Não,Sim,Diferente,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"O estudo está alinhado com todos os critérios de inclusão. Foca em robôs (multifuncionais) em um setor alvo (logística/saúde/serviços de campo), foi publicado em 2021, e o resumo indica foco em (aplicação/impacto/HRI/tecnologias/desafios) (IC1, IC2, IC5). Não atende a nenhum critério de exclusão.",LLM 2,Sim,"Title: Continuous User Authentication for Human-Robot Collaboration
Abstract: Human-robot collaboration is on the increase and having a major impact on areas such as manufacturing, where the abilities of the human worker, augmented by those of the robot, bring increased flexibility and performance. However, close collaboration, including physical interaction, brings with it complex safety and security issues that were previously mitigated by human-robot segregation and isolated control networks. Exoskeletons pose a particularly interesting case whereby physical coupling of the user and robot is required throughout operation. We envisage the use of continuous authentication to exoskeletons, i.e. to ensure a user is who they claim to be, and that they have sufficient authority to operate the device for the duration of its use. In this paper we demonstrate such an approach to behavioural biometrics using data acquired through wearable sensors (hand manipulations recorded by a sensorised glove) while the user performs a selection of industrial tasks, including handling loads and inserting screws. The results show that the approach can discriminate between users with a low Equal Error Rate (EER; <3% in the worst case analysed). We believe that such an approach will also benefit other applications where wearables are used in robot control, such as in tele-operation.
"
ACM,"Schneiders, Eike",Non-Dyadic Human-Robot Interaction: Concepts and Interaction Techniques,2022,Não disponível,"With the increase in robot complexity and the diversity of domains in which we encounter robots, there is an increased need for research focusing on more varied aspects of human-robot interaction. While most research has focused on the dyadic interaction (one-to-one) between one human and one robot, we are currently observing a paradigm shift towards increased attention to HRI in non-dyadic systems. However, we still have limited knowledge of which interaction techniques work well for non-dyadic HRI combining human participants with multiple digital artefacts, including robots. We investigate what characterises non-dyadic HRI in various contexts, including the home and industry, and how the addition of robots affects how we interact in groups. This paper presents our research questions, preliminary results, and plans for future studies, thereby contributing to a better understanding of the concepts and interaction techniques in non-dyadic interaction in human-robot groups in various contexts.","human-human interaction, interaction techniques in groups with robots, non-dyadic hri",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"O estudo não atende ao Critério de Inclusão (IC1). O título/resumo não indica claramente um foco em robôs multifuncionais OU colaborativos (cobots) DENTRO dos setores alvo (logística, saúde, serviços de campo).",Ambas,Não,"Title: Non-Dyadic Human-Robot Interaction: Concepts and Interaction Techniques
Abstract: With the increase in robot complexity and the diversity of domains in which we encounter robots, there is an increased need for research focusing on more varied aspects of human-robot interaction. While most research has focused on the dyadic interaction (one-to-one) between one human and one robot, we are currently observing a paradigm shift towards increased attention to HRI in non-dyadic systems. However, we still have limited knowledge of which interaction techniques work well for non-dyadic HRI combining human participants with multiple digital artefacts, including robots. We investigate what characterises non-dyadic HRI in various contexts, including the home and industry, and how the addition of robots affects how we interact in groups. This paper presents our research questions, preliminary results, and plans for future studies, thereby contributing to a better understanding of the concepts and interaction techniques in non-dyadic interaction in human-robot groups in various contexts.
"
ACM,"Kumar, Kamlesh; Chen, Yuhao; Hu, Boyi; Luo, Yue",Assessing Human Visual Attention in Retail Human-Robot Interaction: A YOLOv8-Nano and Eye-Tracking Approach,2024,10.1145/3631700.3665195,"Objectives: This research delves into the dynamics of human-robot interaction (HRI) in retail environments, with a focus on robot detection from videos captured via an eye-tracking system. Methods: The study employs YOLOv8-nano model for real-time robot detection during grocery shopping tasks. All videos were processed using the YOLOv8 model to test inference speed while performing eye-tracking data analysis as a case study. Results: The YOLOv8 model demonstrated high precision in robot detection, with a mean average precision (mAP) of approximately 97.3% for Intersection over Union (IoU), 100% precision, and 99.87% recall for box detection. The model’s ability to process an average of 160.36 frames per second (FPS) confirmed its suitability for real-time applications. In the case study on the impact of a robot’s presence on human eye movements, the presence of a robot contributes to greater consistency in gaze fixation behavior, potentially leading to more predictable patterns of visual attention. Conclusion: The study’s findings contribute significantly to the design of safer and more efficient cobot systems. They provide a deeper understanding of human responses in real-world scenarios, which is crucial for the development of effective HRI systems.","Applied Computing, Human Robot Interaction, Object Detection, Physiological Patterns",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"O estudo não atende ao Critério de Inclusão (IC1). O título/resumo não indica claramente um foco em robôs multifuncionais OU colaborativos (cobots) DENTRO dos setores alvo (logística, saúde, serviços de campo).",Ambas,Não,"Title: Assessing Human Visual Attention in Retail Human-Robot Interaction: A YOLOv8-Nano and Eye-Tracking Approach
Abstract: Objectives: This research delves into the dynamics of human-robot interaction (HRI) in retail environments, with a focus on robot detection from videos captured via an eye-tracking system. Methods: The study employs YOLOv8-nano model for real-time robot detection during grocery shopping tasks. All videos were processed using the YOLOv8 model to test inference speed while performing eye-tracking data analysis as a case study. Results: The YOLOv8 model demonstrated high precision in robot detection, with a mean average precision (mAP) of approximately 97.3% for Intersection over Union (IoU), 100% precision, and 99.87% recall for box detection. The model’s ability to process an average of 160.36 frames per second (FPS) confirmed its suitability for real-time applications. In the case study on the impact of a robot’s presence on human eye movements, the presence of a robot contributes to greater consistency in gaze fixation behavior, potentially leading to more predictable patterns of visual attention. Conclusion: The study’s findings contribute significantly to the design of safer and more efficient cobot systems. They provide a deeper understanding of human responses in real-world scenarios, which is crucial for the development of effective HRI systems.
"
ACM,"Robinson, Nicole; Tidd, Brendan; Campbell, Dylan; Kuli'{c}, Dana; Corke, Peter",Robotic Vision for Human-Robot Interaction and Collaboration: A Survey and Systematic Review,2023,10.1145/3570731,"Robotic vision, otherwise known as computer vision for robots, is a critical process for robots to collect and interpret detailed information related to human actions, goals, and preferences, enabling robots to provide more useful services to people. This survey and systematic review presents a comprehensive analysis on robotic vision in human-robot interaction and collaboration (HRI/C) over the past 10 years. From a detailed search of 3,850 articles, systematic extraction and evaluation was used to identify and explore 310 papers in depth. These papers described robots with some level of autonomy using robotic vision for locomotion, manipulation, and/or visual communication to collaborate or interact with people. This article provides an in-depth analysis of current trends, common domains, methods and procedures, technical processes, datasets and models, experimental testing, sample populations, performance metrics, and future challenges. Robotic vision was often used in action and gesture recognition, robot movement in human spaces, object handover and collaborative actions, social communication, and learning from demonstration. Few high-impact and novel techniques from the computer vision field had been translated into HRI/C. Overall, notable advancements have been made on how to develop and deploy robots to assist people.","Robotic vision, computer vision, human-robot interaction, gesture recognition, robot movement in human spaces, object handover, collaborative actions, learning from demonstration, social communication",Não,Não,Igual,EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services). EC2 met: Focuses on excluded sectors (military, space, domestic, etc.) without clear application to target sectors. EC4 met: Study type appears to be excluded (e.g., review) based on title.",Ambas,Não,"Title: Robotic Vision for Human-Robot Interaction and Collaboration: A Survey and Systematic Review
Abstract: Robotic vision, otherwise known as computer vision for robots, is a critical process for robots to collect and interpret detailed information related to human actions, goals, and preferences, enabling robots to provide more useful services to people. This survey and systematic review presents a comprehensive analysis on robotic vision in human-robot interaction and collaboration (HRI/C) over the past 10 years. From a detailed search of 3,850 articles, systematic extraction and evaluation was used to identify and explore 310 papers in depth. These papers described robots with some level of autonomy using robotic vision for locomotion, manipulation, and/or visual communication to collaborate or interact with people. This article provides an in-depth analysis of current trends, common domains, methods and procedures, technical processes, datasets and models, experimental testing, sample populations, performance metrics, and future challenges. Robotic vision was often used in action and gesture recognition, robot movement in human spaces, object handover and collaborative actions, social communication, and learning from demonstration. Few high-impact and novel techniques from the computer vision field had been translated into HRI/C. Overall, notable advancements have been made on how to develop and deploy robots to assist people.
"
ACM,"Meissner, Antonia; Tr""{u}bswetter, Angelika; Conti-Kufner, Antonia S.; Schmidtler, Jonas",Friend or Foe? Understanding Assembly Workers’ Acceptance of Human-robot Collaboration,2020,10.1145/3399433,"Due to rising demands on productivity and flexibility, assembly processes are currently experiencing a substantial transformation. Workstations where humans and robots work closely together are becoming increasingly popular, as they provide major advantages compared to manual assembly and full automation. Yet, human-robot collaboration (HRC) can only be successful if the workforce is willing to accept it. How assembly workers perceive HRC still has to be properly investigated. An exploratory investigation using a Grounded Theory approach was conducted to identify factors that are likely to influence workers’ acceptance of introducing HRC at work. Seventeen workers with various levels of HRC experience from four different manufacturing companies were interviewed. Findings reveal that some workers perceive HRC as a threat, while others regard it as an opportunity. This perception seems to depend both on their thoughts and feelings about the technology, i.e., collaborative robots, and the organizational change associated with the introduction of this technology. Several factors related to the robot (object-related factors), the individual background of the workers (subject-related factors), and the organizational environment (context-related factors) are found to influence workers’ thoughts and feelings. Implications for researchers and manufacturing companies are outlined.","Technology acceptance, assembly, grounded theory, human-robot collaboration, human-robot interaction, qualitative, robot acceptance",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services). EC2 met: Focuses on excluded sectors (military, space, domestic, etc.) without clear application to target sectors. EC4 met: Study type appears to be excluded (e.g., review) based on title.",Ambas,Não,"Title: Friend or Foe? Understanding Assembly Workers’ Acceptance of Human-robot Collaboration
Abstract: Due to rising demands on productivity and flexibility, assembly processes are currently experiencing a substantial transformation. Workstations where humans and robots work closely together are becoming increasingly popular, as they provide major advantages compared to manual assembly and full automation. Yet, human-robot collaboration (HRC) can only be successful if the workforce is willing to accept it. How assembly workers perceive HRC still has to be properly investigated. An exploratory investigation using a Grounded Theory approach was conducted to identify factors that are likely to influence workers’ acceptance of introducing HRC at work. Seventeen workers with various levels of HRC experience from four different manufacturing companies were interviewed. Findings reveal that some workers perceive HRC as a threat, while others regard it as an opportunity. This perception seems to depend both on their thoughts and feelings about the technology, i.e., collaborative robots, and the organizational change associated with the introduction of this technology. Several factors related to the robot (object-related factors), the individual background of the workers (subject-related factors), and the organizational environment (context-related factors) are found to influence workers’ thoughts and feelings. Implications for researchers and manufacturing companies are outlined.
"
ACM,"Luo, Yue and Chen, Yuhao and Hu, Boyi",Multisensory Evaluation of Human-Robot Interaction in Retail Stores - The Effect of Mobile Cobots on Individuals' Physical and Neurophysiological Responses,2023,10.1145/3568294.3580115,"As more mobile collaborative robots (cobots) are being deployed in domestic environments, it is necessary to ensure safety while interacting with humans. To this end, a better understanding of individuals' physical and neurophysiological responses (i.e., short term adaptation) during those interactions becomes crucial to frame the cobot's behavioral and control algorithms. The primary objective of this study was to assess individuals' physical and neurophysiological responses to the mobile cobot in a retail environment. Eight participants were recruited to complete typical grocery shopping tasks (i.e., cart pushing, item picking, and item sorting) with and without a mobile robot running in the same space. Results showed the co-existence of mobile cobot in the retail environment stimulated individuals' physical responses, by significantly changing their upper-limb kinematics, i.e., reducing the average flexion angles of L5/S1, T12/L1, and right shoulder in the sagittal plane. However, no significant differences were observed in the neurophysiological adaptation based on the measures of muscle activity of the latissimus dorsi, anterior deltoid, and bicep brachii, nor the pupil diameter.","human-robot interaction, neurophysiological adaptation, physical adaptation, retail environmen",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services). EC2 met: Focuses on excluded sectors (military, space, domestic, etc.) without clear application to target sectors. EC4 met: Study type appears to be excluded (e.g., review) based on title.",Ambas,Não,"Title: Multisensory Evaluation of Human-Robot Interaction in Retail Stores - The Effect of Mobile Cobots on Individuals' Physical and Neurophysiological Responses
Abstract: As more mobile collaborative robots (cobots) are being deployed in domestic environments, it is necessary to ensure safety while interacting with humans. To this end, a better understanding of individuals' physical and neurophysiological responses (i.e., short term adaptation) during those interactions becomes crucial to frame the cobot's behavioral and control algorithms. The primary objective of this study was to assess individuals' physical and neurophysiological responses to the mobile cobot in a retail environment. Eight participants were recruited to complete typical grocery shopping tasks (i.e., cart pushing, item picking, and item sorting) with and without a mobile robot running in the same space. Results showed the co-existence of mobile cobot in the retail environment stimulated individuals' physical responses, by significantly changing their upper-limb kinematics, i.e., reducing the average flexion angles of L5/S1, T12/L1, and right shoulder in the sagittal plane. However, no significant differences were observed in the neurophysiological adaptation based on the measures of muscle activity of the latissimus dorsi, anterior deltoid, and bicep brachii, nor the pupil diameter.
"
ACM,"Abe, Naoko and Rye, David and Loke, Lian",A Microsociological Approach to Understanding the Robot Collaborative Motion in Human-Robot Interaction,2020,10.1145/3369457.3369503,"Existing approaches to human-robot collaboration typically focus on how to build robots that can work safely and fluently with humans on collaborative tasks. Less is known about how people interpret the boundary between movement-based collaboration and non-collaboration when interacting with robots. By applying a microsociological theory to analysing the process of interaction as it unfolds, we propose and identify points of breakdown in the collaborative task of a human and a robot carrying an object to a destination. In designing the experiment, Kinetography Laban is used to enable a precise description of the intended normative and disruptive motion paths of the robot. The contribution of the paper is the theoretical understanding of collaboration from sociology, and a method for designing and evaluating collaborative motion between humans and robots that combines microsociology and Kinetography Laban. The proposed method accounts for the contingent meaning construction performed by people in recognising behavioural motion cues of robots as part of an ongoing interaction process, and enables the boundary between collaborative and non-collaborative robot motion to be defined.","Human-robot collaboration, Kinetography Laban, interaction, meaning construction, microsociology, robot path",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services). EC2 met: Focuses on excluded sectors (military, space, domestic, etc.) without clear application to target sectors. EC4 met: Study type appears to be excluded (e.g., review) based on title.",Ambas,Não,"Title: A Microsociological Approach to Understanding the Robot Collaborative Motion in Human-Robot Interaction
Abstract: Existing approaches to human-robot collaboration typically focus on how to build robots that can work safely and fluently with humans on collaborative tasks. Less is known about how people interpret the boundary between movement-based collaboration and non-collaboration when interacting with robots. By applying a microsociological theory to analysing the process of interaction as it unfolds, we propose and identify points of breakdown in the collaborative task of a human and a robot carrying an object to a destination. In designing the experiment, Kinetography Laban is used to enable a precise description of the intended normative and disruptive motion paths of the robot. The contribution of the paper is the theoretical understanding of collaboration from sociology, and a method for designing and evaluating collaborative motion between humans and robots that combines microsociology and Kinetography Laban. The proposed method accounts for the contingent meaning construction performed by people in recognising behavioural motion cues of robots as part of an ongoing interaction process, and enables the boundary between collaborative and non-collaborative robot motion to be defined.
"
ACM,"Kassem, Khaled and Saad, Alia and Pascher, Max and Schett, Martin and Michahelles, Florian",Push Me: Evaluating Usability and User Experience in Nudge-based Human-Robot Interaction through Embedded Force and Torque Sensors,2024,10.1145/3670653.3677487,"Robots are expected to be integrated into human workspaces, which makes the development of effective and intuitive interaction crucial. While vision- and speech-based robot interfaces have been well studied, direct physical interaction has been less explored. However, HCI research has shown that direct manipulation interfaces provide more intuitive and satisfying user experiences, compared to other interaction modes. This work examines how built-in force/torque sensors in robots can facilitate direct manipulation through nudge-based interactions. We conducted a user study (N = 23) to compare this haptic approach with traditional touchscreen interfaces, focusing on workload, user experience, and usability. Our results show that haptic interactions are more engaging and intuitive but also more physically demanding compared to touchscreen interaction. These findings have implications for the design of physical human-robot interaction interfaces. Given the benefits of physical interaction highlighted in our study, we recommend that designers incorporate this interaction method for human-robot interaction, especially at close quarters.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services). EC2 met: Focuses on excluded sectors (military, space, domestic, etc.) without clear application to target sectors. EC4 met: Study type appears to be excluded (e.g., review) based on title.",Ambas,Não,"Title: Push Me: Evaluating Usability and User Experience in Nudge-based Human-Robot Interaction through Embedded Force and Torque Sensors
Abstract: Robots are expected to be integrated into human workspaces, which makes the development of effective and intuitive interaction crucial. While vision- and speech-based robot interfaces have been well studied, direct physical interaction has been less explored. However, HCI research has shown that direct manipulation interfaces provide more intuitive and satisfying user experiences, compared to other interaction modes. This work examines how built-in force/torque sensors in robots can facilitate direct manipulation through nudge-based interactions. We conducted a user study (N = 23) to compare this haptic approach with traditional touchscreen interfaces, focusing on workload, user experience, and usability. Our results show that haptic interactions are more engaging and intuitive but also more physically demanding compared to touchscreen interaction. These findings have implications for the design of physical human-robot interaction interfaces. Given the benefits of physical interaction highlighted in our study, we recommend that designers incorporate this interaction method for human-robot interaction, especially at close quarters.
"
ACM,"Onnasch, Linda and Hildebrandt, Clara Laudine",Impact of Anthropomorphic Robot Design on Trust and Attention in Industrial Human-Robot Interaction,2021,10.1145/3472224,"The application of anthropomorphic features to robots is generally considered beneficial for human-robot interaction (HRI). Although previous research has mainly focused on social robots, the phenomenon gains increasing attention in industrial human-Robot interaction as well. In this study, the impact of anthropomorphic design of a collaborative industrial robot on the dynamics of trust and visual attention allocation was examined. Participants interacted with a robot, which was either anthropomorphically or non-anthropomorphically designed. Unexpectedly, attribute-based trust measures revealed no beneficial effect of anthropomorphism but even a negative impact on the perceived reliability of the robot. Trust behavior was not significantly affected by an anthropomorphic robot design during faultless interactions, but showed a relatively steeper decrease after participants experienced a failure of the robot. With regard to attention allocation, the study clearly reveals a distracting effect of anthropomorphic robot design. The results emphasize that anthropomorphism might not be an appropriate feature in industrial HRI as it not only failed to reveal positive effects on trust, but distracted participants from relevant task areas which might be a significant drawback with regard to occupational safety in HRI.","Human-robot interaction, anthropomorphism, robotic design, trust, attention allocation",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services). EC2 met: Focuses on excluded sectors (military, space, domestic, etc.) without clear application to target sectors. EC4 met: Study type appears to be excluded (e.g., review) based on title.",Ambas,Não,"Title: Impact of Anthropomorphic Robot Design on Trust and Attention in Industrial Human-Robot Interaction
Abstract: The application of anthropomorphic features to robots is generally considered beneficial for human-robot interaction (HRI). Although previous research has mainly focused on social robots, the phenomenon gains increasing attention in industrial human-Robot interaction as well. In this study, the impact of anthropomorphic design of a collaborative industrial robot on the dynamics of trust and visual attention allocation was examined. Participants interacted with a robot, which was either anthropomorphically or non-anthropomorphically designed. Unexpectedly, attribute-based trust measures revealed no beneficial effect of anthropomorphism but even a negative impact on the perceived reliability of the robot. Trust behavior was not significantly affected by an anthropomorphic robot design during faultless interactions, but showed a relatively steeper decrease after participants experienced a failure of the robot. With regard to attention allocation, the study clearly reveals a distracting effect of anthropomorphic robot design. The results emphasize that anthropomorphism might not be an appropriate feature in industrial HRI as it not only failed to reveal positive effects on trust, but distracted participants from relevant task areas which might be a significant drawback with regard to occupational safety in HRI.
"
ACM,"Tokmurziyev, Issatay and Altamirano Cabrera, Miguel and Moreno, Luis and Khan, Muhammad Haris and Tsetserukou, Dzmitry",GazeGrasp: DNN-Driven Robotic Grasping with Wearable Eye-Gaze Interface,2025,,"We present GazeGrasp, a gaze-based manipulation system enabling individuals with motor impairments to control collaborative robots using eye-gaze. The system employs an ESP32 CAM for eye tracking, MediaPipe for gaze detection, and YOLOv8 for object localization, integrated with a Universal Robot UR10 for manipulation tasks. After user-specific calibration, the system allows intuitive object selection with a magnetic snapping effect and robot control via eye gestures. Experimental evaluation involving 13 participants demonstrated that the magnetic snapping effect significantly reduced gaze alignment time, improving task efficiency by 31%. GazeGrasp provides a robust, hands-free interface for assistive robotics, enhancing accessibility and autonomy for users.","assistive robotics, eye-gaze tracking, human-robot interaction",Sim,Sim,Igual,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.",All inclusion criteria appear to be met based on title and abstract.,Ambas,Sim,"Title: GazeGrasp: DNN-Driven Robotic Grasping with Wearable Eye-Gaze Interface
Abstract: We present GazeGrasp, a gaze-based manipulation system enabling individuals with motor impairments to control collaborative robots using eye-gaze. The system employs an ESP32 CAM for eye tracking, MediaPipe for gaze detection, and YOLOv8 for object localization, integrated with a Universal Robot UR10 for manipulation tasks. After user-specific calibration, the system allows intuitive object selection with a magnetic snapping effect and robot control via eye gestures. Experimental evaluation involving 13 participants demonstrated that the magnetic snapping effect significantly reduced gaze alignment time, improving task efficiency by 31%. GazeGrasp provides a robust, hands-free interface for assistive robotics, enhancing accessibility and autonomy for users.
"
ACM,"An, Dong and Rittenbruch, Markus and Razayan, Leo",The Design of Extended Reality-enabled Tangible Interaction to Enhance the Interaction with Collaborative Robots,2025,,"Collaborative robots (cobots) are increasingly employed in manufacturing to enhance productivity and efficiency, particularly by performing repetitive or precise tasks, allowing workers to focus on more complex activities. However, the growing adoption of cobots in dynamic environments, such as small and medium-sized enterprises (SMEs), poses challenges in designing flexible and user-friendly interaction models. This research addresses these challenges by integrating tangible interaction and Extended Reality (XR) technologies to develop innovative interaction methods for human-robot collaboration in metalworking. The tangible interaction leverages users' familiarity with physical objects, while XR provides immersive, real-time visual overlays to enhance task execution and decision-making. A co-design methodology is employed, involving metalworkers, XR designers, and roboticists, to ensure the system meets user needs. The study progresses through four phases: contextual inquiry, co-design workshops, system development, and user testing. Preliminary findings highlight the potential of XR-enabled tangible interaction to improve safety, efficiency, and intuitiveness in cobot applications. Future work aims to refine prototypes, evaluate scalability, and explore broader industrial applications, paving the way for safer and more effective human-robot collaboration systems.","collaborative robot, extended reality, human-robot interaction, tangible interaction.",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services). EC2 met: Focuses on excluded sectors (military, space, domestic, etc.) without clear application to target sectors. EC4 met: Study type appears to be excluded (e.g., review) based on title.",Ambas,Não,"Title: The Design of Extended Reality-enabled Tangible Interaction to Enhance the Interaction with Collaborative Robots
Abstract: Collaborative robots (cobots) are increasingly employed in manufacturing to enhance productivity and efficiency, particularly by performing repetitive or precise tasks, allowing workers to focus on more complex activities. However, the growing adoption of cobots in dynamic environments, such as small and medium-sized enterprises (SMEs), poses challenges in designing flexible and user-friendly interaction models. This research addresses these challenges by integrating tangible interaction and Extended Reality (XR) technologies to develop innovative interaction methods for human-robot collaboration in metalworking. The tangible interaction leverages users' familiarity with physical objects, while XR provides immersive, real-time visual overlays to enhance task execution and decision-making. A co-design methodology is employed, involving metalworkers, XR designers, and roboticists, to ensure the system meets user needs. The study progresses through four phases: contextual inquiry, co-design workshops, system development, and user testing. Preliminary findings highlight the potential of XR-enabled tangible interaction to improve safety, efficiency, and intuitiveness in cobot applications. Future work aims to refine prototypes, evaluate scalability, and explore broader industrial applications, paving the way for safer and more effective human-robot collaboration systems.
"
ACM,"Suzuki, Ryo and Karim, Adnan and Xia, Tian and Hedayati, Hooman and Marquardt, Nicolai",Augmented Reality and Robotics: A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces,2022,10.1145/3491102.3517719,"This paper contributes to a taxonomy of augmented reality and robotics based on a survey of 460 research papers. Augmented and mixed reality (AR/MR) have emerged as a new way to enhance human-robot interaction (HRI) and robotic interfaces (e.g., actuated and shape-changing interfaces). Recently, an increasing number of studies in HCI, HRI, and robotics have demonstrated how AR enables better interactions between people and robots. However, often research remains focused on individual explorations and key design strategies, and research questions are rarely analyzed systematically. In this paper, we synthesize and categorize this research field in the following dimensions: 1) approaches to augmenting reality; 2) characteristics of robots; 3) purposes and benefits; 4) classification of presented information; 5) design components and strategies for visual augmentation; 6) interaction techniques and modalities; 7) application domains; and 8) evaluation strategies. We formulate key challenges and opportunities to guide and inform future research in AR and robotics.","AR-HRI, VAM-HRI, actuated tangible UI, augmented reality, human-robot interaction, mixed reality, robotics, shape-changing UI",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services). EC4 met: Study type appears to be excluded (e.g., survey) based on title.",Ambas,Não,"Title: Augmented Reality and Robotics: A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces
Abstract: This paper contributes to a taxonomy of augmented reality and robotics based on a survey of 460 research papers. Augmented and mixed reality (AR/MR) have emerged as a new way to enhance human-robot interaction (HRI) and robotic interfaces (e.g., actuated and shape-changing interfaces). Recently, an increasing number of studies in HCI, HRI, and robotics have demonstrated how AR enables better interactions between people and robots. However, often research remains focused on individual explorations and key design strategies, and research questions are rarely analyzed systematically. In this paper, we synthesize and categorize this research field in the following dimensions: 1) approaches to augmenting reality; 2) characteristics of robots; 3) purposes and benefits; 4) classification of presented information; 5) design components and strategies for visual augmentation; 6) interaction techniques and modalities; 7) application domains; and 8) evaluation strategies. We formulate key challenges and opportunities to guide and inform future research in AR and robotics.
"
ACM,"Arevalo Arboleda, Stephanie and Pascher, Max and Baumeister, Annalies and Klein, Barbara and Gerken, Jens",Reflecting upon Participatory Design in Human-Robot Collaboration for People with Motor Disabilities: Challenges and Lessons Learned from Three Multiyear Projects,2021,10.1145/3453892.3458044,"Human-robot technology has the potential to positively impact the lives of people with motor disabilities. However, current efforts have mostly been oriented towards technology (sensors, devices, modalities, interaction techniques), thus relegating the user and their valuable input to the wayside. In this paper, we aim to present a holistic perspective of the role of participatory design in Human-Robot Collaboration (HRC) for People with Motor Disabilities (PWMD). We have been involved in several multiyear projects related to HRC for PWMD, where we encountered different challenges related to planning and participation, preferences of stakeholders, using certain participatory design techniques, technology exposure, as well as ethical, legal, and social implications. These challenges helped us provide five lessons learned that could serve as a guideline to researchers when using participatory design with vulnerable groups. In particular, early-career researchers who are starting to explore HRC research for people with disabilities.","challenges and lessons learned, human-robot collaboration, participatory design, people with motor disabilities",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,IC1 not satisfied: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics/healthcare/field services).,Ambas,Não,"Title: Reflecting upon Participatory Design in Human-Robot Collaboration for People with Motor Disabilities: Challenges and Lessons Learned from Three Multiyear Projects
Abstract: Human-robot technology has the potential to positively impact the lives of people with motor disabilities. However, current efforts have mostly been oriented towards technology (sensors, devices, modalities, interaction techniques), thus relegating the user and their valuable input to the wayside. In this paper, we aim to present a holistic perspective of the role of participatory design in Human-Robot Collaboration (HRC) for People with Motor Disabilities (PWMD). We have been involved in several multiyear projects related to HRC for PWMD, where we encountered different challenges related to planning and participation, preferences of stakeholders, using certain participatory design techniques, technology exposure, as well as ethical, legal, and social implications. These challenges helped us provide five lessons learned that could serve as a guideline to researchers when using participatory design with vulnerable groups. In particular, early-career researchers who are starting to explore HRC research for people with disabilities.
"
ACM,"Schrum, Mariah L. and Neville, Glen and Johnson, Michael and Moorman, Nina and Paleja, Rohan and Feigh, Karen M. and Gombolay, Matthew C.",Effects of Social Factors and Team Dynamics on Adoption of Collaborative Robot Autonomy,2021,10.1145/3434073.3444649,"As automation becomes more prevalent, the fear of job loss due to automation increases [22]. Workers may not be amenable to working with a robotic co-worker due to a negative perception of the technology. The attitudes of workers towards automation are influenced by a variety of complex and multi-faceted factors such as intention to use, perceived usefulness and other external variables [15]. In an analog manufacturing environment, we explore how these various factors influence an individual's willingness to work with a robot over a human co-worker in a collaborative Lego building task. We specifically explore how this willingness is affected by: 1) the level of social rapport established between the individual and his or her human co-worker, 2) the anthropomorphic qualities of the robot, and 3) factors including trust, fluency and personality traits. Our results show that a participant's willingness to work with automation decreased due to lower perceived team fluency (p=0.045), rapport established between a participant and their co-worker (p=0.003), the gender of the participant being male (p=0.041), and a higher inherent trust in people (p=0.018).","adoption, anthropomorphism, automation, hri",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: Effects of Social Factors and Team Dynamics on Adoption of Collaborative Robot Autonomy
Abstract: As automation becomes more prevalent, the fear of job loss due to automation increases [22]. Workers may not be amenable to working with a robotic co-worker due to a negative perception of the technology. The attitudes of workers towards automation are influenced by a variety of complex and multi-faceted factors such as intention to use, perceived usefulness and other external variables [15]. In an analog manufacturing environment, we explore how these various factors influence an individual's willingness to work with a robot over a human co-worker in a collaborative Lego building task. We specifically explore how this willingness is affected by: 1) the level of social rapport established between the individual and his or her human co-worker, 2) the anthropomorphic qualities of the robot, and 3) factors including trust, fluency and personality traits. Our results show that a participant's willingness to work with automation decreased due to lower perceived team fluency (p=0.045), rapport established between a participant and their co-worker (p=0.003), the gender of the participant being male (p=0.041), and a higher inherent trust in people (p=0.018).
"
ACM,"Cruz-Sandoval, Dagoberto and Murakami, Michele and Kubota, Alyssa and Riek, Laurel D.",PODER: A Robot Programming Framework to Further Inclusion of People with Mild Cognitive Impairment in HRI Research,2025,,"Many HRI researchers have engaged in participatory research to include users in robot design processes. However, to our knowledge, people with mild cognitive impairment (PwMCI) and early stage dementia have yet to be included in developing and programming robots, and the HRI community lacks tools to facilitate their inclusion. We bridge this gap by introducing PODER (PrOgramming framework to Develop Robot behaviors), which enables a lived technology experience for PwMCI via scaffolding, peer programming, and development tools to support them as key developers of social robots. We conducted a study where PwMCI and early stage dementia used PODER to program robot interactions, and found that participants were highly engaged and deeply enjoyed their experience, creating programs for robots that reflected their interests, experiences, and needs. Our results show the impact of including participants with MCI and early stage dementia in robot programming, including an increased understanding of technology, shifting their perceived role from technology users to programmers, and desire to be involved with the end-to-end process. By releasing PODER to the community, we hope this work can facilitate the intentional inclusion of people with cognitive impairments in further HRI research.","assistive robotics, human-robot interaction, inclusion, people with cognitive impairments, robot programming",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: PODER: A Robot Programming Framework to Further Inclusion of People with Mild Cognitive Impairment in HRI Research
Abstract: Many HRI researchers have engaged in participatory research to include users in robot design processes. However, to our knowledge, people with mild cognitive impairment (PwMCI) and early stage dementia have yet to be included in developing and programming robots, and the HRI community lacks tools to facilitate their inclusion. We bridge this gap by introducing PODER (PrOgramming framework to Develop Robot behaviors), which enables a lived technology experience for PwMCI via scaffolding, peer programming, and development tools to support them as key developers of social robots. We conducted a study where PwMCI and early stage dementia used PODER to program robot interactions, and found that participants were highly engaged and deeply enjoyed their experience, creating programs for robots that reflected their interests, experiences, and needs. Our results show the impact of including participants with MCI and early stage dementia in robot programming, including an increased understanding of technology, shifting their perceived role from technology users to programmers, and desire to be involved with the end-to-end process. By releasing PODER to the community, we hope this work can facilitate the intentional inclusion of people with cognitive impairments in further HRI research.
"
ACM,"Gargioni, Luigi and Fogli, Daniela",Integrating ChatGPT with Blockly for End-User Development of Robot Tasks,2024,10.1145/3610978.3640653,"This paper presents an End-User Development environment for collaborative robot programming, which integrates Open AI ChatGPT with Google Blockly. Within this environment, a user, who is neither expert in robotics nor in computer programming, can define the items characterizing the application domain (e.g., objects, actions, and locations) and define pick-and-place tasks involving these items. Task definition can be achieved with a combination of natural language and block-based interaction, which exploits the computational capabilities of ChatGPT and the graphical interaction features offered by Blockly, to check the correctness of generated robot programs and modify them through direct manipulation.","collaborative robots, end-user development, human-machine interaction, human-robot collaboration",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services)",Ambas,Não,"Title: Integrating ChatGPT with Blockly for End-User Development of Robot Tasks
Abstract: This paper presents an End-User Development environment for collaborative robot programming, which integrates Open AI ChatGPT with Google Blockly. Within this environment, a user, who is neither expert in robotics nor in computer programming, can define the items characterizing the application domain (e.g., objects, actions, and locations) and define pick-and-place tasks involving these items. Task definition can be achieved with a combination of natural language and block-based interaction, which exploits the computational capabilities of ChatGPT and the graphical interaction features offered by Blockly, to check the correctness of generated robot programs and modify them through direct manipulation.
"
ACM,"Saad, Alia and Pascher, Max and Kassem, Khaled and Heger, Roman and Liebers, Jonathan and Schneegass, Stefan and Gruenefeld, Uwe",Hand-in-Hand: Investigating Mechanical Tracking for User Identification in Cobot Interaction,2023,10.1145/3626705.3627771,"Robots play a vital role in modern automation, with applications in manufacturing and healthcare. Collaborative robots integrate human and robot movements. Therefore, it is essential to ensure that interactions involve qualified, and thus identified, individuals. This study delves into a new approach: identifying individuals through robot arm movements. Different from previous methods, users guide the robot, and the robot senses the movements via joint sensors. We asked 18 participants to perform six gestures, revealing the potential use as unique behavioral traits or biometrics, achieving F1-score up to 0.87, which suggests direct robot interactions as a promising avenue for implicit and explicit user identification.","behavioral biometrics, cobots, human-robot collaboration, human-robot interaction",Não,Sim,Diferente,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.",All inclusion criteria appear to be met based on title and abstract.,LLM 1,Sim,"Title: Hand-in-Hand: Investigating Mechanical Tracking for User Identification in Cobot Interaction
Abstract: Robots play a vital role in modern automation, with applications in manufacturing and healthcare. Collaborative robots integrate human and robot movements. Therefore, it is essential to ensure that interactions involve qualified, and thus identified, individuals. This study delves into a new approach: identifying individuals through robot arm movements. Different from previous methods, users guide the robot, and the robot senses the movements via joint sensors. We asked 18 participants to perform six gestures, revealing the potential use as unique behavioral traits or biometrics, achieving F1-score up to 0.87, which suggests direct robot interactions as a promising avenue for implicit and explicit user identification.
"
ACM,"Aromaa, Susanna and Lammi, Hanna",User-based Evaluation of a Proof-of-Concept for a Complex Service Robot System,2025,10.1145/3746175.3746176,"The use of advanced technologies that collaborate with humans in work contexts is increasing. Designing these complex systems to support smooth collaboration and a good user experience can be challenging. The goal of this study was two-fold: to understand which kinds of human factors and ergonomics (HFE) methods would be suitable for user-based evaluation of a proof-of-concept (PoC) and to examine the experience of interacting with a multipurpose robot. To achieve these objectives, three HFE methods were applied: a questionnaire, interviews, and observation. Additionally, a Wizard of Oz approach was utilised. As a result, qualitative HFE approaches such as interviews and observations were seen as beneficial in the evaluation of novel PoCs in an early design phase. Regarding the robot system, the results revealed that the interaction was experienced as fluent and natural. However, some concerns were identified, such as the robot interrupting other tasks, understanding the status of the robot, and privacy issues. The findings from this study can be used when designing human-robot interactions for multipurpose robots in work contexts and when selecting suitable HFE methods for user-based PoC testing.","Human factors and ergonomics, Human-robot interaction, Proof-of-concept, User-based testing",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: User-based Evaluation of a Proof-of-Concept for a Complex Service Robot System
Abstract: The use of advanced technologies that collaborate with humans in work contexts is increasing. Designing these complex systems to support smooth collaboration and a good user experience can be challenging. The goal of this study was two-fold: to understand which kinds of human factors and ergonomics (HFE) methods would be suitable for user-based evaluation of a proof-of-concept (PoC) and to examine the experience of interacting with a multipurpose robot. To achieve these objectives, three HFE methods were applied: a questionnaire, interviews, and observation. Additionally, a Wizard of Oz approach was utilised. As a result, qualitative HFE approaches such as interviews and observations were seen as beneficial in the evaluation of novel PoCs in an early design phase. Regarding the robot system, the results revealed that the interaction was experienced as fluent and natural. However, some concerns were identified, such as the robot interrupting other tasks, understanding the status of the robot, and privacy issues. The findings from this study can be used when designing human-robot interactions for multipurpose robots in work contexts and when selecting suitable HFE methods for user-based PoC testing.
"
ACM,"Ayalew, Tewodros W. and Wang, Jennifer and Littman, Michael L. and Ur, Blase and Sebo, Sarah",Enabling End Users to Program Robots Using Reinforcement Learning,2025,,"Reinforcement learning (RL) is a powerful learning technique in robotics, where people can specify rewards that robots learn how to maximize through a process of trial-and-error. Despite the numerous advantages of RL to robot programming, no approaches to our knowledge have sought to enable non-technical users to specify RL programs for robots. In this work, we designed two novel RL-based robot programming paradigms for non-technical users: Full MDP Programming (Full-MDP and Goal-Only MDP Programming (Goal-MDP). To evaluate the efficacy of these two approaches, we ran a between-subjects online user study (N = 409) where participants were asked to program a simulated robot to complete example household tasks (e.g., delivering coffee) using one of our RL programming paradigms or a commonly used baseline: Sequential Programming (Seq), or Trigger-Action Programming (TAP). While users neither performed well nor reported positive experiences with the FullMDP interface, user performance and experience with Goal-MDP was similar to the baselines (Seq and TAP) with significantly shorter programs. These results demonstrate that RL-based paradigms like Goal-MDP are a viable alternative to more traditional approaches and provide a starting point for robot programming interfaces that allow end-users to leverage the myriad benefits of RL for programming robots.","end-user robot programming, human-robot interaction, reinforcement learning",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 not satisfied: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics/healthcare/field services). EC2 met: Focuses on excluded sectors (military, space, domestic, etc.) without clear application to target sectors.",Ambas,Não,"Title: Enabling End Users to Program Robots Using Reinforcement Learning
Abstract: Reinforcement learning (RL) is a powerful learning technique in robotics, where people can specify rewards that robots learn how to maximize through a process of trial-and-error. Despite the numerous advantages of RL to robot programming, no approaches to our knowledge have sought to enable non-technical users to specify RL programs for robots. In this work, we designed two novel RL-based robot programming paradigms for non-technical users: Full MDP Programming (Full-MDP and Goal-Only MDP Programming (Goal-MDP). To evaluate the efficacy of these two approaches, we ran a between-subjects online user study (N = 409) where participants were asked to program a simulated robot to complete example household tasks (e.g., delivering coffee) using one of our RL programming paradigms or a commonly used baseline: Sequential Programming (Seq), or Trigger-Action Programming (TAP). While users neither performed well nor reported positive experiences with the FullMDP interface, user performance and experience with Goal-MDP was similar to the baselines (Seq and TAP) with significantly shorter programs. These results demonstrate that RL-based paradigms like Goal-MDP are a viable alternative to more traditional approaches and provide a starting point for robot programming interfaces that allow end-users to leverage the myriad benefits of RL for programming robots.
"
ACM,"Stower, Rebecca and Gautier, Anna and Wozniak, Maciej and Jensfelt, Patric and Tumova, Jana and Leite, Iolanda",Take a Chance on Me: How Robot Performance and Risk Behaviour Affects Trust and Risk-taking,2025,,"Real-world human-robot interactions often encompass uncertainty. This uncertainty can be handled in different ways, for example by designing robot planners to be more or less risk-tolerant. However, how users actually perceive different risk-taking behaviours in robots has yet to be described. Additionally, in the absence of guarantees on optimal robot performance, the interaction between risk and performance on user perceptions is also unclear. To address this gap, we conducted a user study with 84 participants investigating how robot performance and risk behaviour affects users' trust and risk-taking decisions. Participants collaborated with a Franka robot arm to perform a block-stacking task. We compared a robot which displays consistent but sub-optimal behaviours to a robot displaying risky but occasionally optimal behaviour. Risky robot behaviour led to higher trust than consistent behaviour when the robot was on average good at stacking blocks (high expectation), but lower trust when the robot was on average bad at stacking blocks (low expectation). Individual risk-willingness also predicted likelihood of selecting the risky robot over the consistent robot for future interactions, but only when the average expectation was low. These findings have implications for risk-aware planning and decision-making in mixed human-robot systems.","collaborative robot, failure, risk-taking, trust, user study",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: Take a Chance on Me: How Robot Performance and Risk Behaviour Affects Trust and Risk-taking
Abstract: Real-world human-robot interactions often encompass uncertainty. This uncertainty can be handled in different ways, for example by designing robot planners to be more or less risk-tolerant. However, how users actually perceive different risk-taking behaviours in robots has yet to be described. Additionally, in the absence of guarantees on optimal robot performance, the interaction between risk and performance on user perceptions is also unclear. To address this gap, we conducted a user study with 84 participants investigating how robot performance and risk behaviour affects users' trust and risk-taking decisions. Participants collaborated with a Franka robot arm to perform a block-stacking task. We compared a robot which displays consistent but sub-optimal behaviours to a robot displaying risky but occasionally optimal behaviour. Risky robot behaviour led to higher trust than consistent behaviour when the robot was on average good at stacking blocks (high expectation), but lower trust when the robot was on average bad at stacking blocks (low expectation). Individual risk-willingness also predicted likelihood of selecting the risky robot over the consistent robot for future interactions, but only when the average expectation was low. These findings have implications for risk-aware planning and decision-making in mixed human-robot systems.
"
ACM,"Balcha, Hailu Beshada and Rauffet, Philippe and Wegari, Getachew Mamo and Buche, Cedric",A Review on Human–Robot Trust in Home Service Robots,2025,10.1145/3737893,"As home service robots become increasingly integrated into domestic environments, trust in Human–Robot Interaction (HRI) emerges as a critical factor influencing their acceptance and effectiveness. This article presents survey review aiming to provide an understanding and insights into trust in HRI, particularly in home service robots. By analyzing existing studies, we explore the definition of trust and dimensions in different disciplinary perspectives, influencing factors, and assessment methodologies of trust in HRI. We also explore the dynamic nature of trust, highlighting the roles of robot reliability, transparency, predictability, and social interaction in shaping user perceptions. Furthermore, we present existing trust measurement approaches, including self-report questionnaires, behavioral and physiological metrics, and multimodal assessments, while identifying gaps in standardization and real-time evaluation. Ethical considerations, cultural influences, and the long-term evolution of trust in home service robots are also discussed. By synthesizing insights from interdisciplinary research, this article aims to provide insights that will benefit both the academic and research communities, as well as practical applications, and to inform future studies and guide the development of trustworthy, adaptive and user-centered home service robots that seamlessly integrate into daily life.","Human-Robot Interaction, Trust Dynamics, Home Service Robots, Factors Influencing Trust, Trust Measurement and Assessment",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services). EC2 met: Focuses on excluded sectors (military, space, domestic, etc.) without clear application to target sectors. EC4 met: Study type appears to be excluded (e.g., review) based on title.",Ambas,Não,"Title: A Review on Human–Robot Trust in Home Service Robots
Abstract: As home service robots become increasingly integrated into domestic environments, trust in Human–Robot Interaction (HRI) emerges as a critical factor influencing their acceptance and effectiveness. This article presents survey review aiming to provide an understanding and insights into trust in HRI, particularly in home service robots. By analyzing existing studies, we explore the definition of trust and dimensions in different disciplinary perspectives, influencing factors, and assessment methodologies of trust in HRI. We also explore the dynamic nature of trust, highlighting the roles of robot reliability, transparency, predictability, and social interaction in shaping user perceptions. Furthermore, we present existing trust measurement approaches, including self-report questionnaires, behavioral and physiological metrics, and multimodal assessments, while identifying gaps in standardization and real-time evaluation. Ethical considerations, cultural influences, and the long-term evolution of trust in home service robots are also discussed. By synthesizing insights from interdisciplinary research, this article aims to provide insights that will benefit both the academic and research communities, as well as practical applications, and to inform future studies and guide the development of trustworthy, adaptive and user-centered home service robots that seamlessly integrate into daily life.
"
ACM,"Leesakul, Natalie and Clos, Jeremie and Hyde, Richard",Not the Law's First Rodeo: Towards regulating trustworthy collaborative industrial embodied autonomous systems,2024,10.1145/3686038.3686047,"Does the law stifle technology adoption? At the surface, it may appear to be that there is a regulatory gap and, therefore, such uncertainty can hinder the development and deployment of collaborative industrial embodied autonomous systems (Cobots). Cobots are a class of robots which, unlike other forms of industrial robots, have seemingly introduced new legal challenges due to the direct human-robot collaboration factor. In this paper, to shed light on the above, we investigate the gap in the applicability of the current legal frameworks to this technology from the UK and EU regulatory approaches. We argue that the current law is applicable in regulating this technology given the state of the art. We discuss implications for the regulation to enhance trust and responsible future adoption of Cobots.","Embodied Autonomous Systems, HRI, Human-Robot Collaboration, Law, Regulation, Responsible Innovation, Technology, Trust",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: Not the Law's First Rodeo: Towards regulating trustworthy collaborative industrial embodied autonomous systems
Abstract: Does the law stifle technology adoption? At the surface, it may appear to be that there is a regulatory gap and, therefore, such uncertainty can hinder the development and deployment of collaborative industrial embodied autonomous systems (Cobots). Cobots are a class of robots which, unlike other forms of industrial robots, have seemingly introduced new legal challenges due to the direct human-robot collaboration factor. In this paper, to shed light on the above, we investigate the gap in the applicability of the current legal frameworks to this technology from the UK and EU regulatory approaches. We argue that the current law is applicable in regulating this technology given the state of the art. We discuss implications for the regulation to enhance trust and responsible future adoption of Cobots.
"
ACM,"Nenna, Federica and Zanardi, Davide and Maria Orlando, Egle and Mingardi, Michele and Buodo, Giulia and Gamberini, Luciano",Addressing Trust and Negative Attitudes Toward Robots in Human-Robot Collaborative Scenarios: Insights from the Industrial Work Setting,2024,10.1145/3652037.3663905,"Recent advancements in Human-Robot Collaboration (HRC) have brought to light the significance of ethical, psychological, and attitudinal factors in advanced work and industrial settings, whereby collaborative robots assist humans in work tasks. In these environments, individual factors, attitudes, and trust beliefs of human workers towards robots have a direct impact on the perceived efficiency and safety of HRCs, contributing to worker well-being in the workplace. However, most of the existing research on these topics has been concentrated on social robots and much less on industrial ones. This study aims to fill this gap by exploring the relationships between Negative Attitudes toward robots (NARS) and Trust in industrial HRC. Results demonstrated how, while the overall correlation between NARS and Trust was non-significant, unexpected trends also arose. Gender-dependent dynamics added complexity, with women exhibiting stronger correlations between emotional attitudes and trust. Men, on the other hand, demonstrated a link between stronger NARS and enhanced trust, particularly in robot motion speed perceptions. These intricate findings emphasize the need for tailored design considerations in cobot development, acknowledging the nuanced interplay between dispositional attitudes and trust in shaping human perceptions of robotic technologies in practical scenarios.","Human-Robot Collaboration, Negative attitude toward robots, Robotics, Trust",Sim,Não,Diferente,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.","IC1 (Sector) not satisfied: Does not clearly apply to target sectors (logistics, healthcare, field services).",LLM 1,Sim,"Title: Addressing Trust and Negative Attitudes Toward Robots in Human-Robot Collaborative Scenarios: Insights from the Industrial Work Setting
Abstract: Recent advancements in Human-Robot Collaboration (HRC) have brought to light the significance of ethical, psychological, and attitudinal factors in advanced work and industrial settings, whereby collaborative robots assist humans in work tasks. In these environments, individual factors, attitudes, and trust beliefs of human workers towards robots have a direct impact on the perceived efficiency and safety of HRCs, contributing to worker well-being in the workplace. However, most of the existing research on these topics has been concentrated on social robots and much less on industrial ones. This study aims to fill this gap by exploring the relationships between Negative Attitudes toward robots (NARS) and Trust in industrial HRC. Results demonstrated how, while the overall correlation between NARS and Trust was non-significant, unexpected trends also arose. Gender-dependent dynamics added complexity, with women exhibiting stronger correlations between emotional attitudes and trust. Men, on the other hand, demonstrated a link between stronger NARS and enhanced trust, particularly in robot motion speed perceptions. These intricate findings emphasize the need for tailored design considerations in cobot development, acknowledging the nuanced interplay between dispositional attitudes and trust in shaping human perceptions of robotic technologies in practical scenarios.
"
ACM,"Gargioni, Luigi and Fogli, Daniela and Baroni, Pietro",Preparation of Personalized Medicines through Collaborative Robots: A Hybrid Approach to the End-User Development of Robot Programs,2025,10.1145/3715852,"Galenic formulations are personalized medicines prepared by pharmacists in their laborato ries. They are produced in small batches considering single patients’ characteristics, such as age, gender, allergies, and the like, thus contributing to responsible health. The production process is performed manually with the support of mechanic machines. This activity is time-consuming, prone to errors, and subject to quality variations. In this paper, we propose the integration of collaborative robots into the galenic formulation process to obtain several advantages, such as increased productivity, reduced variability, improved accuracy, and minimized risks associated with human error. Additionally, the use of robots can alleviate the physical burden on human operators, allowing them to focus on higher-level tasks that require critical thinking and decision-making. To achieve this goal, a software application, called PRAISE (Pharmaceutical Robotic and AI System for End users), has been developed; it is meant to support end users (i.e., pharmacists) in defining robot programs suitable to the case at hand. This application is conceived as an End-User Development (EUD) environment, which implements a hybrid interaction approach based on a natural language interface leveraging Large Language Models and a graphical interface to check and possibly revise the user-created robot programs. A user study carried out with nine pharmacists demonstrates the validity of the approach.","Human-machine interaction, end-user development, human-robot collaboration, collaborative robots",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 not satisfied. Title/abstract do not clearly indicate a focus on target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: Preparation of Personalized Medicines through Collaborative Robots: A Hybrid Approach to the End-User Development of Robot Programs
Abstract: Galenic formulations are personalized medicines prepared by pharmacists in their laborato ries. They are produced in small batches considering single patients’ characteristics, such as age, gender, allergies, and the like, thus contributing to responsible health. The production process is performed manually with the support of mechanic machines. This activity is time-consuming, prone to errors, and subject to quality variations. In this paper, we propose the integration of collaborative robots into the galenic formulation process to obtain several advantages, such as increased productivity, reduced variability, improved accuracy, and minimized risks associated with human error. Additionally, the use of robots can alleviate the physical burden on human operators, allowing them to focus on higher-level tasks that require critical thinking and decision-making. To achieve this goal, a software application, called PRAISE (Pharmaceutical Robotic and AI System for End users), has been developed; it is meant to support end users (i.e., pharmacists) in defining robot programs suitable to the case at hand. This application is conceived as an End-User Development (EUD) environment, which implements a hybrid interaction approach based on a natural language interface leveraging Large Language Models and a graphical interface to check and possibly revise the user-created robot programs. A user study carried out with nine pharmacists demonstrates the validity of the approach.
"
ACM,"Johansen, Stine S and Donovan, Jared W and Rittenbruch, Markus",Articulating Human-World Relations from Co-Designing a Collaborative Robotic System,2025,10.1145/3706598.3714109,"In contrast to traditional industrial robots, collaborative robots are developed with the intention of allowing for close-proximity physical interaction between humans and robots. Current definitions of collaborative robots provide a pragmatic starting point for establishing safety guidelines, choosing operating parameters, and implementing organisational changes, but remain predicated on technological conceptions that prioritise a conscious split between people and robots, with the surrounding world as merely a physical site for interaction. In this paper, we take a postphenomenological perspective on robots in an investigation of human-world relations that robots can give rise to. This perspective can help elucidate the nature of such relations in a design process. Our investigation is anchored in an 8-month research study that aimed to, first, identify opportunities for a robot integration within a medical manufacturing facility and, second, facilitate a design and implementation process of a proof-of-concept robotic system in collaboration with workers. The paper contributes with an empirically anchored postphenomenological analysis of how human-world relations played out in the design process of a collaborative robotic system. Finally, we elaborate on the utility and limitations of a postphenomenological lens for design research.","Robotics, Postphenomenology, Human-Robot Collaboration, Designerly HRI",Não,Não,Igual,EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 not satisfied. Title/abstract do not clearly indicate a focus on target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: Articulating Human-World Relations from Co-Designing a Collaborative Robotic System
Abstract: In contrast to traditional industrial robots, collaborative robots are developed with the intention of allowing for close-proximity physical interaction between humans and robots. Current definitions of collaborative robots provide a pragmatic starting point for establishing safety guidelines, choosing operating parameters, and implementing organisational changes, but remain predicated on technological conceptions that prioritise a conscious split between people and robots, with the surrounding world as merely a physical site for interaction. In this paper, we take a postphenomenological perspective on robots in an investigation of human-world relations that robots can give rise to. This perspective can help elucidate the nature of such relations in a design process. Our investigation is anchored in an 8-month research study that aimed to, first, identify opportunities for a robot integration within a medical manufacturing facility and, second, facilitate a design and implementation process of a proof-of-concept robotic system in collaboration with workers. The paper contributes with an empirically anchored postphenomenological analysis of how human-world relations played out in the design process of a collaborative robotic system. Finally, we elaborate on the utility and limitations of a postphenomenological lens for design research.
"
ACM,"Abe, Naoko and Rye, David and Loke, Lian",Designing an Experiment for Generating Human Experiences of Robot Cooperativeness and Uncooperativeness,2020,10.1145/3406499.3418750,"While existing approaches to human-robot collaboration typically focus on how to build robots that can work safely and fluently with humans on collaborative tasks, our research focuses on how people experience interaction with a robot and interpret its behaviour as collaborative or non-collaborative. By applying a microsociological theory to analyse the process of interaction as it unfolds, our project aims to identify the boundary between cooperativeness and uncooperativeness of the robot in the shared task of a human and a robot carrying an object to a destination. The paper presents the experimental protocol designed based on the microsociological theory that is less known in current human-robot interaction studies. The aim of the experiment is to enable participants to experience expected and unexpected interactions with a robot and to account for how the interaction affects participant interpretation of robot cooperativeness and uncooperativeness.","experiment design, human-robot collaboration, interaction, microsociology, robot path",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 not satisfied. Title/abstract do not clearly indicate a focus on target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: Designing an Experiment for Generating Human Experiences of Robot Cooperativeness and Uncooperativeness
Abstract: While existing approaches to human-robot collaboration typically focus on how to build robots that can work safely and fluently with humans on collaborative tasks, our research focuses on how people experience interaction with a robot and interpret its behaviour as collaborative or non-collaborative. By applying a microsociological theory to analyse the process of interaction as it unfolds, our project aims to identify the boundary between cooperativeness and uncooperativeness of the robot in the shared task of a human and a robot carrying an object to a destination. The paper presents the experimental protocol designed based on the microsociological theory that is less known in current human-robot interaction studies. The aim of the experiment is to enable participants to experience expected and unexpected interactions with a robot and to account for how the interaction affects participant interpretation of robot cooperativeness and uncooperativeness.
"
ACM,"Schneiders, Eike and Papachristos, Eleftherios",It's not all Bad - Worker Perceptions of Industrial Robots,2022,N/A,"The current discourse presented by mainstream media towards industrial robots seems to focus on the negative aspects their introduction brings to the workforce. However, it is unclear whether industrial workers share this negative perspective regarding industrial robots. In this paper, we present the results of a survey study (N=94) investigating differences in perception towards industrial robots, depending on the presence or absence of exposure to them in the workplace. Our results show that while workers with robot experience acknowledge that robots can lead to job loss, they also show stronger beliefs in the robots ability to boost new job opportunities. Additionally, we found that first-hand experience with robots in the workplace can positively affect workers perceptions about their advantages. Overall, our findings show that, contrasting the bleak picture drawn by mainstream media, workers exposed to industrial robots developed a more nuanced view of this new technology in the workplace.","human-robot interaction, perception of industrial robots, survey study, worker perception",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 met. The abstract indicates this is a review, survey, or other excluded publication type.",Ambas,Não,"Title: It's not all Bad - Worker Perceptions of Industrial Robots
Abstract: The current discourse presented by mainstream media towards industrial robots seems to focus on the negative aspects their introduction brings to the workforce. However, it is unclear whether industrial workers share this negative perspective regarding industrial robots. In this paper, we present the results of a survey study (N=94) investigating differences in perception towards industrial robots, depending on the presence or absence of exposure to them in the workplace. Our results show that while workers with robot experience acknowledge that robots can lead to job loss, they also show stronger beliefs in the robots ability to boost new job opportunities. Additionally, we found that first-hand experience with robots in the workplace can positively affect workers perceptions about their advantages. Overall, our findings show that, contrasting the bleak picture drawn by mainstream media, workers exposed to industrial robots developed a more nuanced view of this new technology in the workplace.
"
ACM,"Michaelis, Joseph E. and Siebert-Evenstone, Amanda and Shaffer, David Williamson and Mutlu, Bilge",Collaborative or Simply Uncaged? Understanding Human-Cobot Interactions in Automation,2020,10.1145/3313831.3376547,"Collaborative robots, or cobots, represent a breakthrough technology designed for high-level (e.g. collaborative) interactions between workers and robots with capabilities for flexible deployment in industries such as manufacturing. Understanding how workers and companies use and integrate cobots is important to inform the future design of cobot systems and educational technologies that facilitate effective worker-cobot interaction. Yet, little is known about typical training for collaboration and the application of cobots in manufacturing. To close this gap, we interviewed nine experts in manufacturing about their experience with cobots. Our thematic analysis revealed that, contrary to the envisioned use, experts described most cobot applications as only low-level (e.g. pressing start/stop buttons) interactions with little flexible deployment, and experts felt traditional robotics skills were needed for collaborative and flexible interaction with cobots. We conclude with design recommendations for improved future robots, including programming and interface designs, and educational technologies to support collaborative use.","collaborative robots, educational technology, end-user programming, human-robot collaboration, human-robot interaction (hri), technology adoption",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 not satisfied. Title/abstract do not clearly indicate a focus on target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: Collaborative or Simply Uncaged? Understanding Human-Cobot Interactions in Automation
Abstract: Collaborative robots, or cobots, represent a breakthrough technology designed for high-level (e.g. collaborative) interactions between workers and robots with capabilities for flexible deployment in industries such as manufacturing. Understanding how workers and companies use and integrate cobots is important to inform the future design of cobot systems and educational technologies that facilitate effective worker-cobot interaction. Yet, little is known about typical training for collaboration and the application of cobots in manufacturing. To close this gap, we interviewed nine experts in manufacturing about their experience with cobots. Our thematic analysis revealed that, contrary to the envisioned use, experts described most cobot applications as only low-level (e.g. pressing start/stop buttons) interactions with little flexible deployment, and experts felt traditional robotics skills were needed for collaborative and flexible interaction with cobots. We conclude with design recommendations for improved future robots, including programming and interface designs, and educational technologies to support collaborative use.
"
ACM,"Oechsner, Carl and Leusmann, Jan and Welsch, Robin and Butz, Andreas Martin and Mayer, Sven",Influence of Perceived Danger on Proxemics in Human-Robot Object Handovers,2025,10.1145/3743049.3743064,"As robots increasingly share human environments, we need to understand how their behavioral parameters affect our perceptions of safety and interaction quality. To explore this, we conducted a user study (N=48) investigating the relationship between approach speed, stopping distance, and the perceived danger of the object itself in a robot-human handover situation. Participants iteratively adjusted the speed and distance of a robot handing them items of varying danger categories to find a combination they considered optimal. We found a significant impact of the delivered item’s perceived danger index on speed and distance preferences and could identify a linear dependency. By eliciting user preferences for these parameters, we can provide guidelines for adaptable robotic interactions that are considered safe, thus contributing to the design of spaces where robots and humans can coexist seamlessly, emphasizing user experience, trust, and effective collaboration.","Robotics, Kinematics and Dynamics, Social Robots, Proxemics, Human-Robot Collaboration",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 not satisfied. Title/abstract do not clearly indicate a focus on target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: Influence of Perceived Danger on Proxemics in Human-Robot Object Handovers
Abstract: As robots increasingly share human environments, we need to understand how their behavioral parameters affect our perceptions of safety and interaction quality. To explore this, we conducted a user study (N=48) investigating the relationship between approach speed, stopping distance, and the perceived danger of the object itself in a robot-human handover situation. Participants iteratively adjusted the speed and distance of a robot handing them items of varying danger categories to find a combination they considered optimal. We found a significant impact of the delivered item’s perceived danger index on speed and distance preferences and could identify a linear dependency. By eliciting user preferences for these parameters, we can provide guidelines for adaptable robotic interactions that are considered safe, thus contributing to the design of spaces where robots and humans can coexist seamlessly, emphasizing user experience, trust, and effective collaboration.
"
ACM,"Schadenberg, Bob R. and Garcia Goo, Hideki and Nyman, Lena and Keisu, Jesper and Evers, Vanessa",The Views of Hospital Laboratory Workers on Augmenting Laboratory Testing with Robots,2023,10.1145/3568294.3580157,"One way to address shortages in the workforce and improve the safety of health workers is through robots. Here, we will specifically look at whether and how robots might augment workers working on the pre-analytical phase of clinical testing in hospital laboratories. We conducted eight interviews with workers using futuristic autobiographies. Through our analysis, we identified three themes. Workers envisioned robots to increase their well-being and change blue-collar workers' tasks towards that of automation operators. The latter was perceived to be a change towards doing more meaningful tasks (cognitive tasks, rather than manual labour). Additionally, workers have a need to better cope with structural changes and temporary fluctuations in the workflow. More general-purpose robots could address this.","hospital laboratory, laboratory testing, robots, speculative design",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,IC1 not satisfied. Does not appear to focus on multifunctional or collaborative robots (cobots).,Ambas,Não,"Title: The Views of Hospital Laboratory Workers on Augmenting Laboratory Testing with Robots
Abstract: One way to address shortages in the workforce and improve the safety of health workers is through robots. Here, we will specifically look at whether and how robots might augment workers working on the pre-analytical phase of clinical testing in hospital laboratories. We conducted eight interviews with workers using futuristic autobiographies. Through our analysis, we identified three themes. Workers envisioned robots to increase their well-being and change blue-collar workers' tasks towards that of automation operators. The latter was perceived to be a change towards doing more meaningful tasks (cognitive tasks, rather than manual labour). Additionally, workers have a need to better cope with structural changes and temporary fluctuations in the workflow. More general-purpose robots could address this.
"
ACM,"Jørgensen, Jonas",Comparing How Soft Robotic Tentacles and an Equivalent Traditional Robot are Described,2023,10.1145/3568294.3580155,"Soft robotics technology has several technical benefits and enables inherently safer human-robot interaction (HRI). However, only few studies have addressed how people experience soft robots and how their embodiment and designs can meaningfully support HRI. The present study explores impressions formed in the physical meeting with soft robots. 94 participants interacted with one out of two soft robots or a similar traditional robot. Following interaction, they were asked what they thought the robot resembled and to describe the robot's appearance using five adjectives. The results show that different categories of items were used to describe each of the three robots' resemblances. Furthermore, a significant difference in the sentiment of the adjectives used was found - positive adjectives were predominantly used to describe the two soft robots, whereas there was an overweight of negative adjectives for the traditional robot.",N/A,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 not satisfied. Title/abstract do not clearly indicate a focus on target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: Comparing How Soft Robotic Tentacles and an Equivalent Traditional Robot are Described
Abstract: Soft robotics technology has several technical benefits and enables inherently safer human-robot interaction (HRI). However, only few studies have addressed how people experience soft robots and how their embodiment and designs can meaningfully support HRI. The present study explores impressions formed in the physical meeting with soft robots. 94 participants interacted with one out of two soft robots or a similar traditional robot. Following interaction, they were asked what they thought the robot resembled and to describe the robot's appearance using five adjectives. The results show that different categories of items were used to describe each of the three robots' resemblances. Furthermore, a significant difference in the sentiment of the adjectives used was found - positive adjectives were predominantly used to describe the two soft robots, whereas there was an overweight of negative adjectives for the traditional robot.
"
ACM,"Patnaik, Amitabh and Dawar, Sunny and Kudal, Pallavi",Industry 5.0: Sustainability Challenges in Fusion of Human and AI,2023,10.1145/3590837.3590903,"Most industrial revolutions aim to separate human labor from that of machines. These machines are referred as ""machines"" or ""robots,"" will eventually take over the majority of the labor-intensive, monotonous, or hazardous tasks currently performed by people. Cleaning robots, for instance, can efficiently clean a room or an office. Future cleaning chores will eventually all be carried out by robots; it is only a question of time. Although currently both humans and robots can perform cleaning tasks, prior data on the rate of mechanization suggests that in the future humans will perform fewer cleaning than robots. The degree of technology and public acceptance of robots determine how quickly automation permeates human lives. Studying how people and robots interact and how it affects society is crucial because robots may have a big impact on civilization. Industry 4.0 has attracted a lot of interest since its debut in 2011. Additionally, the conversation around Industry 5.0 has already begun among some academics and futurists. They present various visions of Industry 5.0. Collaboration between robots and humans is one evolving topic for Industry 5.0. People are unsure of what Industry 5.0's theme will be after some time. However, people can be certain that the coworking of humans and robots will be a significant advancement for society and have a big impact on how people conduct business. Researchers aim at contrasting Industry 4.0 with Industry 5.0 perspectives. Further researchers concentrate on the challenges which people would face when co-working between humans and robots start. Researchers finish the study by briefly discussing potential areas for future investigation.","Artificial intelligence, Cobot, Fusion, Human Robot Interaction (HRI), Sustainability",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 not satisfied. Title/abstract do not clearly indicate a focus on target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: Industry 5.0: Sustainability Challenges in Fusion of Human and AI
Abstract: Most industrial revolutions aim to separate human labor from that of machines. These machines are referred as ""machines"" or ""robots,"" will eventually take over the majority of the labor-intensive, monotonous, or hazardous tasks currently performed by people. Cleaning robots, for instance, can efficiently clean a room or an office. Future cleaning chores will eventually all be carried out by robots; it is only a question of time. Although currently both humans and robots can perform cleaning tasks, prior data on the rate of mechanization suggests that in the future humans will perform fewer cleaning than robots. The degree of technology and public acceptance of robots determine how quickly automation permeates human lives. Studying how people and robots interact and how it affects society is crucial because robots may have a big impact on civilization. Industry 4.0 has attracted a lot of interest since its debut in 2011. Additionally, the conversation around Industry 5.0 has already begun among some academics and futurists. They present various visions of Industry 5.0. Collaboration between robots and humans is one evolving topic for Industry 5.0. People are unsure of what Industry 5.0's theme will be after some time. However, people can be certain that the coworking of humans and robots will be a significant advancement for society and have a big impact on how people conduct business. Researchers aim at contrasting Industry 4.0 with Industry 5.0 perspectives. Further researchers concentrate on the challenges which people would face when co-working between humans and robots start. Researchers finish the study by briefly discussing potential areas for future investigation.
"
ACM,"Li, Ruyi and Guo, Jingfei and Zhang, Xinyi and Zhang, Xuji and Li, Zeqing and Li, Jiannan and Gong, Jiangtao",Guiding Multiple Remote Users in Physical Tasks with Language-driven Robotic Telepresence,2025,10.1145/3749472,"Remote assistance through robotic telepresence could involve both control and memory challenges, particularly in one expert to multiple workers situation. In this work, we proposed a novelty language-driven interface to facilitate remote collaboration through telepresence robots. Through operations and maintenance expert interviews and a scenario simulation study, we identified key pain points in executing one-expert-multiple-workers remote guidance using the telepresence robot and proposed two design goals, which together consist of five sub-design goals with corresponding features. These features were integrated into a standard telepresence robot, resulting in the development of a Collaborative LLM-based Embodied Assistant Robot, named CLEAR Robot. A controlled experiment simulating a remote assembly task of one to two demonstrated that, compared to the standard telepresence robot, CLEAR Robot significantly improved efficiency, reduced cognitive load, facilitated more balanced collaboration, and improved the user experience. We also discuss the impact of language-driven implicit interactions in multi-user collaboration and provide insights for designing robot systems that support one-expert-multiple-workers remote guidance in the future.","human-robot interaction, large language model, remote guidance, telepresence robot",Não,Sim,Diferente,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"The study aligns with all inclusion criteria (IC1-IC5). It discusses collaborative/multifunctional robots in a target sector (IC1), provides evidence of practical application/evaluation (IC2), is within the time period (IC5), and does not meet exclusion criteria.",,Sim,"Title: Guiding Multiple Remote Users in Physical Tasks with Language-driven Robotic Telepresence
Abstract: Remote assistance through robotic telepresence could involve both control and memory challenges, particularly in one expert to multiple workers situation. In this work, we proposed a novelty language-driven interface to facilitate remote collaboration through telepresence robots. Through operations and maintenance expert interviews and a scenario simulation study, we identified key pain points in executing one-expert-multiple-workers remote guidance using the telepresence robot and proposed two design goals, which together consist of five sub-design goals with corresponding features. These features were integrated into a standard telepresence robot, resulting in the development of a Collaborative LLM-based Embodied Assistant Robot, named CLEAR Robot. A controlled experiment simulating a remote assembly task of one to two demonstrated that, compared to the standard telepresence robot, CLEAR Robot significantly improved efficiency, reduced cognitive load, facilitated more balanced collaboration, and improved the user experience. We also discuss the impact of language-driven implicit interactions in multi-user collaboration and provide insights for designing robot systems that support one-expert-multiple-workers remote guidance in the future.
"
ACM,"Unhelkar, Vaibhav V. and Li, Shen and Shah, Julie A.",Decision-Making for Bidirectional Communication in Sequential Human-Robot Collaborative Tasks,2020,10.1145/3319502.3374779,"Communication is critical to collaboration; however, too much of it can degrade performance. Motivated by the need for effective use of a robot's communication modalities, in this work, we present a computational framework that decides if, when, and what to communicate during human-robot collaboration. The framework, titled CommPlan, consists of a model specification process and an execution-time POMDP planner. To address the challenge of collecting interaction data, the model specification process is hybrid : where part of the model is learned from data, while the remainder is manually specified. Given the model, the robot's decision-making is performed computationally during interaction and under partial observability of human's mental states. We implement CommPlan for a shared workspace task, in which the robot has multiple communication options and needs to reason within a short time. Through experiments with human participants, we confirm that CommPlan results in the effective use of communication capabilities and improves human-robot collaboration.","human-in-the-loop learning, human-robot communication, planning under uncertainty",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 not satisfied. Title/abstract do not clearly indicate a focus on target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: Decision-Making for Bidirectional Communication in Sequential Human-Robot Collaborative Tasks
Abstract: Communication is critical to collaboration; however, too much of it can degrade performance. Motivated by the need for effective use of a robot's communication modalities, in this work, we present a computational framework that decides if, when, and what to communicate during human-robot collaboration. The framework, titled CommPlan, consists of a model specification process and an execution-time POMDP planner. To address the challenge of collecting interaction data, the model specification process is hybrid : where part of the model is learned from data, while the remainder is manually specified. Given the model, the robot's decision-making is performed computationally during interaction and under partial observability of human's mental states. We implement CommPlan for a shared workspace task, in which the robot has multiple communication options and needs to reason within a short time. Through experiments with human participants, we confirm that CommPlan results in the effective use of communication capabilities and improves human-robot collaboration.
"
ACM,"Taylor, Angelique and Tanjim, Tauhid and Cao, Huajie and Lee, Hee Rin",Towards Collaborative Crash Cart Robots that Support Clinical Teamwork,2024,10.1145/3610977.3634967,"Healthcare workers (HCWs) face many challenges during bedside care that impede team collaboration and often lead to poor patient outcomes. Robots have the potential to support medical decision-making, help identify medical errors, and deliver supplies to clinical teams in a timely manner. However, there is a lack of knowledge about using robots to support clinical team dynamics despite being used in surgery, healthcare operations, and other applications. To address this gap, we engaged in a co-design process of robots that support clinical teamwork. We collaboratively explore how robots can support clinical teamwork with HCWs. This collaborative process includes understanding the challenges they face during bedside care and envisioning robots that can help mitigate these issues. Our study shows that robots can act as a shared mental model for clinical teams, help close communication gaps, and provide procedural steps to assist HCWs with limited in-hospital experience. This research highlights new ways HRI researchers can deploy robots in acute care settings, as well as define appropriate levels of autonomy to maintain human control in safety-critical settings.","co-design, emergency medicine, robots, teamwork",Não,Sim,Diferente,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.","The study aligns with all inclusion criteria (IC1-IC5). It discusses collaborative/multifunctional robots in a target sector (IC1), provides evidence of practical application/evaluation (IC2), is within the time period (IC5), and does not meet exclusion criteria.",,Sim,"Title: Towards Collaborative Crash Cart Robots that Support Clinical Teamwork
Abstract: Healthcare workers (HCWs) face many challenges during bedside care that impede team collaboration and often lead to poor patient outcomes. Robots have the potential to support medical decision-making, help identify medical errors, and deliver supplies to clinical teams in a timely manner. However, there is a lack of knowledge about using robots to support clinical team dynamics despite being used in surgery, healthcare operations, and other applications. To address this gap, we engaged in a co-design process of robots that support clinical teamwork. We collaboratively explore how robots can support clinical teamwork with HCWs. This collaborative process includes understanding the challenges they face during bedside care and envisioning robots that can help mitigate these issues. Our study shows that robots can act as a shared mental model for clinical teams, help close communication gaps, and provide procedural steps to assist HCWs with limited in-hospital experience. This research highlights new ways HRI researchers can deploy robots in acute care settings, as well as define appropriate levels of autonomy to maintain human control in safety-critical settings.
"
ACM,"Schoen, Andrew and White, Nathan and Henrichs, Curt and Siebert-Evenstone, Amanda and Shaffer, David and Mutlu, Bilge",CoFrame: A System for Training Novice Cobot Programmers,2022,N/A,"The introduction of collaborative robots (cobots) into the workplace has presented both opportunities and challenges for those seeking to utilize their functionality. Prior research has shown that despite the capabilities afforded by cobots, there is a disconnect between those capabilities and the applications that they currently are deployed in, partially due to a lack of effective cobot-focused instruction in the field. Experts who work successfully within this collaborative domain could offer insight into the considerations and process they use to more effectively capture this cobot capability. Using an analysis of expert insights in the collaborative interaction design space, we developed a set of Expert Frames based on these insights and integrated these Expert Frames into a new training and programming system that can be used to teach novice operators to think, program, and troubleshoot in ways that experts do. We present our system and case studies that demonstrate how Expert Frames provide novice users with the ability to analyze and learn from complex cobot application scenarios.","collaborative robots, expert models, novice users, robot programming interfaces, robotics operator training",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 met. Focuses on an excluded sector (e.g., military, domestic) without clear application to target sectors.",Ambas,Não,"Title: CoFrame: A System for Training Novice Cobot Programmers
Abstract: The introduction of collaborative robots (cobots) into the workplace has presented both opportunities and challenges for those seeking to utilize their functionality. Prior research has shown that despite the capabilities afforded by cobots, there is a disconnect between those capabilities and the applications that they currently are deployed in, partially due to a lack of effective cobot-focused instruction in the field. Experts who work successfully within this collaborative domain could offer insight into the considerations and process they use to more effectively capture this cobot capability. Using an analysis of expert insights in the collaborative interaction design space, we developed a set of Expert Frames based on these insights and integrated these Expert Frames into a new training and programming system that can be used to teach novice operators to think, program, and troubleshoot in ways that experts do. We present our system and case studies that demonstrate how Expert Frames provide novice users with the ability to analyze and learn from complex cobot application scenarios.
"
ACM,"Devarakonda, Sachidananda Bharadwaj and Sharma, Soumyajit Sen and Rudra Pal, Abhishek",Design and development of medical cobot to assist surgeon,2024,10.1145/3637843.3637853,"This paper presents an automated collaborative robot that works with a surgeon during a surgical operation incorporated with Machine learning algorithms and Deep learning algorithms to assist the surgeon by performing auxiliary actions. Our main objective is to create a framework for a collaborative nurse robot that upon voice instruction, will recognize and classify the surgical instruments present in the surgical tray and execute manual tasks such as picking up and delivering that instrument to its operator. There have been discussions on the types of co-bots and the types that can embrace the prescribed idea. After visualizing a co-bot model, designing it in CAD software is a crucial initiation to judge the practicality of the robot. The robot was designed to test its navigation before prototyping it. The main objectives to accomplish the working of an assistant medical co-bot is discussed. For object detection Aruco marker that uses Convolution Neural Network is implicated, for voice detection Google's speech recognition system having Deep neural network algorithm is embraced and for training the Co-bot using Arduino libraries is being discussed. Python has been used as a programming language and pyserial to communicate with Arduino from other two systems i.e., voice recognition system and object detection system. This medical Co-bot reflects our effort to lessen stress on surgeon and human error during operation.","Component, assistant nurse, automation, collaborative robots, deep learning, image classification, machine learning, modeling, python, surgical instruments, voice recognition",Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.","IC1 not satisfied. Title/abstract do not clearly indicate a focus on target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: Design and development of medical cobot to assist surgeon
Abstract: This paper presents an automated collaborative robot that works with a surgeon during a surgical operation incorporated with Machine learning algorithms and Deep learning algorithms to assist the surgeon by performing auxiliary actions. Our main objective is to create a framework for a collaborative nurse robot that upon voice instruction, will recognize and classify the surgical instruments present in the surgical tray and execute manual tasks such as picking up and delivering that instrument to its operator. There have been discussions on the types of co-bots and the types that can embrace the prescribed idea. After visualizing a co-bot model, designing it in CAD software is a crucial initiation to judge the practicality of the robot. The robot was designed to test its navigation before prototyping it. The main objectives to accomplish the working of an assistant medical co-bot is discussed. For object detection Aruco marker that uses Convolution Neural Network is implicated, for voice detection Google's speech recognition system having Deep neural network algorithm is embraced and for training the Co-bot using Arduino libraries is being discussed. Python has been used as a programming language and pyserial to communicate with Arduino from other two systems i.e., voice recognition system and object detection system. This medical Co-bot reflects our effort to lessen stress on surgeon and human error during operation.
"
ACM,"Ahumada-Newhart, Veronica and Wood, Taffeta S. and Taylor, Erin R. and Johnson, Francesca O. and Saltzen, Siena and Joshi, Sanjay S.",Study of Telerobot Personalization for Children: Exploring Qualitative Coding of Artwork,2023,10.1145/3568294.3580142,"Social telepresence robots (i.e., telerobots) are used for social and learning experiences by children. However, most (if not all) commercially available telerobot bodies were designed for adults in corporate or healthcare settings. Due to an adult-focused market, telerobot design has typically not considered important factors such as age and physical aspect in the design of robot bodies. To better understand how peer interactants can facilitate the identities of remote children through personalization of robot bodies, we conducted an exploratory study to evaluate collaborative robot personalization. In this study, child participants (N=28) attended an interactive lesson on robots in our society. After the lesson, participants interacted with two telerobots for personalization activities and a robot fashion show. Finally, participants completed an artwork activity on robot design. Initial findings from this study will inform our continued work on telepresence robots for virtual inclusion and improved educational experiences of remote children and their peers.","education, identity, personalization, robot design, robotics, telepresence",Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.","IC2 not satisfied. Abstract does not provide data on practical applications, impacts, HRI analysis, or implementation challenges.",Ambas,Não,"Title: Study of Telerobot Personalization for Children: Exploring Qualitative Coding of Artwork
Abstract: Social telepresence robots (i.e., telerobots) are used for social and learning experiences by children. However, most (if not all) commercially available telerobot bodies were designed for adults in corporate or healthcare settings. Due to an adult-focused market, telerobot design has typically not considered important factors such as age and physical aspect in the design of robot bodies. To better understand how peer interactants can facilitate the identities of remote children through personalization of robot bodies, we conducted an exploratory study to evaluate collaborative robot personalization. In this study, child participants (N=28) attended an interactive lesson on robots in our society. After the lesson, participants interacted with two telerobots for personalization activities and a robot fashion show. Finally, participants completed an artwork activity on robot design. Initial findings from this study will inform our continued work on telepresence robots for virtual inclusion and improved educational experiences of remote children and their peers.
"
ACM,"Rincon, Gema and Nicolas, Carlos-F. and Poggi, Tomaso",Improving Availability in a Robotic Application without Loss of Safety,2024,10.1145/3706601.3706616,"In our automated and industrialized world, ensuring safety in human-robot interaction is essential, a complex engineering task especially in dynamic environments. The widespread adoption of collaborative and autonomous robots across various sectors underscores the critical need for robust safety measures.This article examines the current state of safety in collaborative robotics and proposes a strategy for assessing the safety of the robot task against the indications of existing standards. If the task is not considered safe in the current environment, a new task is sought for the robot, which increases its availability. These addresses dynamic environments where robots and humans coexist, allowing the autonomous robot to make task decisions based on safety considerations.","autonomous robots, availability, collaborative robots, safety",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 not satisfied. Title/abstract do not clearly indicate a focus on target sectors (logistics, healthcare, field services).",Ambas,Não,"Title: Improving Availability in a Robotic Application without Loss of Safety
Abstract: In our automated and industrialized world, ensuring safety in human-robot interaction is essential, a complex engineering task especially in dynamic environments. The widespread adoption of collaborative and autonomous robots across various sectors underscores the critical need for robust safety measures.This article examines the current state of safety in collaborative robotics and proposes a strategy for assessing the safety of the robot task against the indications of existing standards. If the task is not considered safe in the current environment, a new task is sought for the robot, which increases its availability. These addresses dynamic environments where robots and humans coexist, allowing the autonomous robot to make task decisions based on safety considerations.
"
ACM,"Koike, Amy and Mutlu, Bilge",Exploring the Design Space of Extra-Linguistic Expression for Robots,2023,10.1145/3563657.3595968,"In this paper, we explore the new design space of extra-linguistic cues inspired by graphical tropes used in graphic novels and animation to enhance the expressiveness of social robots. We identified a set of cues that can be used to generate expressions, including smoke/steam/fog, water droplets, and bubbles, and prototyped devices that can generate these fluid expressions for a robot. We conducted design sessions where eight designers explored the use and utility of these expressions in conveying the robot’s internal states in various design scenarios. Our analysis of the 22 designs, the associated design justifications, and the interviews with designers revealed patterns in how each form of expression was used, how they were combined with nonverbal cues, and where the participants drew their inspiration from. These findings informed the design of an integrated module called EmoPack, which can be used to augment the expressive capabilities of any robot platform.","design tools, expressivity, extra-linguistic cues, graphical tropes, human-robot interaction, interaction design",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 met. Focuses on an excluded sector (e.g., military, domestic) without clear application to target sectors.",Ambas,Não,"Title: Exploring the Design Space of Extra-Linguistic Expression for Robots
Abstract: In this paper, we explore the new design space of extra-linguistic cues inspired by graphical tropes used in graphic novels and animation to enhance the expressiveness of social robots. We identified a set of cues that can be used to generate expressions, including smoke/steam/fog, water droplets, and bubbles, and prototyped devices that can generate these fluid expressions for a robot. We conducted design sessions where eight designers explored the use and utility of these expressions in conveying the robot’s internal states in various design scenarios. Our analysis of the 22 designs, the associated design justifications, and the interviews with designers revealed patterns in how each form of expression was used, how they were combined with nonverbal cues, and where the participants drew their inspiration from. These findings informed the design of an integrated module called EmoPack, which can be used to augment the expressive capabilities of any robot platform.
"
ACM,"Ajaykumar, Gopika and Steele, Maureen and Huang, Chien-Ming",A Survey on End-User Robot Programming,2021,10.1145/3466819,"As robots interact with a broader range of end-users, end-user robot programming has helped democratize robot programming by empowering end-users who may not have experience in robot programming to customize robots to meet their individual contextual needs. This article surveys work on end-user robot programming, with a focus on end-user program specification. It describes the primary domains, programming phases, and design choices represented by the end-user robot programming literature. The survey concludes by highlighting open directions for further investigation to enhance and widen the reach of end-user robot programming systems.","End-user robot programming, human-robot interaction, end-user programming",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 met. The abstract indicates this is a review, survey, or other excluded publication type.",Ambas,Não,"Title: A Survey on End-User Robot Programming
Abstract: As robots interact with a broader range of end-users, end-user robot programming has helped democratize robot programming by empowering end-users who may not have experience in robot programming to customize robots to meet their individual contextual needs. This article surveys work on end-user robot programming, with a focus on end-user program specification. It describes the primary domains, programming phases, and design choices represented by the end-user robot programming literature. The survey concludes by highlighting open directions for further investigation to enhance and widen the reach of end-user robot programming systems.
"
ACM,"Schoen, Andrew and Henrichs, Curt and Strohkirch, Mathias and Mutlu, Bilge",Authr: A Task Authoring Environment for Human-Robot Teams,2020,10.1145/3379337.3415872,"Collaborative robots promise to transform work across many industries and promote human-robot teaming as a novel paradigm. However, realizing this promise requires the understanding of how existing tasks, developed for and performed by humans, can be effectively translated into tasks that robots can singularly or human-robot teams can collaboratively perform. In the interest of developing tools that facilitate this process we present Authr, an end-to-end task authoring environment that assists engineers at manufacturing facilities in translating existing manual tasks into plans applicable for human-robot teams and simulates these plans as they would be performed by the human and robot. We evaluated Authr with two user studies, which demonstrate the usability and effectiveness of Authr as an interface and the benefits of assistive task allocation methods for designing complex tasks for human-robot teams. We discuss the implications of these findings for the design of software tools for authoring human-robot collaborative plans.","authoring, human-robot collaboration, task allocation, visual programming",Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.","IC2 not satisfied. Abstract does not provide data on practical applications, impacts, HRI analysis, or implementation challenges.",Ambas,Não,"Title: Authr: A Task Authoring Environment for Human-Robot Teams
Abstract: Collaborative robots promise to transform work across many industries and promote human-robot teaming as a novel paradigm. However, realizing this promise requires the understanding of how existing tasks, developed for and performed by humans, can be effectively translated into tasks that robots can singularly or human-robot teams can collaboratively perform. In the interest of developing tools that facilitate this process we present Authr, an end-to-end task authoring environment that assists engineers at manufacturing facilities in translating existing manual tasks into plans applicable for human-robot teams and simulates these plans as they would be performed by the human and robot. We evaluated Authr with two user studies, which demonstrate the usability and effectiveness of Authr as an interface and the benefits of assistive task allocation methods for designing complex tasks for human-robot teams. We discuss the implications of these findings for the design of software tools for authoring human-robot collaborative plans.
"
ACM,"Abioye, Ayodeji O. and Hunt, William and Gu, Yue and Schneiders, Eike and Naiseh, Mohammad and Archibald, Blair and Sevegnani, Michele and Ramchurn, Sarvapali D. and Fischer, Joel E. and Soorati, Mohammad D.",A User Study Evaluation of Predictive Formal Modelling at Runtime in Human-Swarm Interaction,2025,10.1145/3727989,"Formal Modelling is often used as part of the design and testing process of software development to ensure that components operate within suitable bounds even in unexpected circumstances. We conducted a user study evaluation of predictive formal modelling (PFM) at runtime in a human-swarm mission to determine the benefit of PFM on performance and human-swarm interaction. A total of 180 participants were recruited to perform the role of aerial swarm operators delivering parcels to target locations in a simulation environment. The PFM model was integrated into the simulation software to inform the operator of the estimated mission completion time given the current number of drones deployed. The operator could increase the number of parcels delivered in any timestep by adding drones, which also increased costs, thus requiring the use of the minimum number of drones necessary to complete the task in the given time. We collected user feedback using standard survey questionnaires and measured performance using data obtained from the Human and Robot Interactive Swarm (HARIS) simulator. Our results show that PFM increased the performance of the human swarm team without significantly increasing the operators’ workload or affecting the system’s usability.","Human-Robot Interaction (HRI), Human-Swarm Interaction (HSI), Predictive Formal Modelling (PFM), Workload, Usability",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 met. The abstract indicates this is a review, survey, or other excluded publication type.",Ambas,Não,"Title: A User Study Evaluation of Predictive Formal Modelling at Runtime in Human-Swarm Interaction
Abstract: Formal Modelling is often used as part of the design and testing process of software development to ensure that components operate within suitable bounds even in unexpected circumstances. We conducted a user study evaluation of predictive formal modelling (PFM) at runtime in a human-swarm mission to determine the benefit of PFM on performance and human-swarm interaction. A total of 180 participants were recruited to perform the role of aerial swarm operators delivering parcels to target locations in a simulation environment. The PFM model was integrated into the simulation software to inform the operator of the estimated mission completion time given the current number of drones deployed. The operator could increase the number of parcels delivered in any timestep by adding drones, which also increased costs, thus requiring the use of the minimum number of drones necessary to complete the task in the given time. We collected user feedback using standard survey questionnaires and measured performance using data obtained from the Human and Robot Interactive Swarm (HARIS) simulator. Our results show that PFM increased the performance of the human swarm team without significantly increasing the operators’ workload or affecting the system’s usability.
"
ACM,"Jaiswal, Ashish and Nale, Gaurav and An, Qiyuan and Reza Pavel, Hamza and Karim, Enamul and Acharya, Sneh and Makedon, Fillia",An Assistive Robotic System for Cognitive State Assessment in Individuals with Spinal Cord Injury,2024,10.1145/3652037.3652068,"We introduce an innovative assistive robotic setup tailored for assessing the cognitive state of individuals with spinal cord injuries (SCI) during their daily activities. Utilizing physiological sensors such as ECG, EEG, and EDA, along with cameras for facial expression, our system is designed to detect and evaluate cognitive fatigue in participants as they engage with a collaborative robot. Specifically, two tasks, Cooking Pasta Sauce and Getting Ready for Work–have been crafted to gather data on cognitive states. Participants interact with the robot using natural language (English) to perform tasks, while their physiological responses, facial expressions, and activities are recorded. The study comprises three phases of cognitive fatigue: baseline, moderate, and severe. Cognitive fatigue is induced through the N-back task paradigm, and its severity is assessed using the Visual Analogue Scale for Fatigue (VAS-F) questionnaire. Our system is designed to intervenes during the tasks based on the detected cognitive fatigue levels. In this paper, we concentrate on validating the cognitive fatigue detection system using only physiological sensors during task performance, achieving an accuracy of 85.7% and a recall of 0.87. We provide detailed insights into the system design and present a preliminary analysis of the gathered data.","assistive robots, cognitive fatigue, human computer interface, multimodal system, physiological sensors",Não,Sim,Diferente,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.",Forte alinhamento. O estudo discute um robô colaborativo (IC1) de assistência/saúde (IC1) para indivíduos com lesão medular. Ele fornece dados sobre a validação do sistema e seu design (IC2). O ano de 2024 atende ao IC5.,,Sim,"Title: An Assistive Robotic System for Cognitive State Assessment in Individuals with Spinal Cord Injury
Abstract: We introduce an innovative assistive robotic setup tailored for assessing the cognitive state of individuals with spinal cord injuries (SCI) during their daily activities. Utilizing physiological sensors such as ECG, EEG, and EDA, along with cameras for facial expression, our system is designed to detect and evaluate cognitive fatigue in participants as they engage with a collaborative robot. Specifically, two tasks, Cooking Pasta Sauce and Getting Ready for Work–have been crafted to gather data on cognitive states. Participants interact with the robot using natural language (English) to perform tasks, while their physiological responses, facial expressions, and activities are recorded. The study comprises three phases of cognitive fatigue: baseline, moderate, and severe. Cognitive fatigue is induced through the N-back task paradigm, and its severity is assessed using the Visual Analogue Scale for Fatigue (VAS-F) questionnaire. Our system is designed to intervenes during the tasks based on the detected cognitive fatigue levels. In this paper, we concentrate on validating the cognitive fatigue detection system using only physiological sensors during task performance, achieving an accuracy of 85.7% and a recall of 0.87. We provide detailed insights into the system design and present a preliminary analysis of the gathered data.
"
ACM,"Stegner, Laura and Senft, Emmanuel and Mutlu, Bilge",Situated Participatory Design: A Method for In Situ Design of Robotic Interaction with Older Adults,2023,10.1145/3544548.3580893,"We present a participatory design method to design human-robot interactions with older adults and its application through a case study of designing an assistive robot for a senior living facility. The method, called Situated Participatory Design (sPD), was designed considering the challenges of working with older adults and involves three phases that enable designing and testing use scenarios through realistic, iterative interactions with the robot. In design sessions with nine residents and three caregivers, we uncovered a number of insights about sPD that help us understand its benefits and limitations. For example, we observed how designs evolved through iterative interactions and how early exposure to the robot helped participants consider using the robot in their daily life. With sPD, we aim to help future researchers to increase and deepen the participation of older adults in designing assistive technologies.","Human-robot interaction, accessibility, assistive robots, design methods, field study, older adults, participatory design",Sim,Sim,Igual,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.","Forte alinhamento. O estudo apresenta um estudo de caso (IC2) para projetar HRI (IC1) com um robô assistivo (IC1) em um contexto de saúde (instalação para idosos, IC1). O ano de 2023 atende ao IC5.",Ambas,Sim,"Title: Situated Participatory Design: A Method for In Situ Design of Robotic Interaction with Older Adults
Abstract: We present a participatory design method to design human-robot interactions with older adults and its application through a case study of designing an assistive robot for a senior living facility. The method, called Situated Participatory Design (sPD), was designed considering the challenges of working with older adults and involves three phases that enable designing and testing use scenarios through realistic, iterative interactions with the robot. In design sessions with nine residents and three caregivers, we uncovered a number of insights about sPD that help us understand its benefits and limitations. For example, we observed how designs evolved through iterative interactions and how early exposure to the robot helped participants consider using the robot in their daily life. With sPD, we aim to help future researchers to increase and deepen the participation of older adults in designing assistive technologies.
"
ACM,"Garrett, Rachael and Brundell, Patrick and Castle-Green, Simon and Hawkins, Kat and Tennent, Paul and Zhou, Feng and Lampinen, Airi and H""{o}""{o}k, Kristina and Benford, Steve",Friction in Processual Ethics: Reconfiguring Ethical Relations in Interdisciplinary Research,2025,10.1145/3706598.3714123,"Friction – disagreement and breakdown – is an omnipresent aspect of conducting interdisciplinary research yet is rarely presented in formal research reporting. We analyse a performance-led research process where professional dancers with different disabilities explored how to improvise with an industrial robot, with the support of an interdisciplinary team of human-computer and human-robot interaction researchers. We focus on one site of friction in our research process; how to dance – safely – with robots? By presenting our research process, we exemplify the different ways in which we encountered this friction and how we reconfigured the research process around it. We contribute five ways in which we arrived at a generative ethical outcome, which may be helpful in productively engaging with friction in interdisciplinary collaboration.","ethics, processual ethics, felt ethics, research ethics, artist-led research, somabotics, robots, dance, disability, crip feminism, friction, misalignment",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"EC2 atendido. O contexto do estudo são ""dançarinos"" (entretenimento/arte), que é um setor excluído. Ele não demonstra aplicabilidade clara à logística, saúde ou serviços de campo.",Ambas,Não,"Title: Friction in Processual Ethics: Reconfiguring Ethical Relations in Interdisciplinary Research
Abstract: Friction – disagreement and breakdown – is an omnipresent aspect of conducting interdisciplinary research yet is rarely presented in formal research reporting. We analyse a performance-led research process where professional dancers with different disabilities explored how to improvise with an industrial robot, with the support of an interdisciplinary team of human-computer and human-robot interaction researchers. We focus on one site of friction in our research process; how to dance – safely – with robots? By presenting our research process, we exemplify the different ways in which we encountered this friction and how we reconfigured the research process around it. We contribute five ways in which we arrived at a generative ethical outcome, which may be helpful in productively engaging with friction in interdisciplinary collaboration.
"
ACM,"Krishna Sharma, Vinay and Saluja, Kamalpreet and Mollyn, Vimal and Biswas, Pradipta",Eye Gaze Controlled Robotic Arm for Persons with Severe Speech and Motor Impairment,2020,10.1145/3379155.3391324,Recent advancements in the field of robotics offers new promises for people with different range of abilities although making a human robot interface for people with severe disabilities is challenging. This paper describes the design and development of an eye gaze controlled interface for users with severe speech and motor impairment to manipulate a robotic arm. Two user studies were reported on pick and drop and reachability studies involving users with severe speech and motor impairment. Using the eye gaze controlled interface users could undertake representative pick and drop task at an average duration less than 15 secs and reach a randomly designated target within 60 secs.,"Eye gaze tracking, Human-Robot Interaction, assistive technology",Não,Sim,Diferente,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"Forte alinhamento. O estudo discute um robô assistivo (saúde) (IC1) e fornece dados de estudos de usuário sobre seu desempenho (impacto medido/eficiência, IC2). O ano de 2020 atende ao IC5.",,Sim,"Title: Eye Gaze Controlled Robotic Arm for Persons with Severe Speech and Motor Impairment
Abstract: Recent advancements in the field of robotics offers new promises for people with different range of abilities although making a human robot interface for people with severe disabilities is challenging. This paper describes the design and development of an eye gaze controlled interface for users with severe speech and motor impairment to manipulate a robotic arm. Two user studies were reported on pick and drop and reachability studies involving users with severe speech and motor impairment. Using the eye gaze controlled interface users could undertake representative pick and drop task at an average duration less than 15 secs and reach a randomly designated target within 60 secs.
"
ACM,"Marvel, Jeremy A. et al.",Introduction to the Special Issue on Test Methods for Human-Robot Teaming Performance Evaluations,2022,10.1145/3544303,"This special issue of the Transactions on Human-Robot Interaction highlights, documents, and explores the metrics, test methods, and artifacts used in human-robot interaction (HRI) research. This collection of articles brings to attention the commonalities between the application of measurement science for the assessment and assurance of human-centric robotics in a variety of application domains, including industry, education, and defense. This special issue draws specific attention to the use and impact of metrology toward the advancement of HRI technologies and algorithms, and it promotes the application of measurement science toward the benchmarking and replication of HRI research. Special attention is given to the use cases, data sets, test methodologies, measurement techniques, metrics, and statistical analyses used to evaluate system performance.","Test methods and metrics, repeatability studies, performance measures, benchmarking, use cases, data sets",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"EC4 atendido. O título e o resumo identificam este artigo como uma ""Introdução à Edição Especial"", que é uma forma de editorial, não um artigo de pesquisa primário.",Ambas,Não,"Title: Introduction to the Special Issue on Test Methods for Human-Robot Teaming Performance Evaluations
Abstract: This special issue of the Transactions on Human-Robot Interaction highlights, documents, and explores the metrics, test methods, and artifacts used in human-robot interaction (HRI) research. This collection of articles brings to attention the commonalities between the application of measurement science for the assessment and assurance of human-centric robotics in a variety of application domains, including industry, education, and defense. This special issue draws specific attention to the use and impact of metrology toward the advancement of HRI technologies and algorithms, and it promotes the application of measurement science toward the benchmarking and replication of HRI research. Special attention is given to the use cases, data sets, test methodologies, measurement techniques, metrics, and statistical analyses used to evaluate system performance.
"
ACM,"Cheon, EunJeong et al.",Robots as a Place for Socializing: Influences of Collaborative Robots on Social Dynamics In- and Outside the Production Cells,2022,10.1145/3555558,"Introducing robots in the workplace entails new practices and configurations at the individual, organizational, and social levels. Prior work has focused on how robots may have an immediate effect on individual employees or tasks rather than collectively influencing employees or the organizations they work for gradually over time. By drawing on fourteen in-situ interviews with six collaborative robot (cobot) operators at a Danish manufacturing company, this paper investigates how cobots in the manufacturing context may engage broader interactions beyond the robot-operator interaction. Our focus includes spatial configurations centering around the cobots, social interactions between employees, and information flow through, within, and outside the production cells. Introducing and implementing cobots in the workplace has social dynamics at its core, which we explore in depth. This paper argues that the design of cobots and the environment around them should accommodate the possibility of more complicated social and organizational changes brought about by these robots. Lastly, we discuss research and design implications for the future of workplaces involving robots.","collaborative robots, social dynamics, the future of work, workers, workplaces",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 não atendido. Embora o estudo se concentre em ""robôs colaborativos (cobots)"", o contexto é uma ""empresa de manufatura"" e ""células de produção"". Isso não se alinha aos setores-alvo necessários (logística, saúde ou serviços de campo).",Ambas,Não,"Title: Robots as a Place for Socializing: Influences of Collaborative Robots on Social Dynamics In- and Outside the Production Cells
Abstract: Introducing robots in the workplace entails new practices and configurations at the individual, organizational, and social levels. Prior work has focused on how robots may have an immediate effect on individual employees or tasks rather than collectively influencing employees or the organizations they work for gradually over time. By drawing on fourteen in-situ interviews with six collaborative robot (cobot) operators at a Danish manufacturing company, this paper investigates how cobots in the manufacturing context may engage broader interactions beyond the robot-operator interaction. Our focus includes spatial configurations centering around the cobots, social interactions between employees, and information flow through, within, and outside the production cells. Introducing and implementing cobots in the workplace has social dynamics at its core, which we explore in depth. This paper argues that the design of cobots and the environment around them should accommodate the possibility of more complicated social and organizational changes brought about by these robots. Lastly, we discuss research and design implications for the future of workplaces involving robots.
"
ACM,"Reyes-Cruz, Gisela et al.","Please Follow Me to the Next Stop: A Case Study of Planning, Deploying and Researching a Robot-Guided Tour in a Museum in the UK",2025,10.1145/3706599.3706660,"Robots are increasingly being used in public spaces in the UK. Museums and galleries are a noteworthy setting for exploring robot adoption, such as for providing guided tours or enabling remote visits. Although robots have been deployed in museums in the past, there is arguably little information about what is involved in the process of both deploying and researching them. In this case study paper, we present our experiences and lessons learnt from conducting a research study of a robot-guided tour in a museum in the UK. We describe the process and stakeholders, and discuss the challenges and opportunities that emerged throughout. We provide recommendations for Human-Robot Interaction researchers hoping to move their investigations out of the lab and into the real world.","robot guided tour, museums and galleries, robot deployment, co-creation, stakeholder involvement",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 atendido. O contexto do estudo é um ""museu"", que se enquadra nos setores excluídos (entretenimento/espaço público) e não é um dos setores-alvo (logística, saúde ou serviços de campo).",Ambas,Não,"Title: Please Follow Me to the Next Stop: A Case Study of Planning, Deploying and Researching a Robot-Guided Tour in a Museum in the UK
Abstract: Robots are increasingly being used in public spaces in the UK. Museums and galleries are a noteworthy setting for exploring robot adoption, such as for providing guided tours or enabling remote visits. Although robots have been deployed in museums in the past, there is arguably little information about what is involved in the process of both deploying and researching them. In this case study paper, we present our experiences and lessons learnt from conducting a research study of a robot-guided tour in a museum in the UK. We describe the process and stakeholders, and discuss the challenges and opportunities that emerged throughout. We provide recommendations for Human-Robot Interaction researchers hoping to move their investigations out of the lab and into the real world.
"
ACM,Ausente,CHIWORK '25 Adjunct: Adjunct Proceedings of the 4th Annual Symposium on Human-Computer Interaction for Work,2025,10.1145/3707640,"Welcome to CHIWORK 2025, the 4th Annual Symposium on Human-Computer Interaction for Work to be held at Centrum Wiskunde & Informatica (CWI) in Amsterdam, The Netherlands.

CHIWORK is the annual symposium that aims to grow our understanding of how Human-Computer Interaction (HCI) will support work in the future. Advances in Computing technology are rapidly changing the way we work. Human-computer interaction (HCI) is a critical aspect of this ongoing change, as a way to support workers in successfully navigating fast-paced changes in working environments, which might include novel computing devices, new sensing and work(er) wellbeing and performance measurement techniques, interacting with AI agents, and the new roles for people in work environments where automation is increasing.
",Ausente,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"EC4 atendido. O título identifica isso como ""Anais Adjuntos"", que é uma coleção ou editorial, não um artigo de conferência ou periódico completo revisado por pares.",Ambas,Não,"Title: CHIWORK '25 Adjunct: Adjunct Proceedings of the 4th Annual Symposium on Human-Computer Interaction for Work
Abstract: Welcome to CHIWORK 2025, the 4th Annual Symposium on Human-Computer Interaction for Work to be held at Centrum Wiskunde & Informatica (CWI) in Amsterdam, The Netherlands.

CHIWORK is the annual symposium that aims to grow our understanding of how Human-Computer Interaction (HCI) will support work in the future. Advances in Computing technology are rapidly changing the way we work. Human-computer interaction (HCI) is a critical aspect of this ongoing change, as a way to support workers in successfully navigating fast-paced changes in working environments, which might include novel computing devices, new sensing and work(er) wellbeing and performance measurement techniques, interacting with AI agents, and the new roles for people in work environments where automation is increasing.

"
ACM,"Cheon, EunJeong et al.",Working with Bounded Collaboration: A Qualitative Study on How Collaboration is Co-constructed around Collaborative Robots in Industry,2022,10.1145/3555094,"We investigate how collaboration is understood and configured in industrial workplaces with collaborative robots (cobots). Through a qualitative analysis of 115 case studies of companies using cobots and 14 semi-structured interviews with cobot manufacturers and users, we examine the usages of cobots in the manufacturing industry over the entire temporal spectrum from pre-introduction to completed implementation. By synthesizing diverse stakeholders' perspectives, we present a set of main findings; key roles of a few supportive production workers during the adoption of cobots; a fragmentation of work tasks and the resulting loss of job identity among workers; the disunified meaning of ""collaboration"" which is under constant development; and the collaborative space and the working rhythms between production workers and cobots. By reconsidering what collaboration means in the workplace with cobots, we propose the concept of bounded collaboration, which means that the anticipated collaboration is manifested in a partial and limited manner within a collaborative technology. Finally, we provide practical suggestions for examining and supporting organizations and users in their adoption of cobots.","bounded collaboration, cobots, collaborative robots, manufacturing industry, the future of work",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 não atendido. Embora o estudo se concentre em ""robôs colaborativos (cobots)"", o contexto é a ""indústria de manufatura"" em geral, que não é um dos setores-alvo especificados (logística, saúde ou serviços de campo).",Ambas,Não,"Title: Working with Bounded Collaboration: A Qualitative Study on How Collaboration is Co-constructed around Collaborative Robots in Industry
Abstract: We investigate how collaboration is understood and configured in industrial workplaces with collaborative robots (cobots). Through a qualitative analysis of 115 case studies of companies using cobots and 14 semi-structured interviews with cobot manufacturers and users, we examine the usages of cobots in the manufacturing industry over the entire temporal spectrum from pre-introduction to completed implementation. By synthesizing diverse stakeholders' perspectives, we present a set of main findings; key roles of a few supportive production workers during the adoption of cobots; a fragmentation of work tasks and the resulting loss of job identity among workers; the disunified meaning of ""collaboration"" which is under constant development; and the collaborative space and the working rhythms between production workers and cobots. By reconsidering what collaboration means in the workplace with cobots, we propose the concept of bounded collaboration, which means that the anticipated collaboration is manifested in a partial and limited manner within a collaborative technology. Finally, we provide practical suggestions for examining and supporting organizations and users in their adoption of cobots.
"
ACM,"Cheon, EunJeong et al.",Human-Machine Partnerships in the Future of Work: Exploring the Role of Emerging Technologies in Future Workplaces,2021,10.1145/3462204.3481726,"Technologies in the workplace have been a major focus of CSCW, including studies that investigate technologies for collaborative work, explore new work environments, and address the importance of political and organizational aspects of technologies in workplaces. Emerging technologies, such as AI and robotics, have been deployed in various workplaces, and their proliferation is rapidly expanding. These technologies have not only changed the nature of work but also reinforced power and social dynamics within workplaces, requiring us to rethink the legitimate relationship between emerging technologies and human workers. It will be critical to the development of equitable future work arrangements to identify how these emerging technologies will develop relationships with human workers who have limited power and voice in their workplaces. How can these emerging technologies develop mutually beneficial partnerships with human workers? In this one-day workshop, we seek to illustrate the meaning of human-machine partnerships (HMP) by highlighting that how we define HMP may shape the design of future robots at work. By incorporating interdisciplinary perspectives, we aim to develop a taxonomy of HMP by which we can broaden our relationship with embodied agents but also evaluate and reconsider existing theoretical, methodological, and epistemological challenges in HMP research.","agency, automation, embodied AI agent, partnerships, the future of work",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"EC4 atendido. O resumo identifica este como um artigo de ""workshop de um dia"", não um artigo completo de conferência ou periódico. Ele também se concentra em resultados teóricos (taxonomia) em vez de aplicação prática (EC3).",Ambas,Não,"Title: Human-Machine Partnerships in the Future of Work: Exploring the Role of Emerging Technologies in Future Workplaces
Abstract: Technologies in the workplace have been a major focus of CSCW, including studies that investigate technologies for collaborative work, explore new work environments, and address the importance of political and organizational aspects of technologies in workplaces. Emerging technologies, such as AI and robotics, have been deployed in various workplaces, and their proliferation is rapidly expanding. These technologies have not only changed the nature of work but also reinforced power and social dynamics within workplaces, requiring us to rethink the legitimate relationship between emerging technologies and human workers. It will be critical to the development of equitable future work arrangements to identify how these emerging technologies will develop relationships with human workers who have limited power and voice in their workplaces. How can these emerging technologies develop mutually beneficial partnerships with human workers? In this one-day workshop, we seek to illustrate the meaning of human-machine partnerships (HMP) by highlighting that how we define HMP may shape the design of future robots at work. By incorporating interdisciplinary perspectives, we aim to develop a taxonomy of HMP by which we can broaden our relationship with embodied agents but also evaluate and reconsider existing theoretical, methodological, and epistemological challenges in HMP research.
"
ACM,"Piskopani, Anna Maria et al.",Using a Knowledge Caf'{e} approach as a public engagement activity for raising awareness of data protection issues in robotics for health and social care,2023,10.1145/3597512.3599700,"Robotics and Artificial Intelligence (RAI) offers the opportunity to ameliorate the quality of life for people with health issues. However, there are still considerable barriers linked to the lack of acceptance of these technologies, particularly as they require intensive personal data collection and analysis for monitoring health. We organized two public engagement events for science communication, adopting a Knowledge Café model with the intention of helping people get a better understanding of the potential benefits of these technologies and privacy risks. While personal data plays an important role in the development of these technologies, there has been insufficient public awareness and engagement to ensure informed consent. By hosting Knowledge Cafés, our aim is to provide scenarios of how Robotics and AI could support health and well-being, while surfacing the risks. Our objective was to highlight and discuss ethical, social and legal concerns, facilitating members of the general public to engage with different perspectives, generate ideas to mitigate these risks, together with gaining a deeper understanding of their needs and preferences for beneficial uses of RAI in healthcare.","artificial intelligence, data protection, robotics",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC2 não atendido. O foco do estudo não é a aplicação, impacto, HRI ou tecnologia dos robôs, mas sim uma ""atividade de engajamento público"" (Knowledge Café) para discutir as questões éticas e de proteção de dados relacionadas a eles.",Ambas,Não,"Title: Using a Knowledge Caf'{e} approach as a public engagement activity for raising awareness of data protection issues in robotics for health and social care
Abstract: Robotics and Artificial Intelligence (RAI) offers the opportunity to ameliorate the quality of life for people with health issues. However, there are still considerable barriers linked to the lack of acceptance of these technologies, particularly as they require intensive personal data collection and analysis for monitoring health. We organized two public engagement events for science communication, adopting a Knowledge Café model with the intention of helping people get a better understanding of the potential benefits of these technologies and privacy risks. While personal data plays an important role in the development of these technologies, there has been insufficient public awareness and engagement to ensure informed consent. By hosting Knowledge Cafés, our aim is to provide scenarios of how Robotics and AI could support health and well-being, while surfacing the risks. Our objective was to highlight and discuss ethical, social and legal concerns, facilitating members of the general public to engage with different perspectives, generate ideas to mitigate these risks, together with gaining a deeper understanding of their needs and preferences for beneficial uses of RAI in healthcare.
"
ACM,"Chun, Bohkyung e Knight, Heather",The Robot Makers: An Ethnography of Anthropomorphism at a Robotics Company,2020,10.1145/3377343,"This article is an ethnographic exploration of robot anthropomorphism at a robotics company. It draws on a 10-month participatory ethnography among a robotics company, an anthropologist, and a social robotics research lab. In contrast to psychological methods, this anthropological participatory ethnography integrates all stakeholders’ insights, offering holistic understandings of robots’ in situ operations throughout the fieldwork, data-sharing, interviews, and analysis. In particular, this article unravels employee social constructions of the company’s self-driving factory transport vehicles, “the robots.” These robots are deployed across a variety of warehouses and factories in North America. Our results involve an assessment of six teams at the robotics company’s headquarters: those testing robots, those developing their hardware and software, and those working with customers. We unpack trends of anthropomorphism for each of these teams and across the company.","Collaborative industrial robots, collaborative manufacturing, ethnography in HRI, expressive motions, ...",Não,Sim,Diferente,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"Forte alinhamento. O estudo é uma etnografia (IC2) de HRI (antropomorfismo, IC2) relacionada a ""veículos de transporte de fábrica autônomos"" implantados em ""armazéns"" (logística, IC1). O ano de 2020 atende ao IC5.",,Sim,"Title: The Robot Makers: An Ethnography of Anthropomorphism at a Robotics Company
Abstract: This article is an ethnographic exploration of robot anthropomorphism at a robotics company. It draws on a 10-month participatory ethnography among a robotics company, an anthropologist, and a social robotics research lab. In contrast to psychological methods, this anthropological participatory ethnography integrates all stakeholders’ insights, offering holistic understandings of robots’ in situ operations throughout the fieldwork, data-sharing, interviews, and analysis. In particular, this article unravels employee social constructions of the company’s self-driving factory transport vehicles, “the robots.” These robots are deployed across a variety of warehouses and factories in North America. Our results involve an assessment of six teams at the robotics company’s headquarters: those testing robots, those developing their hardware and software, and those working with customers. We unpack trends of anthropomorphism for each of these teams and across the company.
"
ACM,"Wang, Haoqi et al.",Overview and Analysis of the Application of Digital Twin-based Human-Machine Collaboration in the Product Development Process,2025,10.1145/3696474.3696485,"In the era of Industry 5.0, the collaboration between humans and machines is vital for achieving smart manufacturing that is centered on human needs. This necessitates production services that are more efficient, precise, and safe. Digital twin (DT) technology plays a critical role in facilitating this collaboration by providing a virtual representation of physical systems, allowing for real-time data analysis and decision-making. This paper explores how DT-based human-machine collaboration (HMC) can significantly improve the product development process (PDP). By examining the advantages of DT-based HMC, the paper establishes correlations with key factors such as cost, time, and quality, grounded in the ten knowledge areas outlined in the Project Management Institute's Project Management Body of Knowledge. Additionally, the paper analyzes the practical applications of project management principles related to DT-based HMC within enterprises. Through the application of these project management knowledge areas, the research assesses the likelihood of successful implementation of DT-based HMC in the PDP. The findings highlight that integrating DT technology with effective project management practices can lead to substantial enhancements in manufacturing processes, aligning them more closely with human-centric objectives. Ultimately, this study underscores the transformative potential of digital twins in fostering a collaborative environment that improves product development efficiency, quality, and overall competitiveness in the industry.","Advantages, Digital twin, Human-machine collaboration, Overview, Product development process, ...",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 não atendido e EC4 provavelmente atendido. O contexto é ""processo de desenvolvimento de produto"", não os setores-alvo (logística, saúde, serviços de campo). Além disso, o título ""Visão Geral e Análise"" sugere que pode ser um artigo de revisão (EC4).",Ambas,Não,"Title: Overview and Analysis of the Application of Digital Twin-based Human-Machine Collaboration in the Product Development Process
Abstract: In the era of Industry 5.0, the collaboration between humans and machines is vital for achieving smart manufacturing that is centered on human needs. This necessitates production services that are more efficient, precise, and safe. Digital twin (DT) technology plays a critical role in facilitating this collaboration by providing a virtual representation of physical systems, allowing for real-time data analysis and decision-making. This paper explores how DT-based human-machine collaboration (HMC) can significantly improve the product development process (PDP). By examining the advantages of DT-based HMC, the paper establishes correlations with key factors such as cost, time, and quality, grounded in the ten knowledge areas outlined in the Project Management Institute's Project Management Body of Knowledge. Additionally, the paper analyzes the practical applications of project management principles related to DT-based HMC within enterprises. Through the application of these project management knowledge areas, the research assesses the likelihood of successful implementation of DT-based HMC in the PDP. The findings highlight that integrating DT technology with effective project management practices can lead to substantial enhancements in manufacturing processes, aligning them more closely with human-centric objectives. Ultimately, this study underscores the transformative potential of digital twins in fostering a collaborative environment that improves product development efficiency, quality, and overall competitiveness in the industry.
"
ACM,"Naik, Adwait et al.",Super-immersive Remote Working via Virtual Reality Controlled Robotics,2023,10.1145/3582700.3583700,"In this paper, we briefly describe a novel VR-robot interface developed (on top of the eNetReality [2] authoring platform by eCom Scotland) to provide users with an enhanced learning experience by enabling them to operate the robot remotely through the VR device. We implemented and tested this interface to control the Franka Emika Panda robotic arm. The main objective of this work is to provide an immersive experience to the user by enabling them to interact with the digital twin of the Franka robot and visualize its actions in the VR device. To achieve this objective, we integrated a haptic feedback device to enable the user to receive feedback while the robotic arm performs the pick and place task. We have extensively tested this interface with a cohort of Electronics and Electrical engineering graduates from Glasgow College, UESTC, China. Our ultimate goal is to extend our interface to support multiple robots.","digital twins, immersive visualization, positional tracking",Não,Sim,Diferente,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"Forte alinhamento. O estudo discute a implementação e teste (IC2) de uma HRI (interface VR/haptic, IC1/IC2) para um braço robótico (muitas vezes usado como um cobot, IC1) realizando tarefas de trabalho (pegar e largar, trabalho remoto, IC1). O ano de 2023 atende ao IC5.",,Sim,"Title: Super-immersive Remote Working via Virtual Reality Controlled Robotics
Abstract: In this paper, we briefly describe a novel VR-robot interface developed (on top of the eNetReality [2] authoring platform by eCom Scotland) to provide users with an enhanced learning experience by enabling them to operate the robot remotely through the VR device. We implemented and tested this interface to control the Franka Emika Panda robotic arm. The main objective of this work is to provide an immersive experience to the user by enabling them to interact with the digital twin of the Franka robot and visualize its actions in the VR device. To achieve this objective, we integrated a haptic feedback device to enable the user to receive feedback while the robotic arm performs the pick and place task. We have extensively tested this interface with a cohort of Electronics and Electrical engineering graduates from Glasgow College, UESTC, China. Our ultimate goal is to extend our interface to support multiple robots.
"
ACM,"Kosmidis, Leonidas",METASAT's Model Based Design Solutions,2024,10.1145/3706601.3706608,"METASAT is a recently started project (January 2023) in the Horizon Europe programme, in the SPACE call, coordinated by the Barcelona Supercomputing Center (BSC). METASAT will develop model-based design (MBD) solutions for high performance on-board processors such as multicores, Graphics Processing Units (GPUs) and Artificial Intelligence (AI) Accelerators. While the developed tools and methodologies are particularly focusing on the space domain, reusability to other safety critical domains is also a project goal. This talk will provide an overview of the solutions which will be developed during the project, which will be centered around the open source TASTE framework used at the European Space Agency (ESA), which leverages AADL.",Ausente,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 atendido. O contexto do estudo é explicitamente o ""domínio espacial"".",Ambas,Não,"Title: METASAT's Model Based Design Solutions
Abstract: METASAT is a recently started project (January 2023) in the Horizon Europe programme, in the SPACE call, coordinated by the Barcelona Supercomputing Center (BSC). METASAT will develop model-based design (MBD) solutions for high performance on-board processors such as multicores, Graphics Processing Units (GPUs) and Artificial Intelligence (AI) Accelerators. While the developed tools and methodologies are particularly focusing on the space domain, reusability to other safety critical domains is also a project goal. This talk will provide an overview of the solutions which will be developed during the project, which will be centered around the open source TASTE framework used at the European Space Agency (ESA), which leverages AADL.
"
ACM,"Autili, Marco et al.",Engineering Digital Systems for Humanity: A Research Roadmap,2025,10.1145/3712006,"As testified by new regulations like the European AI Act, worries about the human and societal impact of (autonomous) software technologies are becoming of public concern. Human, societal, and environmental values, alongside traditional software quality, are increasingly recognized as essential for sustainability and long-term well-being. Traditionally, systems are engineered taking into account business goals and technology drivers. Considering the growing awareness in the community, in this article, we argue that engineering of systems should also consider human, societal, and environmental drivers. Then, we identify the macro and technological challenges by focusing on humans and their role while co-existing with digital systems. The first challenge considers humans in a proactive role when interacting with digital systems, i.e., taking initiative in making things happen instead of reacting to events. The second concerns humans having a reactive role in interacting with digital systems, i.e., humans interacting with digital systems as a reaction to events. The third challenge focuses on humans with a passive role, i.e., they experience, enjoy or even suffer the decisions and/or actions of digital systems. The fourth challenge concerns the duality of trust and trustworthiness, with humans playing any role. Building on the new human, societal, and environmental drivers and the macro and technological challenges, we identify a research roadmap of digital systems for humanity. The research roadmap is concretized in a number of research directions organized into four groups: development process, requirements engineering, software architecture and design, and verification and validation.","Human values, Societal values, Environmental values, Research directions, Research roadmap, Software engineering",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"EC4 atendido. O resumo e o título identificam este artigo como um ""Roteiro de Pesquisa"", não um estudo de pesquisa primário.",Ambas,Não,"Title: Engineering Digital Systems for Humanity: A Research Roadmap
Abstract: As testified by new regulations like the European AI Act, worries about the human and societal impact of (autonomous) software technologies are becoming of public concern. Human, societal, and environmental values, alongside traditional software quality, are increasingly recognized as essential for sustainability and long-term well-being. Traditionally, systems are engineered taking into account business goals and technology drivers. Considering the growing awareness in the community, in this article, we argue that engineering of systems should also consider human, societal, and environmental drivers. Then, we identify the macro and technological challenges by focusing on humans and their role while co-existing with digital systems. The first challenge considers humans in a proactive role when interacting with digital systems, i.e., taking initiative in making things happen instead of reacting to events. The second concerns humans having a reactive role in interacting with digital systems, i.e., humans interacting with digital systems as a reaction to events. The third challenge focuses on humans with a passive role, i.e., they experience, enjoy or even suffer the decisions and/or actions of digital systems. The fourth challenge concerns the duality of trust and trustworthiness, with humans playing any role. Building on the new human, societal, and environmental drivers and the macro and technological challenges, we identify a research roadmap of digital systems for humanity. The research roadmap is concretized in a number of research directions organized into four groups: development process, requirements engineering, software architecture and design, and verification and validation.
"
ACM,"Krishna Sharma, Vinay et al.",Comparing Two Safe Distance Maintenance Algorithms for a Gaze-Controlled HRI Involving Users with SSMI,2022,10.1145/3530822,People with severe speech and motor impairment often find it difficult to manipulate physical objects due to spasticity and have familiarity with eye pointing based communication. This article presents a novel eye gaze controlled augmented reality human-robot interface that maintains a safe distance of the robot from the operator. We used a bespoke appearance-based eye gaze tracking algorithm and compared two different safe distance maintenance algorithms. We undertook simulation studies followed by a user trial involving end users. Users with severe speech and motor impairment could bring the robotic arm at any designated point within its working envelope in less than 3 minutes.,"Eye gaze tracking, robotics, assistive technology, Markov decision process, navigation path",Sim,Sim,Igual,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.","Forte alinhamento. O estudo discute e avalia (IC2) uma HRI (controle por olhar, IC1/IC2) para um robô assistivo (saúde) (IC1) e fornece dados de desempenho (""menos de 3 minutos"") de um teste com usuários (IC2). O ano de 2022 atende ao IC5.",Ambas,Sim,"Title: Comparing Two Safe Distance Maintenance Algorithms for a Gaze-Controlled HRI Involving Users with SSMI
Abstract: People with severe speech and motor impairment often find it difficult to manipulate physical objects due to spasticity and have familiarity with eye pointing based communication. This article presents a novel eye gaze controlled augmented reality human-robot interface that maintains a safe distance of the robot from the operator. We used a bespoke appearance-based eye gaze tracking algorithm and compared two different safe distance maintenance algorithms. We undertook simulation studies followed by a user trial involving end users. Users with severe speech and motor impairment could bring the robotic arm at any designated point within its working envelope in less than 3 minutes.
"
ACM,"Hatch, Paul et al.",PATHWiSE: An Authoring Tool to Support Teachers to Create Robot-Supported Social Learning Experiences During Homework,2023,10.1145/3579620,"Educational technologies can provide students with adaptive feedback and guidance, but these systems lack personal interactions that make social and cultural connections to the student's own classroom and prior experiences. Social or companion robots have a high capacity for these types of interactions, but typically require advanced levels of expertise to program. In this study, we examined teachers use of an authoring tool to enable them to leverage their classroom-based expertise to design robot-assisted homework assignments, and explore how seeing a robot enact their designs influences their work. We found that the tool enabled the teachers to create novel social interactions for homework activities that were similar to their classroom interaction patterns. These interaction designs evolved over time and were shaped by the teacher's emerging mental model of the social robot, their concept of the students' perspective of these interactions, and a shift towards informal classroom-like interaction paradigms, thus transforming their view of what they can achieve with homework. We discuss how these findings demonstrate how the context of the activity can influence initial mental models of social activities and suggest practical guidance on designing authoring tools to best facilitate the creation of computer or robot supported social activities, such as homework.","authoring tools, educational robots, mental models, social robots",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"EC2 atendido. O contexto do estudo é educação (""lição de casa"", ""professores""), que se enquadra nos setores excluídos (doméstico/entretenimento).",Ambas,Não,"Title: PATHWiSE: An Authoring Tool to Support Teachers to Create Robot-Supported Social Learning Experiences During Homework
Abstract: Educational technologies can provide students with adaptive feedback and guidance, but these systems lack personal interactions that make social and cultural connections to the student's own classroom and prior experiences. Social or companion robots have a high capacity for these types of interactions, but typically require advanced levels of expertise to program. In this study, we examined teachers use of an authoring tool to enable them to leverage their classroom-based expertise to design robot-assisted homework assignments, and explore how seeing a robot enact their designs influences their work. We found that the tool enabled the teachers to create novel social interactions for homework activities that were similar to their classroom interaction patterns. These interaction designs evolved over time and were shaped by the teacher's emerging mental model of the social robot, their concept of the students' perspective of these interactions, and a shift towards informal classroom-like interaction paradigms, thus transforming their view of what they can achieve with homework. We discuss how these findings demonstrate how the context of the activity can influence initial mental models of social activities and suggest practical guidance on designing authoring tools to best facilitate the creation of computer or robot supported social activities, such as homework.
"
ACM,"Cila, Nazli","Designing Human-Agent Collaborations: Commitment, responsiveness, and support",2022,10.1145/3491102.3517500,"With the advancements in AI, agents (i.e., smart products, robots, software agents) are increasingly capable of working closely together with humans in a variety of ways while benefiting from each other. These human-agent collaborations have gained growing attention in the HCI community; however, the field lacks clear guidelines on how to design the agents’ behaviors in collaborations. In this paper, the qualities that are relevant for designers to create robust and pleasant human-agent collaborations were investigated. Bratman's Shared Cooperative Activity framework was used to identify the core characteristics of collaborations and survey the most important issues in the design of human-agent collaborations, namely code-of-conduct, task delegation, autonomy and control, intelligibility, common ground, offering help and requesting help. The aim of this work is to add structure to this growing and important facet of HCI research and operationalize the concept of human-agent collaboration with concrete design considerations.","Shared Cooperative Activity, autonomous agent, design, human-agent collaboration",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC3 atendido. O estudo é um artigo teórico/conceitual que visa ""identificar as características centrais"" e ""pesquisar as questões mais importantes"" no design de HRI. Ele não apresenta uma aplicação prática, estudo de caso ou protótipo validado",Ambas,Não,"Title: Designing Human-Agent Collaborations: Commitment, responsiveness, and support
Abstract: With the advancements in AI, agents (i.e., smart products, robots, software agents) are increasingly capable of working closely together with humans in a variety of ways while benefiting from each other. These human-agent collaborations have gained growing attention in the HCI community; however, the field lacks clear guidelines on how to design the agents’ behaviors in collaborations. In this paper, the qualities that are relevant for designers to create robust and pleasant human-agent collaborations were investigated. Bratman's Shared Cooperative Activity framework was used to identify the core characteristics of collaborations and survey the most important issues in the design of human-agent collaborations, namely code-of-conduct, task delegation, autonomy and control, intelligibility, common ground, offering help and requesting help. The aim of this work is to add structure to this growing and important facet of HCI research and operationalize the concept of human-agent collaboration with concrete design considerations.
"
ACM,"Bakhshalipour, Mohammad e Gibbons, Phillip B.",Agents of Autonomy: A Systematic Study of Robotics on Modern Hardware,2023,10.1145/3626774,"As robots increasingly permeate modern society, it is crucial for the system and hardware research community to bridge its long-standing gap with robotics. This divide has persisted due to the lack of (i) a systematic performance evaluation of robotics on different computing platforms and (ii) a comprehensive, open-source, cross-platform benchmark suite.
To address these gaps, we present a systematic performance study of robotics on modern hardware and introduce RoWild, an open-source benchmark suite for robotics that is comprehensive and cross-platform. Our workloads encompass a broad range of robots, including driverless vehicles, pilotless drones, and stationary robotic arms, and we evaluate their performance on a spectrum of modern computing platforms, from low-end embedded CPUs to high-end server-grade GPUs.
Our findings reveal that current architectures experience significant inefficiencies when executing robotic workloads, highlighting the need for architectural advancements. We discuss approaches for meeting these requirements, offering insights for improving the performance of robotics.
The full version of the paper is available in [11], and the source code of the benchmark suite is available in [2].","benchmarking, computer architecture, robotics",Não,Sim,Diferente,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"Forte alinhamento. O estudo apresenta uma avaliação de desempenho sistemática (IC2) de robôs (veículos sem motorista, drones, braços robóticos) em contextos de trabalho (implícito, IC1) ao introduzir um conjunto de benchmarks (IC2). O ano de 2023 atende ao IC5.",,Sim,"Title: Agents of Autonomy: A Systematic Study of Robotics on Modern Hardware
Abstract: As robots increasingly permeate modern society, it is crucial for the system and hardware research community to bridge its long-standing gap with robotics. This divide has persisted due to the lack of (i) a systematic performance evaluation of robotics on different computing platforms and (ii) a comprehensive, open-source, cross-platform benchmark suite.
To address these gaps, we present a systematic performance study of robotics on modern hardware and introduce RoWild, an open-source benchmark suite for robotics that is comprehensive and cross-platform. Our workloads encompass a broad range of robots, including driverless vehicles, pilotless drones, and stationary robotic arms, and we evaluate their performance on a spectrum of modern computing platforms, from low-end embedded CPUs to high-end server-grade GPUs.
Our findings reveal that current architectures experience significant inefficiencies when executing robotic workloads, highlighting the need for architectural advancements. We discuss approaches for meeting these requirements, offering insights for improving the performance of robotics.
The full version of the paper is available in [11], and the source code of the benchmark suite is available in [2].
"
ACM,Ausente,AVI '24: Proceedings of the 2024 International Conference on Advanced Visual Interfaces,2024,10.1145/3656650,"

AVI 2024 is the 17th edition of the International Conference on Advanced Visual Interfaces, held in Arenzano, Genoa (IT), in cooperation with ACM, ACM SIGCHI, ACM SIGMM, and ACM SIGWEB.

Every two years since 1992, AVI has gathered a vast international community of experts with a wide range of backgrounds. Throughout three decades, AVI has gained and holds a prestigious position among International HCI conferences, boasting a dedicated nucleus of returning participants, but also providing a venue for young researchers to show their achievements and establish contacts with senior community members.

AVI 2024 presents a broad and sound scientific program covering traditional AVI topics on information and data visualization, interaction with multimodal user interfaces, augmented and virtual reality, while also addressing emerging topics including the application of generative artificial intelligence in HCI design and evaluation.

The program features the presentation of 21 long research papers and 28 short papers selected through a rigorous double-blind reviewing process and organized into sessions on 13 main topics. Furthermore, it includes the presentation of 48 poster papers, 9 demo papers, and 11 doctoral consortium papers, selected through a single-blind reviewing process. Finally, the rich and vibrant program includes 3 keynote talks, 3 tutorials, and 10 workshops addressing some of the most exciting issues in HCI.

Submissions to AVI 2024 came from 34 different countries distributed in descending order in Europe, Asia, North America, South America, and Africa.
",Ausente,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"EC4 atendido. O texto descreve os ""Anais da Conferência Internacional de 2024"", que é um editorial ou resumo, não um artigo de pesquisa completo revisado por pares.",Ambas,Não,"Title: AVI '24: Proceedings of the 2024 International Conference on Advanced Visual Interfaces
Abstract: 

AVI 2024 is the 17th edition of the International Conference on Advanced Visual Interfaces, held in Arenzano, Genoa (IT), in cooperation with ACM, ACM SIGCHI, ACM SIGMM, and ACM SIGWEB.

Every two years since 1992, AVI has gathered a vast international community of experts with a wide range of backgrounds. Throughout three decades, AVI has gained and holds a prestigious position among International HCI conferences, boasting a dedicated nucleus of returning participants, but also providing a venue for young researchers to show their achievements and establish contacts with senior community members.

AVI 2024 presents a broad and sound scientific program covering traditional AVI topics on information and data visualization, interaction with multimodal user interfaces, augmented and virtual reality, while also addressing emerging topics including the application of generative artificial intelligence in HCI design and evaluation.

The program features the presentation of 21 long research papers and 28 short papers selected through a rigorous double-blind reviewing process and organized into sessions on 13 main topics. Furthermore, it includes the presentation of 48 poster papers, 9 demo papers, and 11 doctoral consortium papers, selected through a single-blind reviewing process. Finally, the rich and vibrant program includes 3 keynote talks, 3 tutorials, and 10 workshops addressing some of the most exciting issues in HCI.

Submissions to AVI 2024 came from 34 different countries distributed in descending order in Europe, Asia, North America, South America, and Africa.

"
ACM,"Cameron, Harriet R et al.","Acceptability, Acceptance and Adoption of Telepresence Robots in Museums: The Museum Professionals' Perspectives",2025,10.1145/3706598.3713533,"Telepresence robots have the potential to change our experiences in galleries and museums, allowing for a range of hybrid interactions for visitors and museum professionals, improving accessibility, offering activities or information, and providing a range of practical use cases (e.g. the robots augmenting museum exhibits). We present the results of 3 qualitative studies conducted in the UK exploring the acceptability (1 - interviews with museum professionals with no previous exposure to telepresence), acceptance (2 – focus groups for initial exposure to telepresence robots), and adoption (3 – interviews with museum professionals with long-term exposure to robots) of telepresence robots in museums. Our results identified opportunities and barriers focusing on the unique perspective of museum professionals and showed how priorities of museums shift and change according to their exposure to different technologies. We proposed a set of practical guidelines for future telepresence robots in museums, including design implications, potential applications, and integration strategies.","telepresence robotics, museums and galleries, technology acceptance lifecycle",Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"EC2 atendido. O contexto do estudo é um ""museu"", que se enquadra nos setores excluídos (entretenimento/espaço público) e não é um dos setores-alvo (logística, saúde ou serviços de campo).",Ambas,Não,"Title: Acceptability, Acceptance and Adoption of Telepresence Robots in Museums: The Museum Professionals' Perspectives
Abstract: Telepresence robots have the potential to change our experiences in galleries and museums, allowing for a range of hybrid interactions for visitors and museum professionals, improving accessibility, offering activities or information, and providing a range of practical use cases (e.g. the robots augmenting museum exhibits). We present the results of 3 qualitative studies conducted in the UK exploring the acceptability (1 - interviews with museum professionals with no previous exposure to telepresence), acceptance (2 – focus groups for initial exposure to telepresence robots), and adoption (3 – interviews with museum professionals with long-term exposure to robots) of telepresence robots in museums. Our results identified opportunities and barriers focusing on the unique perspective of museum professionals and showed how priorities of museums shift and change according to their exposure to different technologies. We proposed a set of practical guidelines for future telepresence robots in museums, including design implications, potential applications, and integration strategies.
"
ACM,Ausente,IVA '23: Proceedings of the 23rd ACM International Conference on Intelligent Virtual Agents,2023,10.1145/3570945,"

This volume contains the papers presented at the 23nd International Conference on Intelligent Virtual Agents (IVA 2023) located in Würzburg, Germany, from 19. to 22.09.2023.
",Ausente,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"EC4 atendido. O texto identifica isso como os ""Anais da 23ª Conferência Internacional da ACM"", que é uma coleção ou resumo, não um artigo de pesquisa individual.",Ambas,Não,"Title: IVA '23: Proceedings of the 23rd ACM International Conference on Intelligent Virtual Agents
Abstract: 

This volume contains the papers presented at the 23nd International Conference on Intelligent Virtual Agents (IVA 2023) located in Würzburg, Germany, from 19. to 22.09.2023.

"
ACM,"Talia, Domenico",From Algorithms to Thinking Machines: The New Digital Power,2023,10.1145/3603178,"

This book introduces and provides an analysis of the basic concepts of algorithms, data, and computation and discusses the role of algorithms in ruling and shaping our world. It provides a clear understanding of the power and impact on humanity of the pervasive use of algorithms.

From Algorithms to Thinking Machines combines a layman’s approach with a well-founded scientific description to discuss both principles and applications of algorithms, Big Data, and machine intelligence. The book provides a clear and deep description of algorithms, software systems, data-driven applications, machine learning, and data science concepts, as well as the evolution and impact of artificial intelligence.

After introducing computing concepts, the book examines the relationships between algorithms and human work, discussing how jobs are being affected and how computers and software programs are influencing human life and the labor sphere. Topics such as value alignment, collective intelligence, Big Data impact, automatic decision methods, social control, and political uses of algorithms are illustrated and discussed at length without excessive technical detail. Issues related to how corporations, governments, and autocratic regimes are exploiting algorithms and machine intelligence methods to influence people, laws, and markets are extensively addressed. Ethics principles in software programming and human value insertion into artificial intelligence algorithms are also discussed.
",Ausente,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"EC4 atendido. O resumo identifica repetidamente a publicação como um ""livro"".",Ambas,Não,"Title: From Algorithms to Thinking Machines: The New Digital Power
Abstract: 

This book introduces and provides an analysis of the basic concepts of algorithms, data, and computation and discusses the role of algorithms in ruling and shaping our world. It provides a clear understanding of the power and impact on humanity of the pervasive use of algorithms.

From Algorithms to Thinking Machines combines a layman’s approach with a well-founded scientific description to discuss both principles and applications of algorithms, Big Data, and machine intelligence. The book provides a clear and deep description of algorithms, software systems, data-driven applications, machine learning, and data science concepts, as well as the evolution and impact of artificial intelligence.

After introducing computing concepts, the book examines the relationships between algorithms and human work, discussing how jobs are being affected and how computers and software programs are influencing human life and the labor sphere. Topics such as value alignment, collective intelligence, Big Data impact, automatic decision methods, social control, and political uses of algorithms are illustrated and discussed at length without excessive technical detail. Issues related to how corporations, governments, and autocratic regimes are exploiting algorithms and machine intelligence methods to influence people, laws, and markets are extensively addressed. Ethics principles in software programming and human value insertion into artificial intelligence algorithms are also discussed.

"
IEE,"
Yang Li",Trust-Aware Human–Robot Fusion Decision-Making for Emergency Indoor Patrolling,2024,10.1109/TASE.2024.3350639,"Trust plays a crucial role in decision-making during human-robot collaboration, particularly in emergency scenarios where it becomes more susceptible due to dynamic factors. Misalignment of human-robot trust significantly hampers the efficiency of the collaboration. Therefore, it is imperative to establish effective human-robot interaction and decision support mechanisms that mitigate biases in human confidence levels regarding the robot’s capabilities in dynamic environments. Additionally, online correction of human-robot trust based on human behavioral feedback is vital. This paper focuses on a specific type of emergency task scenario, specifically, indoor human-robot collaborative patrolling in the event of sudden power outages. We propose a trust model based on linear Gaussian and sparse Gaussian processes (sparse GP). We also employ Monte Carlo Tree Search (MCTS) method to determine the robot’s optimal fusion decision-making. Through VR-based human-robot collaborative experiments, we ascertain that the robot prioritizes enhancing human-robot trust in emergency scenarios to mitigate the long-term costs of human-robot collaboration. Note to Practitioners—The primary motivation of this paper lies in tackling the issue of decreased collaboration efficiency in human-robot cooperation, stemming from irrational human decision-making, a problem exacerbated in emergency scenarios where comprehending all available information proves challenging. Grounded in the realm of human-robot trust, this study evaluates the temporal and substantive aspects of human-robot interactions contingent upon the degree of trust. Moreover, it adapts the fusion decision-making process within the human-robot team in accordance with the decision-making strategies adopted by humans at varying trust levels. The optimized decisions of the human-robot ensemble are conveyed to the human participant via decision support. This approach ensures the maintenance of trust levels, facilitating the acceptance of decision support that may seem intuitively irrational but holds objective superiority. Furthermore, it mitigates redundant human-robot interactions once a sufficient level of trust is established.","Robots
,
Collaboration
,
Decision making
,
Task analysis
,
Power system reliability
,
Human-robot interaction
,
Uncertainty",Não,Sim,Diferente,"Despite being peer-reviewed, English, and within the 2020–2025 range, this study does not satisfy IC1.

The context described is emergency indoor patrolling during power outage — this is not logistics, not healthcare, and not field service industrial sectors such as inspection/maintenance tied to business operations. It is closer to public safety / emergency response domain, which is outside the target application sectors.

Also, although it is focused on human-robot trust and collaboration, the scenario is VR-based experimentation and not tied to real applied deployment within the required industrial/logistics/healthcare contexts.

Therefore it fails the primary domain constraint (IC1), so it must be excluded.","Score: 1 Justification: The study is included. It strongly aligns with the inclusion criteria and does not meet the exclusion criteria assessable from the abstract.

IC1 (Theme): Met. The study focuses on a collaborative robot (""human-robot collaboration,"" ""human-robot trust"") in a field service context (""indoor patrolling"" for emergencies, which maps to inspection/maintenance).

IC2 (Research Questions): Met. It provides a clear analysis of HRI (specifically trust) and proposes enabling technologies (a trust model and MCTS for decision-making) to improve collaborative efficiency.

EC1 (Single-Task Robots): Not Met. The article is explicitly about human-robot collaboration and interaction, the opposite of a fixed, non-interactive robot.

EC3 (Theoretical Focus): Not Met. The study is not purely theoretical; it validates its proposals using ""VR-based human-robot collaborative experiments.""

EC4 (Publication Type): Not Met. The abstract describes novel, original research (""We propose...""), not a review, survey, or thesis.",Ambas,Sim,
IEE,I. Nourbakhsh,On the study of human-robot collaboration,2006,10.1109/AMC.2006.1631623,"Human-robot interaction (HRI) is being explored with the aim of creating rich, effective and satisfying interactions between humans and robots. Human-robot collaboration for learning, in which the measurable outcomes are information gain on the part of the humans in the system, is specifically focused upon. In the context of this focus on collaboration for learning, rich means a cognitively sophisticated interaction in which humans and robots communicate as peers; effective means that formal measures of human learning should yield significant outcomes; satisfying means that humans should find the interaction both useful and pleasurable. Two themes have dominated HRI research projects: how to field interactive robot systems to evaluate human-robot collaboration, and how to explicitly model human cognition and learning resulting from robot interaction. Models of interaction and evaluation methodology from human factors, HCI and cognitive psychology, have been joined and extended. Research in reasoning and social policy addresses the issue of decision-making and execution in the context of rich interaction and partial information. Research results and the evaluation methodology are validated, demonstrating significant improvement in interaction effectiveness from contributions as diverse as robot morphology design, diagnostic transparency, and affective behavior modeling. The current research thrust is a special case of collaboration: educational robotics, where robots collaborate with humans to promote learning. Statistical significance across learning themes is demonstrated using formal coding analyses. The present ambition in educational robotics is the principled design of a robotic platform and curriculum, based on an extension of coded learning themes, that can have significant impact on technology literacy and interest in science and engineering education at the middle school and high school levels","Collaboration
,
Cognitive robotics
,
Human robot interaction
,
Educational robots
,
Educational institutions
,
Gain measurement
,
Context
,
Anthropometry
,
Cognition
,
Human factors",Não,Não,Igual,"Score: 0

Justification:

Although the paper is in English and appears to be peer-reviewed, it does **not satisfy IC1 and IC2**.

The abstract clearly focuses on **educational robotics** — robots collaborating with humans for learning outcomes and technology literacy for middle/high school contexts. This domain is **not** logistics, healthcare, or field service (maintenance/inspection). Therefore, it falls into excluded sector relevance for this SLR scope.

Also, the measurable results discussed are related to learning impact, cognitive interaction, affective modeling and educational impact — not operational efficiency, ROI, or practical deployment impact in workplace environments.

Therefore, even though it is a valid HRI/robotics work, it does not match the required application domain and practical industrial relevance required by the inclusion criteria.
","Score: 0 Justification: The study is excluded as it fails to meet the required context criteria for IC1 (Theme).

IC1 (Theme): Not Met. While the study focuses on collaborative robots (""human-robot collaboration""), its application context is explicitly ""educational robotics"" aimed at ""middle school and high school levels."" This sector is not one of the required target domains (logistics, healthcare, or field services).

EC4 (Type of Publication): Likely Met (Excluded). The title ""On the study of..."" and the abstract's high-level summary of research themes (""Two themes have dominated HRI research..."") strongly suggest this is a review, survey, or position paper rather than a primary research article, which are excluded by EC4.",Ambas,Não,
IEE,"
Yang Ye",Improved Trust in Human-Robot Collaboration With ChatGPT,2023,10.1109/ACCESS.2023.3282111,"Human-robot collaboration is becoming increasingly important as robots become more involved in various aspects of human life in the era of Artificial Intelligence. However, the issue of human operators’ trust in robots remains a significant concern, primarily due to the lack of adequate semantic understanding and communication between humans and robots. The emergence of Large Language Models (LLMs), such as ChatGPT, provides an opportunity to develop an interactive, communicative, and robust human-robot collaboration approach. This paper explores the impact of ChatGPT on trust in a human-robot collaboration assembly task. This study designs a robot control system called RoboGPT using ChatGPT to control a 7-degree-of-freedom robot arm to help human operators fetch, and place tools, while human operators can communicate with and control the robot arm using natural language. A human-subject experiment showed that incorporating ChatGPT in robots significantly increased trust in human-robot collaboration, which can be attributed to the robot’s ability to communicate more effectively with humans. Furthermore, ChatGPT’s ability to understand the nuances of human language and respond appropriately helps to build a more natural and intuitive human-robot interaction. The findings of this study have significant implications for the development of trustworthy human-robot collaboration systems.
","Robots
,
Collaboration
,
Artificial intelligence
,
Manipulators
,
Chatbots
,
Human-robot interaction
,
Robot sensing systems",Não,Não,Igual,"Score: 0

Justification:
Even though the article is clearly HRI focused, uses collaborative interaction, natural language control, and measures trust impact (which aligns well with IC2), it fails IC1 due to the application context.

The study is based on robot arm assembly task, but the abstract does not specify that this occurs in logistics / warehouse environments, healthcare, or field service maintenance/inspection scenarios. Assembly tasks without sector specification typically fall under industrial manufacturing context, which in this SLR is not an accepted target domain unless explicitly framed inside the allowed sectors.

Therefore — despite being collaborative, applied, English, and likely within 2020-2025 — the absence of one of the required application domains automatically disqualifies it.","Score: 0
Justification: The study is excluded because it fails to meet **IC1 (Theme)** and appears to meet **EC4 (Type of Publication)**.

* **IC1 (Theme):** **Not Met.** While the study does focus on collaborative robots (""human-robot collaboration""), the application context is explicitly ""educational robotics"" aimed at ""middle school and high school levels."" This context is not among the required domains (logistics, healthcare, or field services).
* **EC4 (Type of Publication):** **Likely Met (Excluded).** The title ""On the study of..."" and the abstract's high-level summary of the field (""Two themes have dominated HRI research projects..."") strongly suggest this is a review, survey, or position paper, which are explicitly excluded. It describes broad themes rather than presenting a specific, novel experiment or application.",Ambas,Não,
IEEE,A. Dobrokvashina; S. Sulaiman; A. Zagirov; E. Chebotareva; H. Kuo-Hsien; E. Magid,Human Robot Interaction in Collaborative Manufacturing Scenarios: Prospective Cases,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10002876,"Nowadays, robots are used extensively in manufacturing sectors because they improve quality and efficiency of production processes. Robots can perform various tasks autonomously with optimal working speed and accuracy. Even in a fully autonomous mode, a human operator is still needed to supervise operations and resolve issues, which led to an emergence of the collaborative robotics field. This paper reviews various potential industrial robots employed for human-robot collaboration and explores solution strategies related to safety during collaborative tasks.",Human-robot interaction;Industrial robot;Collaborative robot;review,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 not fully satisfied: Robot type seems relevant (collaborative/multifunctional), but the context is not clearly one of the target sectors (logistics/healthcare/field).",Ambas,Não,
IEEE,O. Ochoa; E. Mendez; C. Lucas-Dophe; J. A. Luna-Sánchez; V. H. Soto-Herrera; D. Olivera-Guzman; M. A. Perez; E. del-Real; I. N. Ayala-García; A. González,Flexible Human-Robot Interaction: Collaborative Robot Integrated with Hand Tracking,2023,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10349712,"The rising demand for adaptable and user-friendly forms of interaction in the field of manufacturing and assembly tasks has led to increased attention on human-robot collaboration. Collaborative robots (cobots) have emerged as a promising solution to address this demand. In this study, we propose the integration and application of cobots along with a pre-trained deep learning model to assist users in assembly activities, specifically part handover and storage. The human-robot interaction is facilitated through a hand tracking system that enables a close approach to the user's hand. Testing on the system yielded 99% accuracy. The incorporation of deep learning models in cobot applications holds substantial potential for industry transformation, with implications spanning manufacturing, healthcare, and assistive technologies. This research serves as a compelling proof of concept, showcasing the effective implementation of deep learning models to facilitate close human-robot interactions.",Collaborative robot;Deep learning;Human-robot collaboration,Não,Sim,Diferente,EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC met: The study focuses on collaborative/multifunctional robots (IC1) in a target sector (IC1) and discusses practical applications, design, or evaluation (IC2). It is within the time frame (IC5) and not an excluded type (EC4).",,Sim,
IEEE,Y. Shi; T. Wang; J. Yu; S. Xiao; L. Xiong; L. Yang,Virtual Potential Field-Based Motion Planning for Human-Robot Collaboration via Kinesthetically Guided Teleoperation,2023,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10087678,"Driven by the evolving role of modern robots in collaboration with human operators, this paper proposes a virtual potential field-based motion planning and control strategy to realize effective human-robot collaboration through kinesthetic guidance via robot teleoperation. The motion of the teleoperated robot is determined by the human operator using a haptic device programmed to replicate movement under the influence of the virtual potential field constructed based on the obstacles and objectives in the environment. This approach facilitates seamless cooperation between the human and collaborative robot. It can also be readily generalized to include moving obstacles and goals in a dynamic environment. The results suggest that the virtual potential field can effectively enhance the safety and accuracy of human-robot cooperation. The developed method has promising applications in human-centric robotics fields such as medical robotics and robot-assisted surgeries.",human-robot collaboration;virtual potential field;force feedback;teleoperation,Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.","IC met: The study focuses on collaborative/multifunctional robots (IC1) in a target sector (IC1) and discusses practical applications, design, or evaluation (IC2). It is within the time frame (IC5) and not an excluded type (EC4).",Ambas,Não,
IEEE,S. Hoose; F. Würtz; T. Kirks; J. Jost,An Evaluation of Open Source Trajectory Planners for Robotic Manipulators with Focus on Human-Robot Collaboration,2023,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10260597,"The planning of trajectories for the movement of robotic manipulators improved in recent years. Since many trajectory planners are available to the public as open source software, it is common that these are used in various human-robot interaction scenarios, which again have varying requirements to trajectory planners. This paper spotlights the possible application of available open source trajectory planners in the field of human-robot collaboration. In detail, an evaluation of the applicability of open source trajectory planners in various human-robot collaboration scenarios is described in this paper. Hence, we aim to give recommendations on the usage of available trajectory planners in human-robot collaboration scenarios based on multiple metrics, derived from knowledge on preferences of humans regarding their interaction with cobots.",Robotic Manipulators;Human-Robot Collaboration;Trajectory Planning;Cobotics,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 not fully satisfied: Robot type seems relevant (collaborative/multifunctional), but the context is not clearly one of the target sectors (logistics/healthcare/field).",Ambas,Não,
IEEE,H. Gao; C. Chevallereau; S. Caro,Enhancing Safety in Collaborative Cable-Driven Parallel Robots: Contact Distinction and Management for Carrying Tasks,2025,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11095798,"Cable-Driven Parallel Robots (CDPRs) have shown significant potential in industrial applications due to their large workspace, high payload capacity, and flexibility. Nonetheless, ensuring safe and efficient human-robot collaboration, particularly during carrying tasks, remains an open problem. This paper primarily contributes a cable tension-based metric for detecting contact events, combined with a frequency-domain analysis of estimated external wrenches to distinguish different contact scenarios. Building upon this framework, three common contact scenarios are then addressed: (i) payload placement and removal without rigid attachment to the moving-platform (SC1), (ii) unintentional human-cable collisions (SC2), and (iii) human-platform collisions (SC3). Specific management strategies are then proposed, including real-time mass estimation for payload handling, cable tension release for human-cable collisions, and a compliant trajectory controller for human-platform collisions. Experimental validations on a CDPR prototype demonstrate accurate scenario classification and safe contact handling without compromising overall productivity. By facilitating safer interactions, improved adaptability, and reliable handling of diverse contact events, this work expands the applicability of collaborative CDPRs in real-world industrial and logistic settings. Note to Practitioners—In many industrial applications, robots operating alongside human workers must quickly detect and respond to contact events to maintain safety and efficiency. Traditional methods often rely on force thresholds, which can introduce delays or false alarms, especially in dynamic tasks where rapid collisions must be addressed. Our work proposes an alternative approach that utilizes a frequency-domain analysis of sensed cable tensions and a weight-score system to robustly distinguish among various contact scenarios. By examining tension signals in the frequency domain, more nuanced information can be extracted, enabling faster and more accurate responses than threshold-based methods. From a practical standpoint, this technique is relatively straightforward to implement with various sensors, and it can be adapted to robots composed of different materials and link configurations by tuning the weight-score system for each new setup. Its primary benefit is improved contact distinction with high precision, which can enhance operator safety and reduce downtime without requiring extensive hardware modifications. However, like any sensor-driven control method, performance depends on adequate calibration and consistent signal quality. Future research might focus on integrating additional sensing modalities (e.g., vision or proximity sensors) and exploring broader deployment in diverse collaborative robot systems.",Tendon/wire mechanism;parallel robots;human-robot collaboration;physical human-robot interaction;safety in HRI,Não,Não,Igual,EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 not fully satisfied: Robot type seems relevant (collaborative/multifunctional), but the context is not clearly one of the target sectors (logistics/healthcare/field).",Ambas,Não,
IEEE,T. Chowdhury; K. Bhowmik; A. S. Naidu; S. A. Khan,Challenges in the Transition from Supply Chain 4.0 to Supply Chain 5.0,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9989591,"This paper mainly intends to discuss the significant barriers faced by current industrial systems in transitional to Supply Chain 5.0 from Supply Chain 4.0. A systemic literature review methodology was conducted for highlighting top ten barriers which would be the most significantly challenging for an existing Supply Chain 4.0 industry to embrace but are also critical to transition to a Supply Chain 5.0. Barriers to Supply Chain 5.0 transition are only paradigms of the Industry 5.0. The concept of a Supply Chain 5.0 is still in the budding stages of an idea and requires monumental amount of research, innovation, technology and industrial strategy along with improvements in terms of socio-economic and sustainable impacts. Nevertheless, this paper gives valuable insights to researchers and industrialists alike by exploring ideas of Industry 5.0 focusing on supply chain perspectives required to support it to develop into the implementation phase from its preceding version.",Fifth supply chain revolution;Supply Chain 5.0;Cobots;Industry 5.0;Sustainable growth;and Transition barriers,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 met: The publication is a review, survey, or other excluded type.",Ambas,Não,
IEEE,R. R; R. R. Sathya; S. V; J. L. N; G. S,Enhancing Human Cobot Interaction with Mixed Reality: A Futuristic Review,2023,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10199911,"A literature review on the topic of cobots with MR technology would provide a comprehensive overview of existing research, studies, and scholarly articles related to the combination of cobots and MR in various fields. It would involve reviewing published works that investigate the application, benefits, challenges, and outcomes of integrating cobots with MR technology in manufacturing, healthcare, and other industries. Collaborative robots (cobots) have revolutionized manufacturing and other industries by working alongside humans to enhance productivity and efficiency. By conducting a literature review, researchers can identify gaps in current knowledge, understand the methodologies used in previous studies, and gain insights into the potential applications and limitations of cobots with MR technology. This review would serve as a foundation for further research and development in this field, helping researchers and practitioners make informed decisions and contribute to advancements in the use of cobots and MR. However, traditional programming and control interfaces for cobots have limitations that prevent their full potential from being realized. It is conceivable that cobots will develop into ever more useful and valuable resources across a range of industries, including Industry 5.0, as MR continues to advance. The user experience could be improved via cobot integration with MR.",cobots;Industry 5.0;mixed reality;human-cobot interaction;industrial automation,Não,Não,Igual,EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 met: The publication is a review, survey, or other excluded type.",Ambas,Não,
IEEE,R. R; R. R. Sathya; V. V; B. S; J. L. N,Industry 5.0: Enhancing Human-Robot Collaboration through Collaborative Robots – A Review,2023,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10201120,"Modern production systems are currently changing, moving from mass production to mass customization logic, as described in Industry 5.0. The aim of Industry 5.0 is to outperform conventional manufacturing techniques by creating interconnected systems that include everything from machinery, robots, and workers to goods and consumers. This is accomplished by fully integrating the physical and virtual worlds. It focuses on building intelligent hybrid workspaces where robots share labour-intensive duties to increase productivity and safety in a range of industrial sectors. Cobots, or collaborative robots, are introduced in this. Cobots are becoming more prevalent in modern industrial systems because they combine the adaptability and competence of manual labour with the efficiency of automated systems. To maintain consistent human safety and effective collaborative productivity, communication between a human operator and the robot in these collaborative contexts must be precise and seamless. In more specific words, the framework can be used to operate an industrial robot securely and remotely in real-time while still protecting the safety of the technician. The objective of this article is to offer a clear overview of Industry 5.0's major ideas and prospective applications. It focuses on the supporting technologies of Industry 5.0 such as the Internet of Things (IoT), 6G systems, Blockchain Technology (BT), Digital Twin (DT), Artificial Intelligence (AI), Cyber-physical systems, and Extended Reality (XR) technologies, for seamless connectivity and data exchange. Furthermore, it also elaborates on the application of Cobots in various industrial fields.",Industry 5.0;Cobots;Internet of Things;Digital Twin;Cyber-Physical Systems;Artificial Intelligence,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 not fully satisfied: Robot type seems relevant (collaborative/multifunctional), but the context is not clearly one of the target sectors (logistics/healthcare/field).",Ambas,Não,
CCBYNCND,N. Alherimi; A. Saihi; M. Ben-Daya,A Systematic Review of Optimization Approaches Employed in Digital Warehousing Transformation,2024,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10683736,"Digital transformation of warehousing is revolutionizing operations by integrating advanced technologies. Automated Guided Vehicles (AGVs) optimize the movement of goods, while Internet of Things (IoT) enhances connectivity and data collection for improved decision-making. Robots automate tasks like picking and packing, increasing efficiency and reducing errors. Blockchain technology enhances transparency and traceability in the supply chain, building trust and reducing fraud. Digital twins create virtual replicas of warehouses for simulation and optimization, enabling proactive problem-solving and improved resource allocation. Such transformation addresses the increasing complexity and dynamic nature of warehousing in the modern marketplace. This systematic literature review, following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework, investigates the role of optimization models in this digital shift from 2010 to 2023. The findings highlight the crucial enhancements and practical implications brought about by these technologies, showcasing their impact on streamlining operations. These improvements include advancements in path planning, task allocation, inventory management and storage assignment which significantly enhance operational effectiveness within warehousing. The results demonstrate a 25-30% increase in perishable food freshness, a 10% reduction in picking time, a 14.8% increase in space utilization, and a 9.95% decrease in total costs. Moreover, the findings call attention to the insufficient analysis on the economic implications of digital transformations in warehousing, notably in cost reductions and Return on Investment (ROI) evaluations which are crucial metrics for evaluating the financial success and wider benefits of digital transformation initiatives, such as customer satisfaction and revenue growth. The review also identifies critical research gaps, including the need to incorporate sustainability into optimization models, strategies for adapting to dynamic environments, the exploration of collaborative robots (cobots), and the optimization of reverse logistics and returns. This review provides a comprehensive foundation for future research and emphasizes the potential of digitalization to revolutionize warehousing practices through innovative optimization strategies and real-world applications.",Digital transformation;warehousing operation;optimization models;systematic review;path planning;task allocation,Não,Não,Igual,EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 met: Publication appears to be a review, book, thesis, or other excluded type.",Ambas,Não,
IEEE,E. Concha-Pérez; C. Valle-Gutierrez; R. Leal-Rojas; H. G. Gonzalez-Hernandez; J. A. Reyes-Avendaño,Towards Intuitive Human-Robot Interaction: A Machine Learning Approach to Gesture Recognition,2025,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11086443,"This work presents a human gesture recognition system using surface electromyography signals (sEMG) in order to improve human-robot interaction (HRI). A cobot implementation via simulation in RoboDK is also proposed. A structured experimental protocol is proposed that optimizes the acquisition of sEMG and EEG signals and minimizes noise to obtain high-fidelity data before preprocessing. Three hand and arm gestures were defined to establish interaction with the robot, such as Ask, Take, and Neutral. Three machine learning models were trained and tested with raw sEMG data and preprocessed sEMG data, surpassing 96% recognition accuracy using the Bagged Trees model with preprocessed sEMG data. This approach offers promising applications in assistive robotics, rehabilitation, and occupational ergonomics. In addition, the study lays the foundation for future developments that integrate EEG signals, with the aim of improving the accuracy of the system and allowing recognition of movement intentions.",Gesture recognition;Bagged trees;EMG;Ro-boDK;Experimental protocol;EEG,Sim,Não,Diferente,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.","IC2 not satisfied: Study does not appear to provide data on applications, impacts, HRI, technologies, or challenges.",,Sim,
IEEE,O. Chojnowski; A. Eberhard; M. Schiffmann; A. Müller; A. Richert,Human-like Nonverbal Behavior with MetaHumans in Real-World Interaction Studies: An Architecture Using Generative Methods and Motion Capture,2025,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10973925,"Socially interactive agents are gaining prominence in domains like healthcare, education, and service contexts, particularly virtual agents due to their inherent scalability. To facilitate authentic interactions, these systems require verbal and nonverbal communication through e.g., facial expressions and gestures. While natural language processing technologies have rapidly advanced, incorporating human-like nonverbal behavior into real-world interaction contexts is crucial for enhancing the success of communication, yet this area remains underexplored. One barrier is creating autonomous systems with sophisticated conversational abilities that integrate human-like nonverbal behavior. This paper presents a distributed architecture using Epic Games' MetaHuman, combined with advanced conversational AI and camera-based user management, that supports methods like motion capture, handcrafted animation, and generative approaches for nonverbal behavior. We share insights into a system architecture designed to investigate nonverbal behavior in socially interactive agents, deployed in a three-week field study in the Deutsches Museum Bonn, showcasing its potential in realistic nonverbal behavior research.",Socially Interactive Agents;Nonverbal Behavior MetaHuman;Generative AI;Motion Capture,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,IC1 not satisfied: Does not clearly focus on multifunctional or collaborative robots (cobots).,Ambas,Não,
IEEE,S. el Zaatari; Y. Wang; W. Li,Reinforcement Learning based Optimization for Cobot's Path Generation in Collaborative Tasks,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9437874,"Task-Parameterized Learning from Demonstrations (TP-LfD) is an effective approach for collaborative robot (cobot). It aims at generating a path of a cobot moving in a dynamic collaborative task (e.g., a pick-and-place task) adaptively with respect to knowledge learnt from demonstrated tasks. That is, the learnt knowledge from demonstrated tasks are considered task parameters, which are critical input for TP-LfD to generate a movement path of a cobot for a new dynamic task. To further enhance the adaptability of TP-LfD, in this paper, an improved TP-LfD ( i TP-LfD) approach over other developed TP-LfD approaches is presented. One of the major contributions in i TP-LfD is that a reinforcement learning based optimization algorithm is designed to eliminate irrelevant task parameters identified in demonstrations, which boosts the overall computational performance of cobot's path generation. In the end, case studies were used to validate and highlight the adaptability and robustness of the approach.",Learning from demonstrations;reinforcement learning;collaborative robots (Cobots),Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 not satisfied: Does not clearly focus on target sectors (logistics, healthcare, field services).",Ambas,Não,
IEEE,V. S. Musam; A. Jagathpally; N. K. Musham; T. Shahwar; R. Mekala,"Human-Machine Collaboration with AI: Cobots, BLE Integration, and Time-Series Forecasting for Optimized Decision-Making",2025,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11188376,"Modern industries face dynamic challenges that hinder their ability to be maintain optimal efficiency and scalable. Collaborative Robots (Cobots), Bluetooth Low Energy (BLE), and Time-Series Forecasting together improve real-time communication, adaptive decision-making, and workflow efficiency for innovative and sustainable industrial solutions. The integration of cobots with automation and safety, BLE for seamless device communications, and time-series forecasting into a framework enables real-time adaptability with efficient utilization of resources, and optimization productivity during high industrial dynamism. Optimize operational workflows using Cobots, BLE, and Time-Series Forecasting to enable efficiency improvement through scalability and anomaly detection toward making real-time decisions within efficient warehouse and industrial management towards rectification of the inefficiency existing within the systems. It reaches 94 % accuracy, $95 \% ~\mathrm{F} 1$ score, and 92 % scalability, which is far more efficient than traditional methods. This also allows for effective communication, predictive decision-making, and anomaly detection at 91 % for adaptive and sustainable industrial operations. The framework combines Cobots, BLE, and TimeSeries Forecasting to provide unique, scalable, and effective solutions. It revolutionizes industrial processes by enhancing decision-making at a real-time level adaptable to the demands of new, dynamic operational environments.",Cobots;BLE;Time-Series Forecasting;AI Framework;Scalability;Efficiency;Anomaly Detection,Sim,Sim,Igual,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.","Strong alignment with all inclusion criteria: Discusses multifunctional/collaborative robots in a target sector (IC1), focuses on practical aspects (IC2), is a 2020-2025 publication (IC5), and is not an excluded type (EC4).",Ambas,Sim,
IEEE,C. Neef; A. Richert,Likable or Intelligent? Comparing Social Robots and Virtual Agents for Long-Term Health Monitoring,2025,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10973972,"Using social robots and virtual agents (VAs) as interfaces for health monitoring systems for older adults offers the possibility of more engaging interactions that can support long-term health and well-being. While robots are characterized by their physical presence, software-based VAs are more scalable and flexible. Few comparisons of these interfaces exist in the human-robot and humanagent interaction domains, especially in long-term and real-world studies. In this work, we examined impressions of social robots and VAs at the beginning and end of an eight-week study in which older adults interacted with these systems independently in their homes. Using a between-subjects design, participants could choose which interface to evaluate during the study. While participants perceived the social robot as somewhat more likable, the VA was perceived as more intelligent. Our work provides a basis for further studies investigating factors most relevant for engaging interactions with social interfaces for long-term health monitoring.",Health management;older adults;socially interactive agents;assistive technologies,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 not satisfied: Does not clearly focus on target sectors (logistics, healthcare, field services).",Ambas,Não,
IEEE,B. Hu; Y. Luo; Y. Chen,Evaluating Human Locomotion Safety in Mobile Robots Populated Environments,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9985068,"The overarching goal of this work is to understand how human locomotion adapts to mobile collaborative robots (cobots) that are designed to complement human well-being. This understanding will provide relevant inherent safe and human-centered design guidance for future mobile cobot systems. In this study, we will focus on the warehousing, wholesale, and retail trade (WRT) industry, where in general human workers are exposed to extensive experience working with mobile cobots, investigating the human locomotion safety in this environment. Eight participants were recruited to simulate a grocery shopping task with and without the mobile robot nearby. The walking trajectory of all participants revealed that the mobile robot complicated participants walking path selection, compared to the baseline “No Robot” condition. Meanwhile, participants lowered their walking speed and showed a proactive reaction to the approaching robot by initiating and ceasing the walking actions more smoothly. In conclusion, findings confirmed the values of mobile cobots in complex occupational settings and suggested more a systematic approach to ensure these intelligent systems' inherent safety.",Mobile Robots;Human-Robot Interaction;Locomotion Safety;Human-centered Path Planning,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 not satisfied: Does not clearly focus on target sectors (logistics, healthcare, field services).",Ambas,Não,
CCBY,J. Saenz; J. Bessler-Etten; M. Valori; G. B. Prange-Lasonder; I. Fassi; C. Bidard; A. B. Lassen; I. Paniti; A. Toth; T. Stuke; S. Wrede; K. Nielsen,An Online Toolkit for Applications Featuring Collaborative Robots Across Different Domains,2023,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9931662,"Collaborative robots (cobots) are being applied in areas such as healthcare, rehabilitation, agriculture and logistics, beyond the typical manufacturing setting. This is leading to a marked increase in the number of cobot stakeholders with little or no experience in traditional safety engineering. Considering the importance of human safety in collaborative robotic applications, this is currently proving to be a barrier to more widespread cobot usage. A web-based Toolkit that targets cobot end-users and manufacturers with varying levels of safety expertise was developed, helping them to understand how to consider the safety of their cobot applications. In this work, we will provide an overview of the state of the art for ensuring cobot safety, highlight the support provided by the “COVR Toolkit” and introduce three examples where third parties applied the Toolkit for their collaborative robotics application.",Human-robot interaction;intelligent robots;occupational safety;robots;safety;standardization,Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.","IC2 not satisfied: Study does not appear to provide data on applications, impacts, HRI, technologies, or challenges.",Ambas,Não,
IEEE,A. Revankar; D. Halapeti; S. Vengurlekar; A. C. Giriyapur,Digital Shadow Enabled Integrated Multi-platform Automation System for Industrial Assembly,2024,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10677321,"This paper presents a fully autonomous assembly line for custom cubes with two sub-block options (plastic and aluminium). Users can design their cubes through an Android app or website interface. The system retrieves orders, processes them based on deadlines, and dispenses the required sub-blocks. A quality inspection station with computer vision and machine learning ensures that defect-free parts are used. Cobots handle sub-block transportation and manipulation throughout the assembly process, with a dedicated station for inserting pins when necessary. A digital Shadow model facilitates performance analysis and optimization. Cloud-based platforms manage data, order processing, and remote access. Finally, an Automated Storage and Retrieval System (ASRS) manages cube storage and delivery. This research demonstrates the potential of combining automation, machine learning, and real-time monitoring for efficient custom product assembly. The approach offers applications in various industries and lays the groundwork for future research on expanding customization options and production flow optimization.",Digital-shadow;Robotic assembly line;Pneumatic systems;Industry 4.0;IoT;Control strategy optimization;MATLAB Simulink;OPC UA server;PLCs,Não,Sim,Diferente,EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"Justification: Strong alignment with all inclusion criteria: Discusses multifunctional/collaborative robots in a target sector (IC1), focuses on practical aspects (IC2), is a 2020-2025 publication (IC5), and is not an excluded type (EC4).",,Sim,
IEEE,J. Felip; D. Gonzalez-Aguirre; L. Nachman,Intuitive & Efficient Human-robot Collaboration via Real-time Approximate Bayesian Inference,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9982251,"The combination of collaborative robots and end-to-end AI, promises flexible automation of human tasks in factories and warehouses. However, such promise seems a few breakthroughs away. In the meantime, humans and cobots will collaborate helping each other. For these collaborations to be effective and safe, robots need to model, predict and exploit human's intents for responsive decision making processes. Approximate Bayesian Computation (ABC) is approach to perform probabilistic predictions upon uncertain quantities. ABC includes priors conveniently, leverages sampling algorithms for inference and is flexible to benefit from complex models, e.g. via simulators. However, ABC is known to be computationally too intensive to run at interactive frame rates required for effective human-robot collaboration tasks. In this paper, we formulate human intent prediction as an ABC problem and describe two key performance innovations which allow computations at interactive rates. Our real-world experiments with a collaborative robot set-up, demonstrate the viability of our proposed approach. Experimental evaluations convey the advantages and value of human intent prediction for packing cooperative tasks. Qualitative results show how anticipating human's intent improves human-robot collaboration without compromising safety. Quantitative task fluency metrics confirm the qualitative claims.",,Sim,Sim,Igual,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.","Strong alignment with all inclusion criteria: Discusses multifunctional/collaborative robots in a target sector (IC1), focuses on practical aspects (IC2), is a 2020-2025 publication (IC5), and is not an excluded type (EC4).",Ambas,Sim,
IEEE,D. Sirintuna; A. Giammarino; A. Ajoudani,An Object Deformation-Agnostic Framework for Human–Robot Collaborative Transportation,2024,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10081043,"In this study, an adaptive object deformability-agnostic human-robot collaborative transportation framework is presented. The proposed framework enables to combine the haptic information transferred through the object with the human kinematic information obtained from a motion capture system to generate reactive whole-body motions on a mobile collaborative robot. Furthermore, it allows rotating the objects in an intuitive and accurate way during co-transportation based on an algorithm that detects the human rotation intention using the torso and hand movements. First, we validate the framework with the two extremities of the object deformability range (i.e., purely rigid aluminum rod and highly deformable rope) by utilizing a mobile manipulator which consists of an Omni-directional mobile base and a collaborative robotic arm. Next, its performance is compared with an admittance controller during a co-carry task of a partially deformable object in a 12-subjects user study. Quantitative and qualitative results of this experiment show that the proposed framework can effectively handle the transportation of objects regardless of their deformability and provides intuitive assistance to human partners. Finally, we have demonstrated the potential of our framework in a different scenario, where the human and the robot co-transport a manikin using a deformable sheet. Note to Practitioners—Transportation of objects which requires the cooperation of multiple partners, is a common task in industrial settings such as factories and warehouses. The existing human-robot collaboration solutions for this task have focused only on purely rigid objects, although deformable objects need to be carried frequently in real-world applications. In this paper, we introduce a human-robot collaborative transportation framework that can handle objects with different deformability ranging from purely rigid to highly deformable. In particular, the proposed framework generates whole-body movements on a mobile collaborative robot by combining of the haptic information transmitted through the object and the human motion information obtained from a motion capture system. Moreover, the framework includes an intuitive way to rotate the object during the execution based on human hand and torso motion. The results of the experiments where objects with various deformability characteristics were transported in collaboration with a mobile manipulator demonstrated the high potential of the proposed approach in a laboratory setting. In the future, we plan to employ a less expensive vision-based human motion tracking system instead of the IMU-based system used in this study. With this change, we will be able to eliminate the need for wearable sensors from the framework presented, which would enhance its usability in real-world scenarios.",Physical human–robot interaction;collaborative object transportation;deformable materials;mobile manipulation;whole-body control,Sim,Sim,Igual,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.","Strong alignment with all inclusion criteria: Discusses multifunctional/collaborative robots in a target sector (IC1), focuses on practical aspects (IC2), is a 2020-2025 publication (IC5), and is not an excluded type (EC4).",Ambas,Sim,
IEEE,A. Müller; L. Penkert; S. Schneider; A. Richert,Investigating gender-stereotyped interactions with virtual agents in public spaces,2022,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9900529,"Current research on the impact of gender appearance in virtual agents and social robots highlights the danger of transmitting and solidifying existing gender stereotypes. To investigate gender-stereotyped interaction at public spaces in dependency of virtual agents gender, we varied the gender of a virtual agent at a metro station. We used an ethnographic study approach, combining a two-day behavior observation with semi-structured interviews with descriptive and qualitative system log analysis of four weeks. Our results show that topics of conversation differ in dependency of the virtual agents gender: the male virtual agent was asked about topics such as brothels, drugs and alcohol and insulted frequently, while the female one was asked for relationship status or about flirting.",feminist HCI;virtual agent;gender stereotyping;public spaces,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 met: Focus is on an excluded sector (e.g., military, space, domestic) without clear application to target sectors.",Ambas,Não,
IEEE,W. Xiang; K. Yu; F. Han; L. Fang; D. He; Q. -L. Han,Advanced Manufacturing in Industry 5.0: A Survey of Key Enabling Technologies and Future Trends,2024,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10121632,"A revolution in advanced manufacturing has been driven by digital technology in the fourth industrial revolution, also known as Industry 4.0, and has resulted in a substantial increase in profits for the industry. In a new paradigm of Industry 5.0, advanced manufacturing will step further and be capable of offering customized products and a better user experience. A number of key enabling technologies are expected to play crucial roles in assisting Industry 5.0 in meeting higher demands of data acquisition and processing, communications, and collaborative robots in the advanced manufacturing process. The aim of this survey is to provide novel insights into advanced manufacturing in Industry 5.0 by summarizing the latest progress of key enabling technologies, such as artificial intelligence of things (AIoT), beyond 5G communications, and collaborative robotics. Finally, key directions for future research to enable this vision to become a reality, such as the industrial metaverse, are outlined.",Advanced manufacturing;artificial intelligence of things (AIoT);beyond 5G communications;collaborative robots (CoBots);digital twin;industrial metaverse;Industry 5.0,Não,Não,Igual,EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 met: Publication appears to be a review, book, thesis, or other excluded type.",Ambas,Não,
IEEE,V. Martins; S. M. Cerqueira; M. Balcells; E. R. Edelman; C. P. Santos,Towards a Human-Sensitive Controller: Learning Human Specificities in Ergonomics and Physical Constraints,2025,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10970165,"Work-Related Musculoskeletal Disorders remain a major challenge in industrial settings, accounting for over half of occupational diseases in Europe and imposing economic and social burdens. These disorders often cause chronic pain and reduced work capacity, highlighting the need for inclusive workstations that adapt to workers' physical constraints. This paper explores Reinforcement Learning (RL) for developing a personalized control strategy for a collaborative robot (cobot). Q-Learning enabled a cobot to optimize human ergonomic posture while considering physical constraints. This model-free approach allows the cobot to learn optimal actions through interaction with the environment, maximizing a reward function designed to minimize ergonomic and pain risk levels. To evaluate discretization effects, two state space levels (10 cm and 6.25 cm) were tested. Models were initially trained in simulation and fine-tuned in real-world settings, Results underscore the importance of fine-tuning policies to bridge the sim-to-real gap. Fine-tuned policies eliminated pain risk and ensured safe ergonomic postures. Performance was evaluated using reward per episode, ergonomic and pain risk levels, and steps per episode, demonstrating RL-driven cobots' potential to enhance worker health and inclusion.",Human-Robot Collaboration;Reinforcement Learning;Physical Constraints,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 met: Focus is on an excluded sector (e.g., military, space, domestic) without clear application to target sectors.",Ambas,Não,
IEEE,L. Rozo; S. Calinon; D. G. Caldwell; P. Jiménez; C. Torras,Learning Physical Collaborative Robot Behaviors From Human Demonstrations,2016,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7450630,"Robots are becoming safe and smart enough to work alongside people not only on manufacturing production lines, but also in spaces such as houses, museums, or hospitals. This can be significantly exploited in situations in which a human needs the help of another person to perform a task, because a robot may take the role of the helper. In this sense, a human and the robotic assistant may cooperatively carry out a variety of tasks, therefore requiring the robot to communicate with the person, understand his/her needs, and behave accordingly. To achieve this, we propose a framework for a user to teach a robot collaborative skills from demonstrations. We mainly focus on tasks involving physical contact with the user, in which not only position, but also force sensing and compliance become highly relevant. Specifically, we present an approach that combines probabilistic learning, dynamical systems, and stiffness estimation to encode the robot behavior along the task. Our method allows a robot to learn not only trajectory following skills, but also impedance behaviors. To show the functionality and flexibility of our approach, two different testbeds are used: a transportation task and a collaborative table assembly.",Physical human–robot interaction;programming by demonstration (PbD);Robot learning;stiffness estimation;Physical human–robot interaction;programming by demonstration (PbD);Robot learning;stiffness estimation,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,IC5 not met: Publication year (2016) is outside the 2020-2025 range.,Ambas,Não,
CCBY,A. Zia; M. Haleem,"Bridging Research Gaps in Industry 5.0: Synergizing Federated Learning, Collaborative Robotics, and Autonomous Systems for Enhanced Operational Efficiency and Sustainability",2025,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10884751,"Industry 5.0 marks a transformative shift in industrial operations, emphasizing human-machine collaboration, sustainability, and intelligent automation. This study conducts a Systematic Literature Review (SLR) to analyze research contributions from leading digital libraries, including IEEE, ACM, Springer, and MDPI, focusing on publications between 1992 and 2024. The objective is to identify existing research gaps, challenges, and synergies across Federated Learning (FL), Collaborative Robotics (Cobots), and Autonomous Systems (AS). From an initial collection of 12,079 papers, a core set of 92 relevant publications was selected based on predefined research questions. This review provides a structured analysis to guide scholars and practitioners in optimizing the interplay between FL, cobots, and autonomous systems, aiming to enhance adaptability, operational resilience, and environmental sustainability. By addressing unresolved challenges and highlighting emerging opportunities, this SLR contributes to bridging research gaps and supports the development of strategic frameworks that balance efficiency with sustainability, advancing the goals of Industry 5.0.",Autonomous systems;blockchain;collaborative robotics;cybersecurity;digital twin technology;federated learning;industry 5.0;operational efficiency;smart manufacturing;sustainability,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 met: Publication appears to be a review, book, thesis, or other excluded type.",Ambas,Não,
IEEE,J. Saenz; I. Fassi; G. B. Prange-Lasonder; M. Valori; C. Bidard; A. B. Lassen; J. Bessler-Etten,COVR Toolkit – Supporting safety of interactive robotics applications,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582659,"Collaborative robots (cobots) are increasingly finding use beyond the traditional domain of manufacturing, in areas such as healthcare, rehabilitation, agriculture and logistics. This development greatly increases the size and variations in the level of expertise of cobot stakeholders. This becomes particularly critical considering the role of human safety for collaborative robotics applications. In order to support the wide range of cobot stakeholders, the EU-funded project COVR “Being safe around collaborative and versatile robots in shared spaces” has developed a freely available, web-based Toolkit that offers support to understand how to consider the safety of cobot applications. This paper describes the state of the art for ensuring safety across various life cycle phases in the development and implementation of collaborative robotics applications and highlights how the Toolkit provides practical support during these tasks. The Toolkit aims to be the most comprehensive resource for supporting cobot stakeholders in ensuring the safety of their applications.",physical human-robot interaction;safety;collaborative robotics;standardization,Não,Não,Igual,EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC2 not satisfied: Study does not appear to provide data on applications, impacts, HRI, technologies, or challenges.",Ambas,Não,
IEEE,W. D. Li,Reinforcement Learning-based Learning from Demonstrations for Collaborative Robots,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551596,"Learning from Demonstrations (LfD) can support a human operator to control a collaborative robot (cobot) in an intuitive means. Gaussian Mixture Model and Gaussian Mixture Regression (GMM and GMR) are useful tools for implementing such a LfD approach. However, well-performed GMM/GMR require a series of demonstrations without trembling and jerky features, which is challenging to achieve in practical applications. To address this issue, in this paper, an improved Reinforcement Learning (RL)-based approach for GMM/GMR is devised to carry out a variety of complex tasks. The innovations of the research are twofold: firstly, a Gaussian noise strategy is designed to scatter demonstrations with trembling and jerky features to better support the optimization of GMM/GMR; Secondly, an improved RL-based optimization algorithm is developed to eliminate potential under-lover-fitting GMM/GMR. A cases study was conducted to verify the approach. Experimental results and comparative analyses showed that this developed approach exhibited good performances in computational efficiency and solution quality.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 not satisfied: Does not clearly focus on target sectors (logistics, healthcare, field services).",Ambas,Não,
IEEE,N. Valchkova; C. Totomirova; R. Zahariev,Establishing a Model Synthesis Method of a Mobile Platform for Service Collaborative Robot,2023,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10389391,"The development of robotics with the possibility of implementing collaborative robots in practice allows their use in services in new social activities such as health care. The paper examines the possibility of robots finding application in supporting the health system to manage pandemics and natural disasters, for example, as was the case with the Coronavirus infection (COVID-19). Such applications include taking a sample from a patient for screening, hospital disinfection, delivery and logistics of food for the infected patient, collection of physiological materials and waste, etc., activities that improve working conditions and reduce the risk of infection of healthcare workers. This paper aims, based on an analysis of hospital activities, to propose a Synthesis Method for a Collaborative Service Robot Model that is applicable to specific activities. The proposed Example Robot is structurally shaped like a dog and is intended for pediatric hospital settings. It can also be used in other medical institutions such as rehabilitation centers, clinics, dental or ophthalmology centers, etc.",service robots;mobile robots;collaborative robots;robot control,Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.","EC4 met: Publication appears to be a review, book, thesis, or other excluded type.",Ambas,Não,
IEEE,A. Kumar Hiremath; P. Nijalingappa; M. Kumar,3 Industry 5.0 – The new beginning of interaction of humans and machines,2025,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11052388.pdf&bkn=11049588&pdfType=chapter,"Industry 5.0 is a human-centered design approach that uses corporate interpersonal platforms to enable personalize autonomous manufacturing by interacting utilizing human capital and cobots. The Core element of Industry 5.0 is the interaction between humans and robots. Through interconnected networks, Industry 5.0 establishes a solid foundation for advanced manufacturing frameworks. It is indeed intended to integrate with various implementations and give enormous computational capability to handle difficult challenges effectively and with much less human involvement. Industry 5.0 refers to technological advancements over Industry 4.0 services, particularly in the context of future personalization services. Meanwhile, developing AI technologies provide sufficient support for the connectivity of buildings, data, energy, transportation, and governance, resulting in a slew of new industrial applications. As a result, there is a need to further investigate the numerous uses of AI technologies to improve/enhance industrial quality, supply chain management, Industry 5.0, and smarter urbanization. Based on a quantifiable investigation, the chapter contributes to the revolutionary industrial aspirations by exploring Industry 5.0 constituents in vertical dimensions. It provides the Need, Progression and Characterization of Industry 5.0 to portray the Convergence of Technologies in Industry 5.0. The exploration of Composition of human centric approach with fifth industry revolution devises the understanding of advancement in industrial revolution.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 not satisfied: Does not clearly focus on target sectors (logistics, healthcare, field services).",Ambas,Não,
IEEE,H. Keenavinna; R. Wickramarachchi,Industry 5.0 Readiness in the Sri Lankan Apparel Industry: A Systematic Literature Review,2025,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10963306,"The Sri Lankan apparel industry is a key player in the global market and is shifting from Industry 4.0 to the transformative paradigm of Industrial Revolution 5.0 (I5.0). Industry 4.0 is more focused on technology-driven, and Industry 5.0 emphasizes human-centric approaches, sustainable practices, and resilience. These advancements integrate technologies including robots, artificial intelligence (AI), blockchain and innovative thinking of humans and expertise, enabling hyper-customization and enhanced interaction between humans and machines. Advancements in the apparel industry can improve the quality standards of products, optimize resource allocation, and create ethical production practices that prioritize worker well-being and sustainability. This systematic literature review (SLR) focuses on critical readiness factors for moving from Industry 4.0 to 5.0, divided into four domains such as technological, sustainable, human-centric and resilience readiness and a roadmap with actionable recommendations for the transition. The findings reveal progress in automation and sustainability efforts within the Sri Lankan apparel industry, but significant gaps remain, particularly in achieving seamless interaction between people and machines and visibility of the supply chain. Limited technological adoption and reliance on traditional methods further challenge the industry’s ability to fully embrace Industry 5.0. By exploring the factors and gaps, this review offers insights into the readiness required for this shift, acknowledges existing research limitations, and outlines future directions to support the Sri Lankan apparel industry in adopting sustainable competitiveness in I5.0.",cobots;industry 4.0;industry 5.0;roadmap;Sri Lankan apparel industry,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 met: Publication appears to be a review, book, thesis, or other excluded type.",Ambas,Não,
IEEE,T. Shakya; M. Sharma; S. Kathuria; N. Yamsani; R. Singh; P. Negi,"Micro, Small & Medium Enterprises Advancement with Artificial Intelligence and Robots",2023,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10263845,"Artificial Intelligence is becoming more prevalent in today's era and adaption of it is in almost every sector. Micro, Small & Medium Enterprises (MSMEs) use AI as a tool for accelerating growth because they have limited resources. This study begins with the introduction of technology and the constraints to adopt Industry 4.0 in MSMEs and the idea of Industry 4.0, which has been introduced into MSMEs with some remedies. It includes the study of Industry 4.0 in which robotics is an important technology that offers a wide range of capabilities in the manufacturing sector. The automation system has been improved by this technology and robotics is gradually leading to the manufacturing high-quality goods. Further talks about the Human-Robot collaborations in MSMEs and then how robots are becoming increasingly popular among MSMEs. In many intelligent factory robots use AI to perform high level tasks. The study also consists of various challenges faced in MSME sector and also includes suggestions and conclusion. The adoption of AI and collaboration of human-robot has proved to be bustling over time to time in the MSME sector.",Artificial Intelligence (AI);Micro;Small and Medium Enterprises (MSMEs);Human-Robot;Cobot;Industry 4.0;Natural Language Processing (NLP),Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 not satisfied: Does not clearly focus on target sectors (logistics, healthcare, field services).",Ambas,Não,
IEEE,R. Maderna; M. Poggiali; A. M. Zanchettin; P. Rocco,An online scheduling algorithm for human-robot collaborative kitting,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197431,"In manufacturing, kitting is the process of grouping separate items together to be supplied as one unit to the assembly line. This is a key logistic task, which is usually performed manually by human operators. However, picking objects from the warehouse implies a great repetitiveness in arm motion. Moreover, the weight and position of items may increase the physical strain and induce the development of work-related musculoskeletal disorders. The inclusion of a collaborative robot in the process may help to reduce the operator's effort and increase productivity. This paper introduces an online scheduling algorithm to guide the picking operations of the human and the robot. The proposed approach has been experimentally evaluated and compared with an offline scheduler, as well as with the baseline case of manual kitting.",,Não,Sim,Diferente,EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"Strong alignment with all inclusion criteria: Discusses multifunctional/collaborative robots in a target sector (IC1), focuses on practical aspects (IC2), is a 2020-2025 publication (IC5), and is not an excluded type (EC4).",,Sim,
IEEE,J. Sandoval; M. A. Laribi; J. P. Faure; C. Brèque; J. P. Richer; S. Zeghloul,Towards an Autonomous Robot-Assistant for Laparoscopy Using Exteroceptive Sensors: Feasibility Study and Implementation,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9477029,"A new autonomous camera-holder robotic system for Laparoscopic Surgery (LS) is presented in this paper. In the proposed system, a 7-DoF collaborative robot holds and moves the laparoscope, or surgical camera, so that it permanently points towards the instruments’ tips. A motion capture (MoCap) system, tracking online the surgical instruments, provides the robot's controller with instrument's motion data. Unlike the existing systems, this paper proposes an autonomous robot-assistant, freeing up surgeons from the laparoscope motion control, fully responding to the surgical community requirements. Moreover, a fully compliance control law is implemented. In task-space, it is suitable for smoothing robot movements and reducing the contact forces generated at the trocar. Null-space is also exploited through a compliance control law restricting the elbow's robot motion into a desired range, defined to avoid undesired collisions with the rest of the medical equipment. Robot Operating System (ROS) framework has been used to establish the communication between the robot and MoCap system, using the UDP protocol for data exchange. Training tasks, such as suturing training, have been performed by surgeons to validate the usefulness of the proposed platform, proving that a collaborative robot can autonomously comply with camera-holder assistant tasks.",Medical robot;collaborative robot;human-robot interaction;redundant robot,Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract. ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).","EC2 met: Focus is on an excluded sector (e.g., military, space, domestic) without clear application to target sectors.",Ambas,Não,
IEEE,F. Bertocci; A. Grandoni; L. Francalanci; A. Fabbrizzi,Design of Robot-based Measurement System for the Quality Assessment of Ultrasound Probes for Medical Imaging,2020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9137326,"The collaborative robot becomes very attractive applied to the manufacturing process of the ultrasound (US) probes for medical imaging, in which the electroacoustic characterization (pulse-echo test) plays a crucial role for the final product quality assessment. Unfortunately, commercial measurement systems show poor automation features and they are totally worker dependent that negatively affects both the operating cycle time and the data reproducibility, especially for the calibration phase. The aim of this feasibility study is to design a partially automated system for limiting the variability and the cycle time of the measurement by means of a collaborative robot, UR5, with an electric gripper and a 3D-printed adapter. Preliminary tests suggested that the collaboration between a collaborative robot, the so-called co-bots, and the human could open to a tangible advantage in terms of efficiency for the US probes manufacturing process. The higher repeatability performance of the co-bot with the reduction of the calibration time compared to the manual approach helps the trained worker for enhancing the quality assessment in an industrial scenario of thousands-demand per year of medical ultrasound probes.",measurement system;electroacoustic characterization;quality assessment;collaborative robot;medical ultrasound probe;human-robot interaction,Sim,Não,Diferente,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.","IC1 not satisfied: Does not clearly focus on target sectors (logistics, healthcare, field services).",,Sim,
IEEE,D. Vajpayee; N. Gupta; V. Joshi,Digital Transformation in Mechatronics: ICT Applications in Automation and Robotics,2024,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10911320,"Mechatronics, a multidisciplinary field and transformed the conventional methods to dynamic and autonomous systems. The emergence of robotics and technology in various sectors marks a significant revolution in the industry specially in manufacturing, construction, food, and pharmaceutical industries. This ensured quality, efficiency and precision in the concerned industries. Based on this background, it is from this perspective that the paper addresses transformatory work in collaborative robots, automation technologies, and robotic manipulators through object recognition, human-robot interaction, and machine learning applications. Reviewing the key technologies- machine vision, thermography etc. that transformed the quality control across the industries, enhancing the reliability and precision and efficiency of the product.Autonomous robots and manipulators in conjunction with the da Vinci Surgical System represent huge promise for surgical purposes and therapeutic interventions within medicine. Discuss some of the challenges in the path planning for system adaptability and insist on the need for robust data in medical robotics, besides the key success factors for adopting robotics in every other sector. This research marks how the growing role of robotics, which includes changing industries that are driving the Fourth Industrial Revolution, offset labor shortages, and growing global demands, is being found.",Mechatronics;Quality Control;Industry 4.0;Collaborative Robots(Cobots);Machine Vision;Thermography;Radiography;Robotic Inspection;Automation;Intelligent Manufacturing;Cyber-Physical System(CPS);Advanced Mechatronics System (AMS);Artificial Intelligence;Edge Computing;Predictive Maintenance;Non-Destructive Testing;Sensing Technology;Wireless Connectivity;Industrial Robotics;Autonomous Systems,Sim,Sim,Igual,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.",Strong alignment with all inclusion criteria.,Ambas,Sim,
IEEE,,2 Industry 5.0 and 6G: Human-centric Approach,2024,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10440224.pdf&bkn=10440194&pdfType=chapter,"This book covers need for 6G connectivity arising from the pursuit of higher data speeds, ultra-low latency, massive IoT connectivity, enhanced spectral efficiency, and the facilitation of new and transformative applications. By addressing these drivers and expectations, 6G aims to revolutionize wireless communication, opening up a realm of possibilities for industries, societies, and individuals. Technological improvements and evolutions are required beyond fifth-generation (5G) networks for wireless communications as well as in the industry where the involvement of collaborative robots (COBOT) will satisfy the personal needs of human beings as and when required leading to human–machine interactions. A considerable amount of effort has been devoted, both in industry and academia, towards the performance modelling, evaluation and prediction of convergent multi-service heterogeneous, future-generation networks such as 6G. Technical topics discussed in the book include: • Network security and attacks • 6G applications and Industry 5.0 • Human centric interface • Green computing in wireless cellular networks • Next generation networks (IOT, Cloud Computing, Big Data, etc.).",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).",Ambas,Não,
CCBYNCND,F. J. Ruiz-Ruiz; J. M. Gandarias; F. Pastor; J. M. Gómez-De-Gabriel,Upper-Limb Kinematic Parameter Estimation and Localization Using a Compliant Robotic Manipulator,2021,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9381204,"Assistive and rehabilitation robotics have gained momentum over the past decade and are expected to progress significantly in the coming years. Although relevant and promising research advances have contributed to these fields, challenges regarding intentional physical contact with humans remain. Despite being a fundamental component of assistive and rehabilitation tasks, there is an evident lack of work related to robotic manipulators that intentionally manipulate human body parts. Moreover, existing solutions involving end-effector robots are not based on accurate knowledge of human limb dimensions and their current configuration. This knowledge, which is essential for safe human-limb manipulation, depends on the grasping location and human kinematic parameters. This paper addresses the upper-limb manipulation challenge and proposes a pose estimation method using a compliant robotic manipulator. To the best of our knowledge, this is the first attempt to address this challenge. A kinesthetic-based approach enables estimation of the kinematic parameters of the human arm without integrating external sensors. The estimation method relies only on proprioceptive data obtained from a collaborative robot with a Cartesian impedance-based controller to follow a compliant trajectory that depends on human arm kinodynamics. The human arm model is a 2-degree of freedom (DoF) kinematic chain. Thus, prior knowledge of the arm's behavior and an estimation method enables estimation of the kinematic parameters. Two estimation methods are implemented and compared: i) Hough transform (HT); ii) least squares (LS). Furthermore, a resizable, sensorized dummy arm is designed for experimental validation of the proposed approach. Outcomes from six experiments with different arm lengths demonstrate the repeatability and effectiveness of the proposed methodology, which can be used in several rehabilitation robotic applications.",Human–robot interaction;motion analysis;robot motion;assistive robotics,Sim,Não,Diferente,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.","IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges.",,Sim,
IEEE,J. A. Delgado-Guerrero; A. Colomé; S. Foix; C. Torras,Safety Methods for Cartesian Control of Redundant Robotic Arms,2024,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10797461,"Over the last years, the interest in robot safety has increased, due to the improvements in applications such as assistive robotics, co-manipulation or manufacturing cobots. In these scenarios that include physical interactions between humans and robots, it is of upmost importance to have both passive and active safety layers that prevent robotic arms to behave in an unsafe manner. Ultimately, the safety measures that can be applied might depend on the sensors installed on a robot. Robots with joint torque sensors often base their safety in reactive behaviors when a contact is detected. However, robots should be able to also have safety layers that do not depend on detected contacts. In this paper, we show several additions to robotic Cartesian controllers that can significantly improve safety in human-robot physical interaction for robots with joint position encoders only.",RECOGNITION; INTELLIGENCE,Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.","IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges.",Ambas,Não,
Web of Science,"Mendez, E; Ochoa, O; Olivera-Guzman, D; Soto-Herrera, VH; Luna-Sánchez, JA; Lucas-Dophe, C; Lugo-del-Real, E; Ayala-Garcia, IN; Perez, MA; González, A",Integration of Deep Learning and Collaborative Robot for Assembly Tasks,2024,http://dx.doi.org/10.3390/app14020839,"Human-robot collaboration has gained attention in the field of manufacturing and assembly tasks, necessitating the development of adaptable and user-friendly forms of interaction. To address this demand, collaborative robots (cobots) have emerged as a viable solution. Deep Learning has played a pivotal role in enhancing robot capabilities and facilitating their perception and understanding of the environment. This study proposes the integration of cobots and Deep Learning to assist users in assembly tasks such as part handover and storage. The proposed system includes an object classification system to categorize and store assembly elements, a voice recognition system to classify user commands, and a hand-tracking system for close interaction. Tests were conducted for each isolated system and for the complete application as used by different individuals, yielding an average accuracy of 91.25%. The integration of Deep Learning into cobot applications has significant potential for transforming industries, including manufacturing, healthcare, and assistive technologies. This work serves as a proof of concept for the use of several neural networks and a cobot in a collaborative task, demonstrating communication between the systems and proposing an evaluation approach for individual and integrated systems.",,Não,Sim,Diferente,EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,Strong alignment with all inclusion criteria.,,Sim,
Web of Science,"Ochoa, O; Mendez, E; Lucas-Dophe, C; Luna-Sánchez, JA; Soto-Herrera, VH; Olivera-Guzman, D; Perez, MA; del-Real, E; Ayala-García, IN; González, A",Flexible Human-robot interaction: collaborative robot integrated with hand tracking,2023,http://dx.doi.org/10.1109/COMROB60035.2023.10349712,"The rising demand for adaptable and user-friendly forms of interaction in the field of manufacturing and assembly tasks has led to increased attention on human-robot collaboration. Collaborative robots (cobots) have emerged as a promising solution to address this demand. In this study, we propose the integration and application of cobots along with a pre-trained deep learning model to assist users in assembly activities, specifically part handover and storage. The human-robot interaction is facilitated through a hand tracking system that enables a close approach to the user's hand. Testing on the system yielded 99% accuracy. The incorporation of deep learning models in cobot applications holds substantial potential for industry transformation, with implications spanning manufacturing, healthcare, and assistive technologies. This research serves as a compelling proof of concept, showcasing the effective implementation of deep learning models to facilitate close human-robot interactions.",,Não,Não,Igual,EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges.",Ambas,Não,
Web of Science,"Klebbe, R; Friese, C",Exploring the Role of Robots in Inpatient Care: Caregivers Perspectives on the Development and Evaluation of Collaborative Robot Applications - A Qualitative Research Approach,2025,http://dx.doi.org/10.1007/s12369-025-01270-1,"Although current approaches to robotics for healthcare show promising opportunities for support in various fields of application, they often do not yet provide substantial relief in the work routines of caregivers. A key challenge is that normative principles of good care are still insufficiently considered in the conceptualization. In order to develop approaches that are adapted to these principles, it is crucial to align technical capabilities and agency with professional intervention goals and needs. Based on a qualitative research approach with semi-structured interviews, this work aims at (1) developing two robot-assisted application scenarios based on caregivers' requirements, (2) identifying associated prerequisites for agency and robot-capabilities, and (3) identifying target-group related evaluation criteria for robot use. 30 healthcare professionals were included in the study. The results show that most participants support the areas of application we proposed for discussion. Depending on the robots' capabilities and the medical conditions of the care receivers, the robots were granted a high degree of autonomy. At the same time, caregivers must be involved at various times to fulfill their responsibility for the care process. Acceptance- and process-related criteria were identified for the evaluation of the robot application. Our study revealed that a successful use of robotics requires an early involvement of user groups in order to derive relevant robot capabilities and to transfer them into a robust concept of the distribution of agency and responsibility between caregiver, robot, and care receiver.",REPRESENTING DISTRIBUTED COGNITION; SITUATION AWARENESS; SYSTEMS; AUTOMATION; COMPLEXITY,Não,Sim,Diferente,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,Strong alignment with all inclusion criteria.,,Sim,
Web of Science,"Adriaensen, A; Berx, N; Pintelon, L; Costantino, F; Di Gravio, G; Patriarca, R",Interdependence Analysis in collaborative robot applications from a joint cognitive functional perspective,2022,http://dx.doi.org/10.1016/j.ergon.2022.103320,"This paper sets up a framework to assess co-agency in human-robot interactions, and applies it specifically to the socio-technical safety analysis of collaborative robots. We also examine to what extent the concept of Situation Awareness can be applied to assess collaborative robots as efficient team members in socio-technical systems. We explain some theoretical concerns with traditional concepts of Situation Awareness and defend why the concept of Joint Cognitive Systems, which maps the conceptualization of the cognitive system onto the work system as a whole, is best suited for issues of distributed cognition and controllability in human-robot interaction. Thereafter we present a five-step methodology specifically conceived for cobot applications serving the aim of goal coordination between multiple agents by functional interactions. The proposed framework merges two existing safety and resilience analysis methods, being the Functional Resonance Analysis Method and Interdependence Analysis. These methods are used in combination to assess shared control in safe and efficient human-robot interaction from a systems-thinking perspective. This allows to describe the systemic conditions for Distributed Situation Awareness in terms of observable system interactions and as an emergent object of distributed cognition. Instead of looking at undesirable safety outcomes, we have imposed the focus of co-agency as the unit of analysis in line with the Joint Cognitive Systems perspective. The theoretical insights from this paper are additionally applied to a hypothetical but credible demonstration case study with collaborative warehouse robots.",DEEP; MACHINE; CONTEXT,Sim,Sim,Igual,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.",Strong alignment with all inclusion criteria.,Ambas,Sim,
Web of Science,"Borboni, A; Reddy, KVV; Elamvazuthi, I; AL-Quraishi, MS; Natarajan, E; Ali, SSA",The Expanding Role of Artificial Intelligence in Collaborative Robots for Industrial Applications: A Systematic Review of Recent Works,2023,http://dx.doi.org/10.3390/machines11010111,"A collaborative robot, or cobot, enables users to work closely with it through direct communication without the use of traditional barricades. Cobots eliminate the gap that has historically existed between industrial robots and humans while they work within fences. Cobots can be used for a variety of tasks, from communication robots in public areas and logistic or supply chain robots that move materials inside a building, to articulated or industrial robots that assist in automating tasks which are not ergonomically sound, such as assisting individuals in carrying large parts, or assembly lines. Human faith in collaboration has increased through human-robot collaboration applications built with dependability and safety in mind, which also enhances employee performance and working circumstances. Artificial intelligence and cobots are becoming more accessible due to advanced technology and new processor generations. Cobots are now being changed from science fiction to science through machine learning. They can quickly respond to change, decrease expenses, and enhance user experience. In order to identify the existing and potential expanding role of artificial intelligence in cobots for industrial applications, this paper provides a systematic literature review of the latest research publications between 2018 and 2022. It concludes by discussing various difficulties in current industrial collaborative robots and provides direction for future research.",PROBABILISTIC ROADMAPS,Não,Não,Igual,EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 Met: Study is a review, survey, or meta-analysis.",Ambas,Não,
Web of Science,"Xia, XK; Li, T; Sang, SB; Cheng, YQ; Ma, HZ; Zhang, Q; Yang, K",Path Planning for Obstacle Avoidance of Robot Arm Based on Improved Potential Field Method,2023,http://dx.doi.org/10.3390/s23073754,"In medical and surgical scenarios, the trajectory planning of a collaborative robot arm is a difficult problem. The artificial potential field (APF) algorithm is a classic method for robot trajectory planning, which has the characteristics of good real-time performance and low computing consumption. There are many variants of the APF algorithm, among which the most widely used variants is the velocity potential field (VPF) algorithm. However, the traditional VPF algorithm has inherent defects and problems, such as easily falling into local minimum, being unable to reach the target, poor dynamic obstacle avoidance ability, and safety and efficiency problems. Therefore, this work presents the improved velocity potential field (IVPF) algorithm, which considers direction factors, obstacle velocity factor, and tangential velocity. When encountering dynamic obstacles, the IVPF algorithm can avoid obstacles better to ensure the safety of both the human and robot arm. The IVPF algorithm also does not easily fall into a local problem when encountering different obstacles. The experiments informed the RRT* algorithm, VPF algorithm, and IVPF algorithm for comparison. Compared with the informed RRT* and VPF algorithm, the result of experiments indicate that the performances of the IVPF algorithm have significant improvements when dealing with different obstacles. The main aim of this paper is to provide a safe and efficient path planning algorithm for the robot arm in the medical field. The proposed algorithm can ensure the safety of both the human and the robot arm when the medical and surgical robot arm is working, and enables the robot arm to cope with emergencies and perform tasks better. The application of the proposed algorithm could make the collaborative robots work in a flexible and safe condition, which could open up new opportunities for the future development of medical and surgical scenarios.",IMPEDANCE CONTROL; VARIABLE IMPEDANCE; SAFETY ASSESSMENT; FORCE; FRAMEWORK; TELEOPERATION; MANIPULATORS; TASKS,Sim,Não,Diferente,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.","IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).",,Sim,
Web of Science,"Hameed, A; Ordys, A; Mozaryn, J; Sibilska-Mroziewicz, A",Control System Design and Methods for Collaborative Robots: Review,2023,http://dx.doi.org/10.3390/app13010675,"Collaborative robots cooperate with humans to assist them in undertaking simple-to-complex tasks in several fields, including industry, education, agriculture, healthcare services, security, and space exploration. These robots play a vital role in the revolution of Industry 4.0, which defines new standards of manufacturing and the organization of products in the industry. Incorporating collaborative robots in the workspace improves efficiency, but it also introduces several safety risks. Effective safety measures then become indispensable to ensure safe and robust interaction. This paper presents the review of low-level control methodologies of a collaborative robot to assess the current status of human-robot collaboration over the last decade. First, we discuss the classification of human-robot collaboration, architectures of systems and the complex requirements on control strategies. The most commonly used control approaches were presented and discussed. Several methods of control, reported in industrial applications, are elaborated upon with a prime focus on HR-collaborative assembly operations. Since the physical HRC is a critical control problem for the co-manipulation task, this article identifies key control challenges such as the prediction of human intentions, safety, and human-caused disturbances in motion synchronization; the proposed solutions were analyzed afterwards. The discussion at the end of the paper summarizes the features of the control systems that should be incorporated within the systematic framework to allow the execution of a robotic task from global task planning to low-level control implementation for safe and robust interactions.",TASK ALLOCATION; MOBILE ROBOTS; FRAMEWORK; AUTOMATION; SYSTEM,Não,Não,Igual,EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 Met: Study is a review, survey, or meta-analysis.",Ambas,Não,
Web of Science,"Duorinaah, FX; Rajendran, M; Kim, TW; Kim, JI; Lee, S; Lee, S; Kim, MK",Human and Multi-Robot Collaboration in Indoor Environments: A Review of Methods and Application Potential for Indoor Construction Sites,2025,http://dx.doi.org/10.3390/buildings15152794,"The integration of robotic agents into complex indoor construction environments is increasing, particularly through human-robot collaboration (HRC) and multi-robot collaboration (MRC). These collaborative frameworks hold great potential to enhance productivity and safety. However, indoor construction environments present unique challenges, such as dynamic layouts, constrained spaces, and variable lighting conditions, which complicate the safe and effective deployment of collaborative robot teams. Existing studies have primarily addressed various HRC and MRC challenges in manufacturing, logistics, and outdoor construction, with limited attention given to indoor construction settings. To this end, this review presents a comprehensive analysis of human-robot and multi-robot collaboration methods within various indoor domains and critically evaluates the potential of adopting these methods for indoor construction. This review presents three key contributions: (1) it provides a structured evaluation of current human-robot interaction techniques and safety-enhancing methods; (2) it presents a summary of state-of-the-art multi-robot collaboration frameworks, including task allocation, mapping, and coordination; and (3) it identifies major limitations in current systems and provides research directions for enabling scalable, robust, and context-aware collaboration in indoor construction. By bridging the gap between current robotic collaboration methods and the needs of indoor construction, this review lays the foundation for the development of adaptive and optimized collaborative robot deployment frameworks for indoor built environments.",APPEARANCE; AUTOMATION; GENDER,Não,Não,Igual,EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 Met: Study is a review, survey, or meta-analysis.",Ambas,Não,
Web of Science,"Pinto, A; Sousa, S; Simoes, A; Santos, J","A Trust Scale for Human-Robot Interaction: Translation, Adaptation, and Validation of a Human Computer Trust Scale",2022,http://dx.doi.org/10.1155/2022/6437441,"Recently there has been an increasing demand for technologies (automated and intelligent machines) that brings benefits to organizations and society. Similar to the widespread use of personal computers in the past, today's needs are towards facilitating human-machine technology appropriation, especially in highly risky and regulated industries like robotics, manufacturing, automation, military, finance, or healthcare. In this context, trust can be used as a critical element to instruct how human-machine interaction should occur. Considering the context-dependency and multidimensional trust, this study seeks to find a way to measure the effects of perceived trust in a collaborative robot (cobot), regardless of its literal credibility as a real person. This article aims at translating, adapting, and validating a Human-Computer Trust Scale (HCTM) in human-robot interaction (HRI) context and its application to cobots. The Human-Robot Interaction Trust Scale (HRITS) involved 239 participants and included eleven items. The 2nd order CFA with a general factor called trust  have proven to be empirically robust (CFI=.94; TLI=.93; SRMR=.04; and RMSEA=.05) [CR=.84; AVE=.58, and MaxRH=.92]; results indicated a good measurement of the general factor trust, and the model satisfied the criteria for measure trust. An analysis of the differences in perceptions of trust by gender was conducted using a t-test. This analysis showed that statistical differences by gender exist (p=.04). This study's results allowed for a better understanding of trust in HRI, specifically regarding cobots. The validation of a Portuguese scale for trust assessment in HRI can give a valuable contribution to designing collaborative environments between humans and robots.",THERAPY,Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract. ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).","IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges.",Ambas,Não,
Web of Science,"Chiriatti, G; Carbonari, L; Ceravolo, MG; Andrenelli, E; Millevolte, M; Palmieri, G",A Robot-Assisted Framework for Rehabilitation Practices: Implementation and Experimental Results,2023,http://dx.doi.org/10.3390/s23177652,"One of the most interesting characteristics of collaborative robots is their ability to be used in close cooperation scenarios. In industry, this facilitates the implementation of human-in-loop workflows. However, this feature can also be exploited in different fields, such as healthcare. In this paper, a rehabilitation framework for the upper limbs of neurological patients is presented, consisting of a collaborative robot that helps users perform three-dimensional trajectories. Such a practice is aimed at improving the coordination of patients by guiding their motions in a preferred direction. We present the mechatronic setup, along with a preliminary experimental set of results from 19 volunteers (patients and control subjects) who provided positive feedback on the training experience (52% of the subjects would return and 44% enjoyed performing the exercise). Patients were able to execute the exercise, with a maximum deviation from the trajectory of 16 mm. The muscular effort required was limited, with average maximum forces recorded at around 50 N.",,Sim,Sim,Igual,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.",Strong alignment with all inclusion criteria.,Ambas,Sim,
Web of Science,"Hernández, OG; Morell, V; Ramon, JL; Garcia, GJ; Jara, CA",RGBD Data Analysis for the Evaluation of Trajectory Planning Algorithms in Human Robot Interaction Environments for Rehabilitation,2023,http://dx.doi.org/10.1007/978-3-031-21065-5_30,"Robotic platforms are a great solution to ensure assistance and rehabilitation for disabled people using human-robot interaction capabilities. However, safe path planning trajectories are required by the robotic platform to avoid any collision between the human and the robot during the assistance or rehabilitation process. This paper proposes an intelligent robotic system that supervises the environment using 3D data from an RGB-Depth sensor and performs safe trajectories of the collaborative robot manipulator. Human-robot interactions are focused on upper-limb rehabilitation exercises about reaching a point using a collaborative robot UR3. Finally, several planning algorithms from Open Motion Planning Library (OMPL) are evaluated in order to obtain some metrics of the human-robot interaction and to find out the best one.",VALUE CO-CREATION,Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.","IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).",Ambas,Não,
Web of Science,"Zapata, OSM; Correa, YG; Yoshioka, LR; Silva, JR",Modeling Requirements for Collaborative Robotic Services,2023,http://dx.doi.org/10.3390/eng4040165,"Collaborative robots have experienced low acceptance in applications, especially in industry. This fact has attracted the attention of researchers and practitioners, who point to different causes for this limited acceptance. One of the main reasons is the difficulty in converging on suitable methods for modeling collaborative interactions between robots and their surrounding context during the requirements phase. These interactions must be elicited and modeled during the requirements stage to maximize value creation through collaboration. Formal verification is necessary, taking into account the risks of human-robot interaction. However, such modeling is often absent in collaborative robot design, and choosing an appropriate approach remains an open problem. This paper addresses this problem using a model-based requirements cycle where the value creation is detached to provide direct analysis, possible optimization, and formal verification. The general process integrates with the general model-based requirements engineering of the remaining system. This service system approach relies on a goal-oriented requirements approach, and specific algorithms were developed to transfer goal-oriented diagrams into Petri Nets-to provide formal process verification. A case study illustrates the application of the proposed method on a collaborative robot used in a university hospital environment.",TASK ALLOCATION; DESIGN,Sim,Sim,Igual,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.",Strong alignment with all inclusion criteria,Ambas,Sim,
Web of Science,"Gualtieri, L; Rauch, E; Vidoni, R; Matt, DT",An evaluation methodology for the conversion of manual assembly systems into human-robot collaborative workcells,2019,http://dx.doi.org/10.1016/j.promfg.2020.01.046,"A collaborative robot is an industrial robot, which is able to interact physically and safe with humans in a shared and collaborative hybrid workspace. Collaborative robots are introduced helping operators to perform manual activities in modern manufacturing systems combining human inimitable ability with smart machines strengths. Considering current small and medium enterprises, the introduction of industrial collaborative robots involves the retrofitting process of current production systems, which in many cases is the starting point for collaborative process development. Due to the fact that collaborative assembly will be one of the most challenging and interesting applications for collaborative robotics in the near future, a proper human-robot assembly activity division will be a fundamental part of that retrofitting process. The aim of this work is the development of an evaluation methodology for the conversion from a purely manual assembly workstation into a collaborative one, by considering human and robot activities separation. The proposed model in this paper is based on a technical, qualitative and economic evaluation of the current manufacturing system in order to identify if there is the possibility to successfully re-design the workstation by introducing a collaborative robot in an efficient way. Safety and ergonomics indexes are also considered in order to improve operators work conditions between the current and the desired situation. (C) 2019 The Authors. Published by Elsevier B.V.",CAMERA HOLDER; IMPEDANCE CONTROL; SURGERY,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,IC5 Not Met: Publication year (2019) is outside the 2020-2025 range.,Ambas,Não,
Web of Science,"Sandoval, J; Laribi, MA; Faure, JP; Brèque, C; Richer, JP; Zeghloul, S",Towards an Autonomous Robot-Assistant for Laparoscopy Using Exteroceptive Sensors: Feasibility Study and Implementation,2021,http://dx.doi.org/10.1109/LRA.2021.3094644,"A new autonomous camera-holder robotic system for Laparoscopic Surgery (LS) is presented in this paper. In the proposed system, a 7-DoF collaborative robot holds and moves the laparoscope, or surgical camera, so that it permanently points towards the instruments' tips. A motion capture (MoCap) system, tracking online the surgical instruments, provides the robot's controller with instrument's motion data. Unlike the existing systems, this paper proposes an autonomous robot-assistant, freeing up surgeons from the laparoscope motion control, fully responding to the surgical community requirements. Moreover, a fully compliance control law is implemented. In task-space, it is suitable for smoothing robot movements and reducing the contact forces generated at the trocar. Null-space is also exploited through a compliance control law restricting the elbow's robot motion into a desired range, defined to avoid undesired collisions with the rest of the medical equipment. Robot Operating System (ROS) framework has been used to establish the communication between the robot and MoCap system, using the UDP protocol for data exchange. Training tasks, such as suturing training, have been performed by surgeons to validate the usefulness of the proposed platform, proving that a collaborative robot can autonomously comply with camera-holder assistant tasks.",,Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract. ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).","EC2 Met: Focus on an excluded sector (e.g., domestic, military) without application to target sectors.; IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).; IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges.",Ambas,Não,
Web of Science,"Paniti, I; Nacsa, J; Szur, D; Rácz, S; Tóth, J",COMPLEMENTARY MANIPULATOR TOOL DEVELOPMENT FOR SAFE COBOT-ASSISTED HYDROPONICS,2021,http://dx.doi.org/10.33927/hjic-2021-27,"Human-robot collaboration is gaining ground in Manufacturing, Healthcare and Logistics but also in Agriculture. Different types of applications in the latter field are becoming more common. However, in all scenarios, safety assessment and verification are crucial to cope with the related standards and specifications. In this paper, the development and safety testing of a complementary manipulator tool (Clip) is presented which can by design limit the physical interaction energy in a hazardous collaborative robot (cobot) scenario, namely when loading the plant of a Hydroponic System.",AUTOMATION,Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.","IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges.",Ambas,Não,
Web of Science,"Grahn, S; Langbeck, B; Johansen, K; Backman, B","Potential advantages using large anthropomorphic robots in human-robot collaborative, hand guided assembly",2016,http://dx.doi.org/10.1016/j.procir.2016.02.036,"Collaborative robot installations often mean man-machine workspace sharing. This mode of operation can lead to reductions of tact time and work space requirements. We have analyzed potential further benefits of man machine collaboration, where operators and powerful robots share workspace, cooperating when lifting and handling large objects. We found that this mode of operation has the potential to generate economic advantages by reducing the need for manual operators and lifting tools and by offering new opportunities for component logistics. (C) 2016 The Authors. Published by Elsevier B.V.",,Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract. ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).","IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges.; IC5 Not Met: Publication year (2016) is outside the 2020-2025 range.",Ambas,Não,
Web of Science,"Wada, H; Kinugawa, J; Kosuge, K",Trajectory Planning in Time Augmented C-space Using RRT with Sampling Point Including Velocity Determined by Initial Conditions,2020,http://dx.doi.org/10.1109/sii46433.2020.9025821,"The introduction of collaborative robots is expected as one of the solutions for the labor shortage. To implement the collaborative robot in an industrial line, real-time motion planning is necessary to determine a robot's trajectory in order to consider the moving workers. In this paper, we propose a real-time trajectory planning method for co-worker robot based on the RRT in configuration-time space. Motion planning in configuration-time space is effective to avoid moving obstacles while considering robot dynamics and target reach time. In order to consider the dynamics of a robot in a time augmented configuration space, it is necessary to smoothly connect the robot velocities. The proposed method set the velocity of the sampling points depending on the initial condition in configuration-time space. In the simulation, we found that the proposed method has a higher success rate than the method without considering the velocity of the sampling points. Experiments using PaDY that we have developed show the effectiveness of the proposed method in an environment with two moving workers.",AUTOMATION,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 Met: Focus on an excluded sector (e.g., domestic, military) without application to target sectors.; IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).; IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges.",Ambas,Não,
Web of Science,"Liu, SC; Zhang, JJ; Wang, LH; Gao, RX",Vision AI-based human-robot collaborative assembly driven by autonomous robots,2024,http://dx.doi.org/10.1016/j.cirp.2024.03.004,"Autonomous robots that understand human instructions can significantly enhance the efficiency in humanrobot assembly operations where robotic support is needed to handle unknown objects and/or provide ondemand assistance. This paper introduces a vision AI-based method for human-robot collaborative (HRC) assembly, enabled by a large language model (LLM). Upon 3D object reconstruction and pose establishment through neural object field modelling, a visual servoing-based mobile robotic system performs object manipulation and navigation guidance to a mobile robot. The LLM model provides text-based logic reasoning and high-level control command generation for natural human-robot interactions. The effectiveness of the presented method is experimentally demonstrated. (c) 2024 The Author(s). Published by Elsevier Ltd on behalf of CIRP. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/)",TRAVELING SALESPERSON PROBLEMS; ASSIGNMENT; ALLOCATION; ALGORITHM; TAXONOMY; SEARCH,Não,Sim,Diferente,EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,Strong alignment with all inclusion criteria.,,Sim,
Web of Science,"Antonyshyn, L; Silveira, J; Givigi, S; Marshall, J",Multiple Mobile Robot Task and Motion Planning: A Survey,2023,http://dx.doi.org/10.1145/3564696,"With recent advances in mobile robotics, autonomous systems, and artificial intelligence, there is a growing expectation that robots are able to solve complex problems. Many of these problems require multiple robots working cooperatively in a multi-robot system. Complex tasks may also include the interconnection of task-level specifications with robot motion-level constraints. Many recent works in the literature use multiple mobile robots to solve these complex tasks by integrating task and motion planning. We survey recent contributions to the field of combined task and motion planning for multiple mobile robots by categorizing works based on their underlying problem representations, and we identify possible directions for future research. We propose a taxonomy for task and motion planning based on system capabilities, applicable to multi-robot and single-robot systems.",COBOT; PRODUCTIVITY; WORKING; LINE,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 Met: Study is a review, survey, or meta-analysis.; IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).; IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges",Ambas,Não,
Web of Science,"Shah, R; Doss, ASA; Lakshmaiya, N","Advancements in AI-enhanced collaborative robotics: towards safer, smarter, and human-centric industrial automation",2025,http://dx.doi.org/10.1016/j.rineng.2025.105704,"Traditional industrial robots have long been central to manufacturing automation; however, limitations such as inflexible programming, safety concerns in human-robot interaction, and poor adaptability to dynamic production needs have restricted their widespread application. Collaborative robots (cobots) are reshaping this paradigm by enabling safe, efficient, and intelligent human-robot collaboration. This review examines the evolution and integration of collaborative robots (cobots) with Artificial Intelligence (AI), machine learning, and smart sensing technologies to enhance safety, adaptability, and human-centric automation. The paper explores how AI-enhanced cobots optimize production efficiency by reducing cycle times, improving product quality, and facilitating adaptive manufacturing in the automotive, healthcare, and logistics sectors. It highlights critical safety innovations like force-limiting systems, speed and separation monitoring, and ergonomic human-robot interaction. Furthermore, emerging concepts such as digital twins, blockchain for cybersecurity, and Internet of Robotic Things (IoRT) are examined for their potential to advance cobot functionality. Challenges including high initial costs, technical complexity, and cybersecurity threats are critically analyzed. Future trends, including cognitive adaptability, personalized interaction, and the shift toward Industry 5.0 ' s human-centered approach, are also explored. This study identifies key opportunities and challenges in collaborative robotics and proposes strategic pathways for fostering safer, smarter, and more flexible industrial environments.",AUGMENTED REALITY; TELEOPERATION,Não,Não,Igual,EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 Met: Study is a review, survey, or meta-analysis",Ambas,Não,
Web of Science,"Li, CX; Zheng, P; Li, SF; Pang, YM; Lee, CKM",AR-assisted digital twin-enabled robot collaborative manufacturing system with human-in-the-loop,2022,http://dx.doi.org/10.1016/j.rcim.2022.102321,"The teleoperation and coordination of multiple industrial robots play an important role in today's industrial internet-based collaborative manufacturing systems. The user-friendly teleoperation approach allows operators from different manufacturing domains to reduce redundant learning costs and intuitively control the robot in advance. Nevertheless, only a few preliminary works have been introduced very recently, let alone its effective implementation in the manufacturing scenarios. To address the gap, this research proposes a novel multi-robot collaborative manufacturing system with human-in-the-loop control by leveraging the cutting edge augmented reality (AR) and digital twin (DT) techniques. In the proposed system, the DTs of industrial robots are firstly mapped to physical robots and visualize them in the AR glasses. Meanwhile, a multi-robot communication mechanism is designed and implemented, to synchronize the state of robots in the twin. Moreover, a reinforcement learning algorithm is integrated into the robot motion planning to replace the conventional kinematics-based robot movement with corresponding target positions. Finally, three interactive AR-assisted DT modes, including real-time motion control, planned motion control, and robot monitoring mode are generated, which can be readily switched by human operators. Two experimental studies are conducted on (1) a single robot with a commonly used peg-in-hole experiment, and (2) the motion planning of multi-robot collaborative tasks, respectively. From the experimental results, it can be found that the proposed system can well handle the multi-robot teleoperation tasks with high efficiency and owns great potentials to be adopted in other complicated manufacturing scenarios in the near future.",INFORMATION-TECHNOLOGY; USER ACCEPTANCE; UNIFIED THEORY; ORDER PICKING; LOGISTICS; SUPPORT; UTAUT; PERFORMANCE; INTERFACES; ADOPTION,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).",Ambas,Não,
Web of Science,"Jacob, F; Grosse, EH; Morana, S; König, CJ",Picking with a robot colleague: A systematic literature review and evaluation of technology acceptance in human-robot collaborative warehouses,2023,http://dx.doi.org/10.1016/j.cie.2023.109262,"Just-in-time delivery, shorter product life cycles, demographic changes, and the Covid-19 pandemic have driven the industrial application of collaborative robots in warehouses. These robots work alongside humans, increasing their productivity and relieving them of repetitive or strenuous tasks. However, human workers can be reluctant to collaborate with robots owing to certain fears; for example, they may be concerned about job loss, stress, expected effort, or risk to physical integrity. These concerns can negatively impact the acceptance of human --robot collaboration (HRC). As the literature on this topic is fragmented, this study analyzes HRC acceptance in warehouses based on the Unified Theory of Acceptance and Use of Technology. We identify, classify, and analyze studies examining HRC acceptance in warehouses using a systematic literature review methodology. A frame-work is established to guide the analysis of performance expectancy, effort expectancy, (perceived) occupational safety, psychosocial, and legal and privacy factors. The results indicate the importance of corporate infrastruc-ture and consideration of cognitive factors in particular. The findings of this study will support future research on HRC in warehouses and provide guidance for managers regarding HRC applicability.",TRAVELING SALESMAN PROBLEM; PROGRAMMING FORMULATION; OPTIMIZATION; SYSTEMS,Não,Não,Igual,EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 Met: Study is a review, survey, or meta-analysis.",Ambas,Não,
Web of Science,"Tutam, M; De Koster, R",To walk or not to walk? Designing intelligent order picking warehouses with collaborative robots,2024,http://dx.doi.org/10.1016/j.tre.2024.103696,"Order picking is a physically demanding, time-consuming, and costly process in most warehouses. To make the process more efficient, recently, ride-on autonomous robotic order pick trucks (collaborative robots or cobots) have been introduced, that assist the order picker. The order picker can ride on the cobot to travel large distances, but when picking, the cobot behaves as a robot and moves autonomously to the next stop location. The question is where the order picker should get on the cobot (step-on location) to ride further. Using traditional low-level order pick trucks, the order picker rides to every stop location and steps on the truck every time immediately after depositing the picked item on the pick pallet or roll cage. Although riding the truck may be faster than walking, stepping off/on the truck is time-consuming and also demanding for order pickers as it puts much pressure on the knee joints. The cobots allow reducing both travel time (compared to walking only) and knee flexion (compared to riding only). We determine the benefits of choosing optimal step-on locations by formulating an optimization model to minimize total time, including a penalty on the number of knee flexes of the order picker. Since the problem is computationally intractable for large-sized problems, we propose a dynamic programming approach which finds the shortest path of subproblems in each aisle. We find that the optimal collaboration strategy will decrease total travel time, as well as knee flexion of the order picker. Based on Monte Carlo simulation, our results indicate time savings up to 27.9% for one-block and 26.5% for two-block warehouses compared to a heuristic from practice. Based on the data and working practice we obtained from a retail warehouse, the optimal collaboration strategy can improve current practice between 14.5% and 24.1%.",TRUST,Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract. ; EC3 potentially met: Abstract mentions simulation without evidence of real-world application or validated prototype.","IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges.",Ambas,Não,
Web of Science,"Pietrantoni, L; Favilla, M; Fraboni, F; Mazzoni, E; Morandini, S; Benvenuti, M; De Angelis, M","Integrating collaborative robots in manufacturing, logistics, and agriculture: Expert perspectives on technical, safety, and human factors",2024,http://dx.doi.org/10.3389/frobt.2024.1342130,"This study investigates the implementation of collaborative robots across three distinct industrial sectors: vehicle assembly, warehouse logistics, and agricultural operations. Through the SESTOSENSO project, an EU-funded initiative, we examined expert perspectives on human-robot collaboration using a mixed-methods approach. Data were collected from 31 technical experts across nine European countries through an online questionnaire combining qualitative assessments of specific use cases and quantitative measures of attitudes, trust, and safety perceptions. Expert opinions across the use cases emphasized three primary concerns: technical impacts of cobot adoption, social and ethical considerations, and safety issues in design and deployment. In vehicle assembly, experts stressed the importance of effective collaboration between cobots and exoskeletons to predict and prevent collisions. For logistics, they highlighted the need for adaptable systems capable of handling various object sizes while maintaining worker safety. In agricultural settings, experts emphasized the importance of developing inherently safe applications that can operate effectively on uneven terrain while reducing workers' physical strain. Results reveal sector-specific challenges and opportunities: vehicle assembly operations require sophisticated sensor systems for cobot-exoskeleton integration; warehouse logistics demand advanced control systems for large object handling; and agricultural applications need robust navigation systems for uneven terrain. Quantitative findings indicate generally positive attitudes toward cobots, particularly regarding societal benefits, moderate to high levels of trust in cobot capabilities and favorable safety perceptions. The study highlights three key implications: (1) the need for comprehensive safety protocols tailored to each sector's unique requirements, (2) the importance of user-friendly interfaces and intuitive programming methods for successful cobot integration, and (3) the necessity of addressing workforce transition and skill development concerns. These findings contribute to our understanding of human-robot collaboration in industrial settings and provide practical guidance for organizations implementing collaborative robotics while considering both technological advancement and human-centered design principles.",ROBOT MANIPULATOR; SYSTEM,Não,Não,Igual,EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges.",Ambas,Não,
Web of Science,"Chicaiza, FA; Slawiñski, E; Mut, V",Delayed Bilateral Teleoperation of Mobile Manipulators With Hybrid Mapping: Rate/Nonlinear-Position Modes,2024,http://dx.doi.org/10.1109/OJIES.2024.3419422,"Mobile manipulators find versatile applications across various fields, leveraging the combination of autonomous functionalities and bilateral teleoperation schemes to enhance the effectiveness of these robotic mechanisms. Regarding teleoperation, command generation involves a leader robot with a few degrees of freedom in a bounded workspace, accompanied by a redundant follower robot operating in an unbounded workspace. This article introduces the concept of Cartesian/articular control for delayed bilateral teleoperation of a mobile manipulator, where the follower robot aims to execute the rate/nonlinear-position commands issued by a human handling the leader robot through a proposed hybrid mapping. We implement a P+d controller applied in Cartesian space for the leader while a controller based on inverse kinematics in joint space is employed for the follower, taking advantage of its redundancy. We then propose a Lyapunov-Krasovskii candidate function to analyze theoretically and numerically the time derivative of the functional on the system trajectories. As a result, we derive the conditions that the proposed hybrid mapping and controller parameters must satisfy to ensure bounded errors. Finally, we statistically evaluated objective metrics from multiple pick-and-place task executions considering time delays to quantify the performance achieved.",TIME-DELAY; INTERFACE; ASSISTANCE; SYMPTOMS; SYSTEM; TASKS,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 Met: Focus on an excluded sector (e.g., domestic, military) without application to target sectors.; IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).",Ambas,Não,
Web of Science,"Kim, S; Hernandez, I; Nussbaum, MA; Lim, S","Teleoperator-Robot-Human Interaction in Manufacturing: Perspectives from Industry, Robot Manufacturers, and Researchers",2024,http://dx.doi.org/10.1080/24725838.2024.2310301,"Industrial robots have become an important aspect in modern industry. In the context of human-robot collaboration, enabling teleoperated robots to work in close proximity to local/onsite humans can provide new opportunities to improve human engagement in a distributed workplace. Interviews with industry stakeholders highlighted several potential benefits of such teleoperator-robot-human collaboration (tRHC), including the application of tRHC to tasks requiring both expertise and manual dexterity (e.g., maintenance and highly skilled tasks in sectors including construction, manufacturing, and healthcare), as well as opportunities to expand job accessibility for individuals with disabilities and older individuals. However, interviewees also indicated potential challenges of tRHC, particularly related to human perception (e.g., perceiving remote environments), safety, and trust. Given these challenges, and the current limited information on the practical value and implementation of tRHC, we propose several future research directions, with a focus on human factors and ergonomics, to help realize the potential benefits of tRHC. BackgroundThe increasing prevalence of robots in industrial environments is attributed in part to advancements in collaborative robot technologies, enabling robots to work in close proximity to humans. Simultaneously, the rise of teleoperation, involving remote robot control, poses unique opportunities and challenges for human-robot collaboration (HRC) in diverse and distributed workspaces.PurposeThere is not yet a comprehensive understanding of HRC in teleoperation, specifically focusing on collaborations involving the teleoperator, the robot, and the local or onsite workers in industrial settings, here referred to as teleoperator-robot-human collaboration (tRHC). We aimed to identify opportunities, challenges, and potential applications of tRHC through insights provided from industry stakeholders, thereby supporting effective future industrial implementations.MethodsThirteen stakeholders in robotics, specializing in different domains (i.e., safety, robot manufacturing, aerospace/automotive manufacturing, and supply chains), completed semi-structured interviews that focused on exploring diverse aspects relevant to tRHC. The interviews were then transcribed and thematic analysis was applied to group responses into broader categories, which were further compared across stakeholder industries.ResultsWe identified three main categories and 13 themes from the interviews. These categories include Benefits, Concerns, and Technical Challenges. Interviewees highlighted accessibility, ergonomics, flexibility, safety, time & cost saving, and trust as benefits of tRHC. Concerns raised encompassed safety, standards, trust, and workplace optimization. Technical challenges consisted of critical issues such as communication time delays, the need for high dexterity in robot manipulators, the importance of establishing shared situational awareness among all agents, and the potential of augmented and virtual reality in providing immersive control interfaces.ConclusionsDespite important challenges, tRHC could offer unique benefits, facilitating seamless collaboration among the teleoperator, teleoperated robot(s), and onsite workers across physical and geographic boundaries. To realize such benefits and address the challenges, we propose several research directions to further explore and develop tRHC capabilities.",,Não,Não,Igual,EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges.",Ambas,Não,
Web of Science,"Su, ZF; Yao, HC; Peng, JW; Liao, ZL; Wang, ZW; Yu, H; Dai, HD; Lueth, TC",LQR-based control strategy for improving human-robot companionship and natural obstacle avoidance,2024,http://dx.doi.org/10.1016/j.birob.2024.100185,"In the dynamic and unstructured environment of human-robot symbiosis, companion robots require natural human-robot interaction and autonomous intelligence through multimodal information fusion to achieve effective collaboration. Nevertheless, the control precision and coordination of the accompanying actions are not satisfactory in practical applications. This is primarily attributed to the difficulties in the motion coordination between the accompanying target and the mobile robot. This paper proposes a companion control strategy based on the Linear Quadratic Regulator (LQR) to enhance the coordination and precision of robot companion tasks. This method enables the robot to adapt to sudden changes in the companion target's motion. Besides, the robot could smoothly avoid obstacles during the companion process. Firstly, a human-robot companion interaction model based on nonholonomic constraints is developed to determine the relative position and orientation between the robot and the companion target. Then, an LQR-based companion controller incorporating behavioral dynamics is introduced to simultaneously avoid obstacles and track the companion target's direction and velocity. Finally, various simulations and real-world human-robot companion experiments are conducted to regulate the relative position, orientation, and velocity between the target object and the robot platform. Experimental results demonstrate the superiority of this approach over conventional control algorithms in terms of control distance and directional errors throughout system operation. The proposed LQR-based control strategy ensures coordinated and consistent motion with target persons in social companion scenarios. (c) 2024 The Author(s). Published by Elsevier B.V. on behalf of Shandong University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",DISTANCE,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).",Ambas,Não,
Web of Science,"Forlini, M; Neri, F; Ciccarelli, M; Palmieri, G; Callegari, M",Experimental implementation of skeleton tracking for collision avoidance in collaborative robotics,2024,http://dx.doi.org/10.1007/s00170-024-14104-7,"Collaborative robotic manipulators can stop in case of a collision, according to the ISO/TS 15066 and ISO 10218-1 standards. However, in a human-robot collaboration scenario where the robot and the human share the workspace, a better solution with concerns to production and operator safety would be to perceive in advance the presence of an obstacle and be able to avoid it, thereby completing the task without halting the robot. In this paper, an obstacle avoidance algorithm is tested using a sensor system for real-time human detection; the operator represents a potential dynamic obstacle that can interfere with the robot motion. The sensor system consists of three RGB-D cameras. A custom software framework has been developed in Python exploiting machine learning tools for human skeleton detection. The coordinates of the human body joints relative to the manipulator base are used as input to the obstacle avoidance algorithm. The use of multiple sensors makes it possible to limit the occlusion problem; in addition, the choice of non-wearable sensors goes in the direction of better operator comfort. A series of experimental tests were performed to verify the accuracy of skeleton detection and the ability of the system to avoid obstacles in real time. The human motion caption system, in particular, was validated through a comparison with a commercial system based on wearable IMU sensors widely used and validated in motion capture. There is an NRMSE of 3.23%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$3.23\%$$\end{document} for the RGB-D camera-based skeleton detection system, against an NRMSE of 12.23%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$12.23\%$$\end{document} for the IMU wearable sensor system. Test results confirm that the system is able to avoid collisions with the human body under various conditions, static or dynamic, ensuring a minimum safety distance to any part of the manipulator. In 44 tests in which the operator moves around the robot with possible collisions (at a speed typical of manufacturing operations), the minimum operator-robot distance averaged 208mm\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$208\,\textrm{mm}$$\end{document}, being 200mm\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$200\,\textrm{mm}$$\end{document} the limit safety distance set by algorithm.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges.",Ambas,Não,
Web of Science,"Wei, K; Ren, BY",A Method on Dynamic Path Planning for Robotic Manipulator Autonomous Obstacle Avoidance Based on an Improved RRT Algorithm,2018,http://dx.doi.org/10.3390/s18020571,"In a future intelligent factory, a robotic manipulator must work efficiently and safely in a Human-Robot collaborative and dynamic unstructured environment. Autonomous path planning is the most important issue which must be resolved first in the process of improving robotic manipulator intelligence. Among the path-planning methods, the Rapidly Exploring Random Tree (RRT) algorithm based on random sampling has been widely applied in dynamic path planning for a high-dimensional robotic manipulator, especially in a complex environment because of its probability completeness, perfect expansion, and fast exploring speed over other planning methods. However, the existing RRT algorithm has a limitation in path planning for a robotic manipulator in a dynamic unstructured environment. Therefore, an autonomous obstacle avoidance dynamic path-planning method for a robotic manipulator based on an improved RRT algorithm, called Smoothly RRT (S-RRT), is proposed. This method that targets a directional node extends and can increase the sampling speed and efficiency of RRT dramatically. A path optimization strategy based on the maximum curvature constraint is presented to generate a smooth and curved continuous executable path for a robotic manipulator. Finally, the correctness, effectiveness, and practicability of the proposed method are demonstrated and validated via a MATLAB static simulation and a Robot Operating System (ROS) dynamic simulation environment as well as a real autonomous obstacle avoidance experiment in a dynamic unstructured environment for a robotic manipulator. The proposed method not only provides great practical engineering significance for a robotic manipulator's obstacle avoidance in an intelligent factory, but also theoretical reference value for other type of robots' path planning.",PHYSICALLY PRESENT,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).; IC5 Not Met: Publication year (2018) is outside the 2020-2025 range.",Ambas,Não,
Web of Science,"Crivelli, D; Balconi, M","Industrial Collaborative Robotics, Humanoid Cobots, and Social Embodiment: A Critical Look on Human-Robot Interaction",2025,http://dx.doi.org/10.1142/S0219843624300010,"Collaborative robotics combines human and robot capabilities in shared workspaces, integrating robotics, human-computer interaction, ergonomics, and psychology. In industrial settings, human-robot collaboration typically involves physical interaction with collaborative robots (cobots), designed to assist in tasks such as manufacturing and logistics. However, we discuss that cognitive and social-affective layers of interaction are equally crucial for enhancing collaboration. By adopting the 4E-cognition framework, we argue that the concept of social embodiment, widely used in virtual agents and service robotics, could contribute to the design and implementation of industrial cobots. While socially relevant functions are often secondary to operational efficiency, integrating them into cobot design could enhance interaction quality, trust, and overall task performance. Focusing on cobots' social presence and their ability to engage in proactive interactions can improve their acceptance and facilitate a sense of shared intentionality and agency in human operators. Finally, we discuss the ethical and practical challenges of developing socially embodied humanoid cobots, addressing the balance between cobot autonomy and human control, adaptive learning in long-term interaction and personalization, and the implications of building trust and transparency in human-robot collaboration. A more holistic design approach could yield both operational benefits and improved human well-being in collaborative environments.",MULTIPLE MOBILE MANIPULATORS; LEADER-FOLLOWING CONSENSUS; LINEAR MULTIAGENT SYSTEMS; EULER-LAGRANGE SYSTEMS; CONNECTIVITY PRESERVATION; ADAPTIVE-CONTROL; UNCERTAIN KINEMATICS; COMMUNICATION DELAYS; COOPERATIVE CONTROL; DISTRIBUTED CONTROL,Não,Sim,Diferente,EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,Strong alignment with all inclusion criteria,,Sim,
Web of Science,"Feng, Z; Hu, GQ; Sun, YJ; Soon, J",An overview of collaborative robotic manipulation in multi-robot systems,2020,http://dx.doi.org/10.1016/j.arcontrol.2020.02.002,"Robotic manipulation aims at combining the versatility and flexibility of mobile robot platforms with manipulation capabilities of robot manipulators. This survey paper comprehensively reviews the state-of-the-art development of collaborative robotic manipulation from the perspective of modelling, control and optimization. Then, the recent results in this field can be categorized into coordination of multiple fixed manipulators, mobile robots and mobile manipulators, respectively. A classification and comparison of various issues and promising approaches is given. Finally, a short discussion section is given to summarize existing research and to point out several future research directions. (C) 2020 Elsevier Ltd. All rights reserved.",ONTOLOGY; MANIPULATION; EXPLORATION; MAPS,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 Met: Study is a review, survey, or meta-analysis.; IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).; IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges.",Ambas,Não,
Web of Science,"Bernardo, R; Sousa, JMC; Gonçalves, PJS",A novel framework to improve motion planning of robotic systems through semantic knowledge-based reasoning,2023,http://dx.doi.org/10.1016/j.cie.2023.109345,"The need to improve motion planning techniques for manipulator robots, and new effective strategies to manipulate different objects to perform more complex tasks, is crucial for various real-world applications where robots cooperate with humans. This paper proposes a novel framework that aims to improve the motion planning of a robotic agent (a manipulator robot) through semantic knowledge-based reasoning. The Semantic Web Rule Language (SWRL) was used to infer new knowledge based on the known environment and the robotic system. Ontological knowledge, e.g., semantic maps, were generated through a deep neural network, trained to detect and classify objects in the environment where the robotic agent performs. Manipulation constraints were deduced, and the environment corresponding to the agent's manipulation workspace was created so the planner could interpret it to generate a collision-free path. For reasoning with the ontology, different SPARQL queries were used. The proposed framework was implemented and validated in a real experimental setup, using the planning framework ROSPlan to perform the planning tasks. The proposed framework proved to be a promising strategy to improve motion planning of robotics systems, showing the benefits of artificial intelligence, for knowledge representation and reasoning in robotics.",STORAGE; VEHICLES; DESIGN; MODEL,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 Met: Focus on an excluded sector (e.g., domestic, military) without application to target sectors.; IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).; IC2 Not Met: Study does not provide data on applications, impacts, HRI, technologies, or challenges.",Ambas,Não,
Web of Science,"Yang, P; Song, SS; Huang, L; Gong, YM; Shen, ZJM",Deploying pickers and robots in cobot-based collaborative order picking systems,2025,http://dx.doi.org/10.1080/24725854.2025.2501036,"As a promising application of cobots in labor-intensive warehouses, human-robot collaborative order picking systems provide a flexible and human-friendly picking solution by capitalizing on the best attributes of human pickers and robots. Few studies have determined operation modes of human-robot collaborative order picking systems to be beneficial to efficiency, cost, and the well-being of human workers. We identify four human-robot collaborative modes for order picking: single robot to single picker (couple), single robot to multiple pickers (SR-to-MP), single picker to multiple robots (SP-to-MR), and multiple pickers to multiple robots. For each mode, we establish a fork-join queuing network (FJQN) model to analyze system performance and apply a fatigue-recovery model to estimate the fatigue of the pickers. The proposed FJQN and fatigue-recovery model are validated by simulation. Although the throughput time and picker fatigue in the SR-to-MP mode can benefit from an appropriate zoning policy, we find, interestingly, that the zoning policy cannot reduce the throughput time in the SP-to-MR mode. The SP-to-MR mode is economical if a warehouse does not pursue a swift throughput time. A well-capitalized warehouse can adopt the SR-to-MP mode to improve the throughput time further in a more human-friendly manner.",,Sim,Sim,Igual,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.",Strong alignment with all inclusion criteria.,Ambas,Sim,
Web of Science,"Gao, HB; Chevallereau, C; Caro, S",Enhancing Safety in Collaborative Cable-Driven Parallel Robots: Contact Distinction and Management for Carrying Tasks,2025,http://dx.doi.org/10.1109/TASE.2025.3589966,"Cable-Driven Parallel Robots (CDPRs) have shown significant potential in industrial applications due to their large workspace, high payload capacity, and flexibility. Nonetheless, ensuring safe and efficient human-robot collaboration, particularly during carrying tasks, remains an open problem. This paper primarily contributes a cable tension-based metric for detecting contact events, combined with a frequency-domain analysis of estimated external wrenches to distinguish different contact scenarios. Building upon this framework, three common contact scenarios are then addressed: (i) payload placement and removal without rigid attachment to the moving-platform (SC1), (ii) unintentional human-cable collisions (SC2), and (iii) human-platform collisions (SC3). Specific management strategies are then proposed, including real-time mass estimation for payload handling, cable tension release for human-cable collisions, and a compliant trajectory controller for human-platform collisions. Experimental validations on a CDPR prototype demonstrate accurate scenario classification and safe contact handling without compromising overall productivity. By facilitating safer interactions, improved adaptability, and reliable handling of diverse contact events, this work expands the applicability of collaborative CDPRs in real-world industrial and logistic settings. Note to Practitioners-In many industrial applications, robots operating alongside human workers must quickly detect and respond to contact events to maintain safety and efficiency. Traditional methods often rely on force thresholds, which can introduce delays or false alarms, especially in dynamic tasks where rapid collisions must be addressed. Our work proposes an alternative approach that utilizes a frequency-domain analysis of sensed cable tensions and a weight-score system to robustly distinguish among various contact scenarios. By examining tension signals in the frequency domain, more nuanced information can be extracted, enabling faster and more accurate responses than threshold-based methods. From a practical standpoint, this technique is relatively straightforward to implement with various sensors, and it can be adapted to robots composed of different materials and link configurations by tuning the weight-score system for each new setup. Its primary benefit is improved contact distinction with high precision, which can enhance operator safety and reduce downtime without requiring extensive hardware modifications. However, like any sensor-driven control method, performance depends on adequate calibration and consistent signal quality. Future research might focus on integrating additional sensing modalities (e.g., vision or proximity sensors) and exploring broader deployment in diverse collaborative robot systems.",NEURAL-NETWORKS,Não,Não,Igual,EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 Met: Focus on an excluded sector (e.g., domestic, military) without application to target sectors.; IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).",Ambas,Não,
Web of Science,"Bae, H; Kim, G; Kim, J; Qian, DW; Lee, S",Multi-Robot Path Planning Method Using Reinforcement Learning,2019,http://dx.doi.org/10.3390/app9153057,"This paper proposes a noble multi-robot path planning algorithm using Deep q learning combined with CNN (Convolution Neural Network) algorithm. In conventional path planning algorithms, robots need to search a comparatively wide area for navigation and move in a predesigned formation under a given environment. Each robot in the multi-robot system is inherently required to navigate independently with collaborating with other robots for efficient performance. In addition, the robot collaboration scheme is highly depends on the conditions of each robot, such as its position and velocity. However, the conventional method does not actively cope with variable situations since each robot has difficulty to recognize the moving robot around it as an obstacle or a cooperative robot. To compensate for these shortcomings, we apply Deep q learning to strengthen the learning algorithm combined with CNN algorithm, which is needed to analyze the situation efficiently. CNN analyzes the exact situation using image information on its environment and the robot navigates based on the situation analyzed through Deep q learning. The simulation results using the proposed algorithm shows the flexible and efficient movement of the robots comparing with conventional methods under various environments.",DESIGN; MOTION; FORCE,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC3 potentially met: Abstract mentions simulation without evidence of real-world application or validated prototype.,"IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).; IC5 Not Met: Publication year (2019) is outside the 2020-2025 range.",Ambas,Não,
Web of Science,"Urrea, C; Sari, P; Kern, J; Torres, H",Enhancing Adaptability and Autonomy in Cooperative Selective Compliance Assembly Robot Arm Robots: Implementation of Coordination and Rapidly Exploring Random Tree Algorithms for Safe and Efficient Manipulation Tasks,2024,http://dx.doi.org/10.3390/app14156804,"In this study, a cooperative robotic system comprising two Selective Compliance Assembly Robot Arm (SCARA) robots was developed and simulated. An algorithm was proposed for the coordination of robots in cooperative tasks, along with a Rapidly exploring Random Tree (RRT) path planner for obstacle avoidance. The proposed system proved effective in transferring objects between robots and in handling various scenarios of variable complexity without collisions. The implementation of advanced trajectory planning and coordination algorithms significantly improves the adaptability and autonomy of robotic systems, allowing robots to predict and react to the movements of their counterparts and changes in the environment in real time. This capability is crucial for maintaining a safe and efficient work environment. The importance of synchronization and effective communication between robots is highlighted to avoid collisions and optimize trajectories and cycle times. All tests were conducted in virtual environments, allowing for the evaluation and refinement of the performance of the robots' performance under controlled conditions. The positive results obtained in the simulations suggest that the system is well suited for future practical implementation in industrial and manufacturing applications, such as chemical handling, collaborative welding, quality inspection, among others. These findings underscore the potential of the cooperative SCARA system to improve the efficiency and safety in industrial applications using advanced algorithms and control techniques, establishing a solid foundation for future research and development in the field of cooperative robotics.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related manufacturing/assembly).",Ambas,Não,
Web of Science,"Cai, XN",Mechanical Structure Design of Wearable Assistive Robot Driven by ADAMS System,2024,http://dx.doi.org/10.1109/ACCESS.2024.3472116,"Currently wearable assistive robot has been widely researched and applied in many fields. Aiming at the problems of difficult and time-consuming handling of goods, a wearable assistive robot using automatic dynamic analysis of mechanical systems is designed. The robot is assisted by robot operating system. The robot uses robot operating system to assist the automatic dynamic analysis of mechanical systems system, and the mechanical structure of the robot is analyzed and designed. Then the robot structure is simulated and analyzed by the software to explore the practical application of the robot. The results of the study indicated that the height of the robot's air drive affected the effectiveness of the robot's application. The angle of the robot could reach 36.2 degrees at 0mm height, 53.6 degrees at 50mm and 66.7 degrees at 100mm. At the same time, the maximum force of the robot's stand could reach 191.5N. The amount of robot's assisting force varied in different handling goods. The actual force applied by the robot varied in different arm positions. However, the actual structural design of the robot is in line with the actual application effect. It can be concluded that the robot designed by the system conforms to the actual application structure and can realize the actual booster assistance effect. This is a good guide for the assistive control and structure analysis of the assistive robot.",TRACKING,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Met: Title/abstract do not clearly indicate multifunctional/collaborative robots in the target sectors (logistics, healthcare, field services, or related",Ambas,Não,
Web of Science,"Zakaria, WZEW; Ramli, A; Misro, MY; Wahab, MNA",Motion Planning of Differential Drive Mobile Robot Using Circular Arc,2024,,"In modern applications, mobile robots are important dynamic systems. Motion planning is a crucial responsibility for these robots as it enables them to move from one place to another safely and efficiently. Extensive research has been conducted on motion planning for static scenarios. However, research is limited when the scenarios are dynamic because it is difficult and expensive to continuously replan the robot's moves to ensure its safety. This paper presents the circular arc path algorithm for sensorless differential drive mobile robot movement, given that the initial point and endpoint are defined. The differential drive mobile robot, which is adopted for various vehicles and robots, is very popular due to its simple operation and robustness. A mobile robot with two driving wheels that uses a differential drive splits its overall velocity between its left and right wheels. Accordingly, the radius of the circle that forms after movement between two points is the main factor that determines the left and right velocity of the robot's wheels. Through this algorithm, all points will be interpolated with G1 continuity, which only requires an initial direction to move. Robot simulation is performed using CoppeliaSim, and the algorithm is developed using Remote API functions in Matlab.",STRESS; CLASSIFICATION; COLLABORATION; STRATEGIES; BEHAVIOR; EMOTION; DISPLAY; FUTURE; SCOPUS; INDEX,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC3 potentially met: Abstract mentions simulation without evidence of real-world application or validated prototype.,"IC1 não satisfeito: O título/resumo não indicam claramente um setor alvo (logística, saúde, serviços de campo).",Ambas,Não,
Web of Science,"Gervasi, R; Barravecchia, F; Mastrogiacomo, L; Franceschini, F",Applications of affective computing in human-robot interaction: State-of-art and challenges for manufacturing,2023,http://dx.doi.org/10.1177/09544054221121888,"The introduction of collaborative robots aims to make production more flexible, promoting a greater interaction between humans and robots also from physical point of view. However, working closely with a robot may lead to the creation of stressful situations for the operator, which can negatively affect task performance. In Human-Robot Interaction (HRI), robots are expected to be socially intelligent, that is, capable of understanding and reacting accordingly to human social and affective clues. This ability can be exploited implementing affective computing, which concerns the development of systems able to recognize, interpret, process, and simulate human affects. Social intelligence is essential for robots to establish a natural interaction with people in several contexts, including the manufacturing sector with the emergence of Industry 5.0. In order to take full advantage of the human-robot collaboration, the robotic system should be able to perceive the psycho-emotional and mental state of the operator through different sensing modalities (e.g. facial expressions, body language, voice, or physiological signals) and to adapt its behavior accordingly. The development of socially intelligent collaborative robots in the manufacturing sector can lead to a symbiotic human-robot collaboration, arising several research challenges that still need to be addressed. The goals of this paper are the following: (i) providing an overview of affective computing implementation in HRI; (ii) analyzing the state-of-art on this topic in different application contexts (e.g. healthcare, service applications, and manufacturing); (iii) highlighting research challenges for the manufacturing sector.",AVOIDANCE; DISTANCE; COLLABORATION; OBJECTS,Sim,Sim,Igual,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.","Forte alinhamento com todos os critérios de inclusão. O estudo parece discutir robôs colaborativos/multifuncionais em um setor alvo e foca em aplicações práticas, design, avaliação ou desafios de implementação.",Ambas,Sim,
Web of Science,"Secil, S; Ozkan, M",A collision-free path planning method for industrial robot manipulators considering safe human-robot interaction,2023,http://dx.doi.org/10.1007/s11370-023-00465-7,"This paper introduces a new method to solve the collision-free path planning problem for industrial robots considering safe human-robot coexistence. The aim is to keep the robot at a safe distance away from the human and let the robot's tip reach the target location through a smooth path. The proposed method is iterative, and each iteration provides random candidate waypoints for the robot's tip. The waypoint that the robot will follow for each iteration is determined by solving the optimization problem. The objective function is formulated considering the distance between the human and the robot, as well as the criteria for the robot's tip to reach the target by following a smooth path. The human and the robot in the environment are represented by the capsules, and the minimum distance calculation is performed between these capsules using the Gilbert-Johnson-Keerthi algorithm. The simulation results demonstrate the performance of the proposed method for different scenarios involving human-robot coexistence.",ENVIRONMENTS; TRUST; BEHAVIOR; EMOTION,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 não satisfeito: O título/resumo não indicam claramente um setor alvo (logística, saúde, serviços de campo).",Ambas,Não,
Web of Science,"Badia, SBI; Silva, PA; Branco, D; Pinto, A; Carvalho, C; Menezes, P; Almeida, J; Pilacinski, A",Virtual Reality for Safe Testing and Development in Collaborative Robotics: Challenges and Perspectives,2022,http://dx.doi.org/10.3390/electronics11111726,"Collaborative robots (cobots) could help humans in tasks that are mundane, dangerous or where direct human contact carries risk. Yet, the collaboration between humans and robots is severely limited by the aspects of the safety and comfort of human operators. In this paper, we outline the use of extended reality (XR) as a way to test and develop collaboration with robots. We focus on virtual reality (VR) in simulating collaboration scenarios and the use of cobot digital twins. This is specifically useful in situations that are difficult or even impossible to safely test in real life, such as dangerous scenarios. We describe using XR simulations as a means to evaluate collaboration with robots without putting humans at harm. We show how an XR setting enables combining human behavioral data, subjective self-reports, and biosignals signifying human comfort, stress and cognitive load during collaboration. Several works demonstrate XR can be used to train human operators and provide them with augmented reality (AR) interfaces to enhance their performance with robots. We also provide a first attempt at what could become the basis for a human-robot collaboration testing framework, specifically for designing and testing factors affecting human-robot collaboration. The use of XR has the potential to change the way we design and test cobots, and train cobot operators, in a range of applications: from industry, through healthcare, to space operations.",SAFETY,Não,Sim,Diferente,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract. ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC3 potentially met: Abstract mentions simulation without evidence of real-world application or validated prototype.","Forte alinhamento com todos os critérios de inclusão. O estudo parece discutir robôs colaborativos/multifuncionais em um setor alvo e foca em aplicações práticas, design, avaliação ou desafios de implementação.",,Sim,
Web of Science,"Saenz, J; Bessler-Etten, J; Valori, M; Prange-Lasonder, GB; Fassi, I; Bidard, C; Lassen, AB; Paniti, I; Toth, A; Stuke, T; Wrede, S; Nielsen, K",An Online Toolkit for Applications Featuring Collaborative Robots Across Different Domains,2023,http://dx.doi.org/10.1109/THMS.2022.3213416,"Collaborative robots (cobots) are being applied in areas such as healthcare, rehabilitation, agriculture and logistics, beyond the typical manufacturing setting. This is leading to a marked increase in the number of cobot stakeholders with little or no experience in traditional safety engineering. Considering the importance of human safety in collaborative robotic applications, this is currently proving to be a barrier to more widespread cobot usage. A web-based Toolkit that targets cobot end-users and manufacturers with varying levels of safety expertise was developed, helping them to understand how to consider the safety of their cobot applications. In this work, we will provide an overview of the state of the art for ensuring cobot safety, highlight the support provided by the COVR Toolkit and introduce three examples where third parties applied the Toolkit for their collaborative robotics application.",,Não,Sim,Diferente,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.","Forte alinhamento com todos os critérios de inclusão. O estudo parece discutir robôs colaborativos/multifuncionais em um setor alvo e foca em aplicações práticas, design, avaliação ou desafios de implementação.",,Sim,
Web of Science,"Zhang, H; Sheng, Q; Hu, JW; Sheng, XJ; Xiong, ZH; Zhu, XY",Cooperative Transportation With Mobile Manipulator: A Capability Map-Based Framework for Physical Human-Robot Collaboration,2022,http://dx.doi.org/10.1109/TMECH.2022.3155601,"In the cooperative transportation task with a mobile manipulator (MM), the mobile robot and the manipulator must move simultaneously to adapt to the human motion. In addition, the motion of the MM is underconstrained due to redundancy, which makes MM real-time motion planning challenging. In this article, a capability map-based framework was proposed to enable real-time motion planning of the MM. In the motion planner, the dexterity of the MM, the formation of the human-robot system, and obstacle avoidance of the mobile robot are considered to get safe and human-like robot motion. Moreover, to make optimization faster and avoid local minimum, capability map, which represents the manipulability distribution of the MM in its workspace, is queried to determine the seed of the optimization algorithm. The proposed motion planner is self-contained and can be extended to the transportation task with multiple MMs. The effectiveness of this proposed framework is validated both in simulations and real-world experiments.",ROBUST,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 atendido: O foco parece ser exclusivamente em um setor excluído (por exemplo, militar, espacial, doméstico).",Ambas,Não,
Web of Science,"Wang, WT; Li, R; Diekel, ZM; Chen, Y; Zhang, ZJ; Jia, YY",Controlling Object Hand-Over in Human-Robot Collaboration Via Natural Wearable Sensing,2019,http://dx.doi.org/10.1109/THMS.2018.2883176,"With the deployment of collaborative robots in intelligent manufacturing, object hand-over between humans and robots plays a significant role in human-robot collaborations. In most collaboration studies, human hand-over intentions were usually assumed to be known by the robot, and the research mainly focused on robot motion planning and control during the hand-over process. Several approaches have been developed to control the human-robot hand-over, such as vision-based approach and physical contact-based approach, but their applications in manufacturing environments are limited due to various constraints, such as limited human working ranges and safety concerns. In this paper, we develop a practical approach using a wearable sensory system, which has a natural and simple configuration and can be easily utilized by humans. This approach could make a robot recognize a human's hand-over intentions and enable the human to effectively and naturally control the hand-over process. In addition, the approach could recognize the attribute classes of the objects in the human's hand using the wearable sensing and enable the robot to actively make decisions to ensure that graspable objects are handed over from the human to the robot. Results and evaluations illustrate the effectiveness and advantages of the proposed approach in human-robot hand-over control.",MOVING TARGET; CONVEYOR; ALGORITHM; TRACKING; DESIGN; GRASP,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC5 não satisfeito: O ano de publicação é 2019, fora do intervalo de 2020–2025.",Ambas,Não,
Web of Science,"Yang, MM; Yang, ER",Two-stage multi-sensor fusion positioning system with seamless switching for cooperative mobile robot and manipulator system,2023,http://dx.doi.org/10.1007/s41315-023-00276-0,"The stoppage of a mobile platform is generally scheduled to feed parts for machines on production lines, such as fenced industrial robotic manipulators. A non-stop mobile robotic part feeding system can contribute to production efficiency and flexibility but contains several challenging tasks. For example, the industrial robotic manipulator needs to perceive the positions of the mobile robot accurately and robustly before grasping the supplies when the mobile robot moves around. Thus, based on the relative distance between the two robots, an interaction mode of the integrated robotic system consisting of a fixed robotic manipulator and a mobile robot is developed for robotic interaction. In order to accurately and robustly perceive the positions of a mobile robot, two different positioning approaches for the robotic manipulator positioning mobile robot in an indoor environment are utilised. One approach is ultrasonic sensors fused with inertia measurement units (IMU) by extended Kalman filter (EKF). Furthermore, an outlier rejection mechanism is implemented to escape outliers from ultrasonic measurement. Another positioning approach is achieved by detecting an ArUco marker with visual sensor. Lastly, a positioning switching strategy according to the visual sensor state allows the robotic manipulator to reposition the mobile robot seamlessly. According to the static experiments, EKF-based positioning approach fusing IMU with ultrasonic sensor can export high-accuracy (the root mean square error is 0.04 m) and high-precision (the standard deviation is 0.0033 m) in positioning while keeping a high update frequency of 181.9 HZ in static positioning. Evaluations through dynamic experiments demonstrate that the proposed positioning system can suppress the positioning drifts over time in comparison with wheel encoder-based positioning method. The two-stage repositioning strategy can support the robotic manipulator to identify the positions of the mobile robot robustly, even in the case when the visual sensor is occluded.",LOGISTICS; AUTONOMY; SUPPORT; TIME,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 não satisfeito: O título/resumo não indicam claramente um setor alvo (logística, saúde, serviços de campo).",Ambas,Não,
Web of Science,"Koreis, J; Loske, D; Klumpp, M","Together, we travel: empirical insights on human-robot collaborative order picking for retail warehousing",2025,http://dx.doi.org/10.1108/IJLM-03-2023-0127,"PurposeIncreasing personnel costs and labour shortages have pushed retailers to give increasing attention to their intralogistics operations. We study hybrid order picking systems, in which humans and robots share work time, workspace and objectives and are in permanent contact. This necessitates a collaboration of humans and their mechanical coworkers (cobots).Design/methodology/approachThrough a longitudinal case study on individual-level technology adaption, we accompanied a pilot testing of an industrial truck that automatically follows order pickers in their travel direction. Grounded on empirical field research and a unique large-scale data set comprising N = 2,086,260 storage location visits, where N = 57,239 storage location visits were performed in a hybrid setting and N = 2,029,021 in a manual setting, we applied a multilevel model to estimate the impact of this cobot settings on task performance.FindingsWe show that cobot settings can reduce the time required for picking tasks by as much as 33.57%. Furthermore, practical factors such as product weight, pick density and travel distance mitigate this effect, suggesting that cobots are especially beneficial for short-distance orders.Originality/valueGiven that the literature on hybrid order picking systems has primarily applied simulation approaches, the study is among the first to provide empirical evidence from a real-world setting. The results are discussed from the perspective of Industry 5.0 and can prevent managers from making investment decisions into ineffective robotic technology.",ROBOT; SYSTEM; MANIPULATION; ALGORITHM; DESIGN; TASKS,Não,Sim,Diferente,EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"Forte alinhamento com todos os critérios de inclusão. O estudo parece discutir robôs colaborativos/multifuncionais em um setor alvo e foca em aplicações práticas, design, avaliação ou desafios de implementação.",,Sim,
Web of Science,"Marvel, JA; Bostelman, R; Falco, J",Multi-Robot Assembly Strategies and Metrics,2018,http://dx.doi.org/10.1145/3150225,"We present a survey of multi-robot assembly applications and methods and describe trends and general insights into the multi-robot assembly problem for industrial applications. We focus on fixtureless assembly strategies featuring two or more robotic systems. Such robotic systems include industrial robot arms, dexterous robotic hands, and autonomous mobile platforms, such as automated guided vehicles. In this survey, we identify the types of assemblies that are enabled by utilizing multiple robots, the algorithms that synchronize the motions of the robots to complete the assembly operations, and the metrics used to assess the quality and performance of the assemblies.",OBJECT; FRICTION,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 atendido: A publicação parece ser uma revisão, survey ou outro tipo excluído.",Ambas,Não,
Web of Science,"Costanzo, M; De Maria, G; Natale, C",Handover Control for Human-Robot and Robot-Robot Collaboration,2021,http://dx.doi.org/10.3389/frobt.2021.672995,"Modern scenarios in robotics involve human-robot collaboration or robot-robot cooperation in unstructured environments. In human-robot collaboration, the objective is to relieve humans from repetitive and wearing tasks. This is the case of a retail store, where the robot could help a clerk to refill a shelf or an elderly customer to pick an item from an uncomfortable location. In robot-robot cooperation, automated logistics scenarios, such as warehouses, distribution centers and supermarkets, often require repetitive and sequential pick and place tasks that can be executed more efficiently by exchanging objects between robots, provided that they are endowed with object handover ability. Use of a robot for passing objects is justified only if the handover operation is sufficiently intuitive for the involved humans, fluid and natural, with a speed comparable to that typical of a human-human object exchange. The approach proposed in this paper strongly relies on visual and haptic perception combined with suitable algorithms for controlling both robot motion, to allow the robot to adapt to human behavior, and grip force, to ensure a safe handover. The control strategy combines model-based reactive control methods with an event-driven state machine encoding a human-inspired behavior during a handover task, which involves both linear and torsional loads, without requiring explicit learning from human demonstration. Experiments in a supermarket-like environment with humans and robots communicating only through haptic cues demonstrate the relevance of force/tactile feedback in accomplishing handover operations in a collaborative task.",MOTION; OPTIMIZATION,Sim,Não,Diferente,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.","EC3 atendido: Parece ser um estudo puramente teórico ou baseado em simulação sem aplicação prática, protótipo ou validação nos setores alvo.",,Sim,
Web of Science,"Zhang, LX; Meng, XJ; Ding, ZJ; Wang, TS",Two Stage Path Planning Method for Co-Worked Double Industrial Robots,2023,http://dx.doi.org/10.1109/ACCESS.2023.3332310,"It is a significant capability for multi-industrial robots to plan an optimal collision-free path for both end-effectors and robotic arms. However, the path planning methods for co-worked multi-industrial robots, especially for closely co-worked industrial robots is still very limited. In this paper, to tackle the planning problem that has a specified distance constraint of end-effector in the context of complex collision avoidance, a two stage path planning method is proposed for the co-worked double industrial robot. In this two stage path planning method, the dual path planning with the distance constraint and the joint space planning of double robots are integrated sequentially. For the first stage, an algorithm named random sampling particle swarm optimization (RSPSO) is developed to plan the path for each end-effector, which can plan an optimal collision-free path with the specified distance constraint. For the second stage, the joint space planning that combines the inverse kinematics, D-H method and collision detection is performed to find the angular displacements with collision avoidance for dual robotic arms. Two simulation examples and an experiment are used to verify the proposed method.",RRT,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"EC2 atendido: O foco parece ser exclusivamente em um setor excluído (por exemplo, militar, espacial, doméstico).",Ambas,Não,
Web of Science,"Wong, CC; Chen, CJ; Wong, KY; Feng, HM",Implementation of a Real-Time Object Pick-and-Place System Based on a Changing Strategy for Rapidly-Exploring Random Tree,2023,http://dx.doi.org/10.3390/s23104814,"An object pick-and-place system with a camera, a six-degree-of-freedom (DOF) robot manipulator, and a two-finger gripper is implemented based on the robot operating system (ROS) in this paper. A collision-free path planning method is one of the most fundamental problems that has to be solved before the robot manipulator can autonomously pick-and-place objects in complex environments. In the implementation of the real-time pick-and-place system, the success rate and computing time of path planning by a six-DOF robot manipulator are two essential key factors. Therefore, an improved rapidly-exploring random tree (RRT) algorithm, named changing strategy RRT (CS-RRT), is proposed. Based on the method of gradually changing the sampling area based on RRT (CSA-RRT), two mechanisms are used in the proposed CS-RRT to improve the success rate and computing time. The proposed CS-RRT algorithm adopts a sampling-radius limitation mechanism, which enables the random tree to approach the goal area more efficiently each time the environment is explored. It can avoid spending a lot of time looking for valid points when it is close to the goal point, thus reducing the computing time of the improved RRT algorithm. In addition, the CS-RRT algorithm adopts a node counting mechanism, which enables the algorithm to switch to an appropriate sampling method in complex environments. It can avoid the search path being trapped in some constrained areas due to excessive exploration in the direction of the goal point, thus improving the adaptability of the proposed algorithm to various environments and increasing the success rate. Finally, an environment with four object pick-and-place tasks is established, and four simulation results are given to illustrate that the proposed CS-RRT-based collision-free path planning method has the best performance compared with the other two RRT algorithms. A practical experiment is also provided to verify that the robot manipulator can indeed complete the specified four object pick-and-place tasks successfully and effectively.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 não satisfeito: O título/resumo não indicam claramente um setor alvo (logística, saúde, serviços de campo).",Ambas,Não,
Web of Science,"Brogårdh, T",Present and future robot control development -: An industrial perspective,2007,http://dx.doi.org/10.1016/j.arcontrol.2007.01.002,"Robot control is a key competence for robot manufacturers and a lot of development is made to increase robot performance, reduce robot cost and introduce new functionalities. Examples of development areas that get big attention today are multi robot control, safe control, force control, 3D vision, remote robot supervision and wireless communication. The application benefits from these developments are discussed as well as the technical challenges that the robot manufacturers meet. Model-based control is now a key technology for the control of industrial robots and models and control schemes are continuously refined to meet the requirements on higher performance even when the cost pressure leads to the design of robot mechanics that is more difficult to control. Driving forces for the future development of robots can be found in, for example, new robot applications in the automotive industry, especially for the final assembly, in small and medium size enterprises, in foundries, in food industry and in the processing and assembly of large structures. Some scenarios on future robot control development are proposed. One scenario is that lightweight robot concepts could have an impact on future car manufacturing and on future automation of small and medium size enterprises (SMEs). Such a development could result in modular robots and in control schemes using sensors in the robot arm structure, sensors that could also be used for the implementation of redundant safe control. Introducing highly modular robots will increase the need of robot installation support, making Plug and Play functionality even more important. One possibility to obtain a highly modular robot program could be to use a recently developed new type of parallel kinematic robot structure with large work space in relation to the robot foot print. For further efficient use of robots, the scenario of adaptive robot performance is introduced. This means that the robot control is optimised with respect to the thermal and fatigue load on the robot for the specific program that the robot performs. The main conclusion of the presentation is that industrial robot development is far away from its limits and that a lot of research and development is needed to obtain a more widely use of robot automation in industry. (c) 2007 Elsevier Ltd. All rights reserved.",FRAMEWORK,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC5 não satisfeito: O ano de publicação é 2007, fora do intervalo de 2020–2025.",Ambas,Não,
Web of Science,"Atzeni, G; Vignali, G; Tebaldi, L; Bottani, E",A bibliometric analysis on collaborative robots in Logistics 4.0 environments,2021,http://dx.doi.org/10.1016/j.procs.2021.01.291,"Logistics activities were included in the wave of changes brought with the advent of the fourth industrial revolution. Several applications can be recognized for several activities, aiming all at efficiently optimizing processes and consequently production and volumes. Among them, collaborative robots involved for instance in picking, palletizing or assembly operations are quickly spreading, as also demonstrated by the increase in the number of publications available in literature. In response, this paper presents the results of a bibliometric analysis carried out on 64 scientific papers which deal with this topic within the logistics field. Analysis were made through two different software applications, namely Microsoft Excel (TM) and VOSviewer. Results are quite optimistic as they delineate great opportunities for collaborative robots to establish their position in the industrial context. (C) 2021 The Authors. Published by Elsevier B.V.",HAND,Não,Sim,Diferente,EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"Forte alinhamento com todos os critérios de inclusão. O estudo parece discutir robôs colaborativos/multifuncionais em um setor alvo e foca em aplicações práticas, design, avaliação ou desafios de implementação.",,Sim,
Web of Science,"Ribeiro, T; Gonçalves, F; Garcia, IS; Lopes, G; Ribeiro, AF",CHARMIE: A Collaborative Healthcare and Home Service and Assistant Robot for Elderly Care,2021,http://dx.doi.org/10.3390/app11167248,"The global population is ageing at an unprecedented rate. With changes in life expectancy across the world, three major issues arise: an increasing proportion of senior citizens; cognitive and physical problems progressively affecting the elderly; and a growing number of single-person households. The available data proves the ever-increasing necessity for efficient elderly care solutions such as healthcare service and assistive robots. Additionally, such robotic solutions provide safe healthcare assistance in public health emergencies such as the SARS-CoV-2 virus (COVID-19). CHARMIE is an anthropomorphic collaborative healthcare and domestic assistant robot capable of performing generic service tasks in non-standardised healthcare and domestic environment settings. The combination of its hardware and software solutions demonstrates map building and self-localisation, safe navigation through dynamic obstacle detection and avoidance, different human-robot interaction systems, speech and hearing, pose/gesture estimation and household object manipulation. Moreover, CHARMIE performs end-to-end chores in nursing homes, domestic houses, and healthcare facilities. Some examples of these chores are to help users transport items, fall detection, tidying up rooms, user following, and set up a table. The robot can perform a wide range of chores, either independently or collaboratively. CHARMIE provides a generic robotic solution such that older people can live longer, more independent, and healthier lives.",,Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract. ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).","IC2 não satisfeito: O estudo não fornece dados claros sobre aplicações práticas, impactos, análise de HRI, tecnologias habilitadoras ou desafios de implementação.",Ambas,Não,
Web of Science,"Chen, ZX; Yuan, XZ; Cu, Q; Hu, CX; He, DX",A Digital Twin System for 6DoF Robot Grasping,2023,http://dx.doi.org/10.1109/CCDC58219.2023.10327020,"Driven by Industry 4.0 and smart logistics, robot technology has entered a stage of rapid development. Robots are increasingly applied in factories. In this paper, we propose a digital twin system for robot grasping. A 6DoF industrial robot is used as the execution module of object grasping in the physical world, and a simulated grasping environment is built in the virtual world as same as the physical world. After the path planning and collision detection in the virtual world, the trajectory data of the robot is sent to the physical world with a specific data structure. The experimental results show that the parameter error of the end effector between the physical twin and the virtual twin is less than 5mm, which verifies that the system proposed in this paper has good real-time performance.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,IC1 não satisfeito: O título/resumo não indicam claramente robôs multifuncionais ou colaborativos (cobots) ou HRI.,Ambas,Não,
Web of Science,"Abdi, A; Park, JH",A Hybrid AI-Based Adaptive Path Planning for Intelligent Robot Arms,2023,http://dx.doi.org/10.1109/ACCESS.2023.3338566,"Intelligent robot arms are advanced robotic systems used in Industry 4.0 to perform complex tasks. Unlike conventional robot arms, which perform predefined tasks, intelligent robot arms have autonomy and can operate in changing environments, interact with other machines, and collaborate with humans. In this regard, adaptive path planning is crucial for intelligent robot arms, involving real-time environment monitoring and path generation to continuously update the robot's trajectory based on changes in the surroundings. This paper presents an adaptive path planning method for intelligent robot arms to be used in dynamic environments. The proposed method is based on a hybrid active-passive approach and has been tested in a dynamic workspace simulation environment. The results indicate the ability of the proposed method to respond dynamically in a complex scenario where the target is fluctuating, and an obstacle is intentionally placed in the robot's path. Additionally, real-time analysis results show that the method can be categorized as real-time path planning with less than 100 ms reaction time for grid sizes with less than 96 x 96 x 96 cells. This insight presents opportunities for the establishment of smart factories, smart homes, and smart cities, where the presence of intelligent robot arms in dynamic environments becomes essential.",INTEGRATION,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC3 potentially met: Abstract mentions simulation without evidence of real-world application or validated prototype.,"EC2 atendido: O foco parece ser exclusivamente em um setor excluído (por exemplo, militar, espacial, doméstico).",Ambas,Não,
Web of Science,"Engemann, H; Du, SZ; Kallweit, S; Cönen, P; Dawar, H",OMNIVIL-An Autonomous Mobile Manipulator for Flexible Production,2020,http://dx.doi.org/10.3390/s20247249,"Flexible production is a key element in modern industrial manufacturing. Autonomous mobile manipulators can be used to execute various tasks: from logistics, to pick and place, or handling. Therefore, autonomous robotic systems can even increase the flexibility of existing production environments. However, the application of robotic systems is challenging due to their complexity and safety concerns. This paper addresses the design and implementation of the autonomous mobile manipulator OMNIVIL. A holonomic kinematic design provides high maneuverability and the implemented sensor setup with the underlying localization strategies are robust against typical static and dynamic uncertainties in industrial environments. For a safe and efficient human-robot collaboration (HRC), a novel workspace monitoring system (WMS) is developed to detect human co-workers and other objects in the workspace. The multilayer sensor setup and the parallel data analyzing capability provide superior accuracy and reliability. An intuitive zone-based navigation concept is implemented, based on the workspace monitoring system. Preventive behaviors are predefined for a conflict-free interaction with human co-workers. A workspace analyzing tool is implemented for adaptive manipulation, which significantly simplifies the determination of suitable platform positions for a manipulation task.",ROBOT MANIPULATORS; IMPEDANCE CONTROL; SAFETY,Não,Sim,Diferente,EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"Forte alinhamento com todos os critérios de inclusão. O estudo parece discutir robôs colaborativos/multifuncionais em um setor alvo e foca em aplicações práticas, design, avaliação ou desafios de implementação.",,Sim,
Web of Science,"Su, H; Ovur, SE; Li, ZJ; Hu, YB; Li, JH; Knoll, A; Ferrigno, G; De Momi, E",Internet of Things (IoT)-based Collaborative Control of a Redundant Manipulator for Teleoperated Minimally Invasive Surgeries,2020,http://dx.doi.org/10.1109/icra40945.2020.9197321,"In this paper, an Internet of Things-based human-robot collaborative control scheme is developed in Robot-assisted Minimally Invasive Surgery scenario. A hierarchical operational space formulation is designed to exploit the redundancies of the 7-DoFs redundant manipulator to handle multiple operational tasks based on their priority levels, such as guaranteeing a remote center of motion constraint and avoiding collision with a swivel motion without influencing the undergoing surgical operation. Furthermore, the concept of the Internet of Robotic Things is exploited to facilitate the best action of the robot in human-robot interaction. Instead of utilizing compliant swivel motion, HTC VIVE PRO controllers, used as the Internet of Things technology, is adopted to detect the collision. A virtual force is applied to the robot elbow, enabling a smooth swivel motion for human-robot interaction. The effectiveness of the proposed strategy is validated using experiments performed on a patient phantom in a lab setup environment, with a KUKA LWR4 + slave robot and a SIGMA 7 master manipulator. By comparison with previous works, the results show improved performances in terms of the accuracy of the RCM constraint and surgical tip.",4.0 MATURITY MODELS; PERCEIVED SAFETY; INDUSTRY; MANAGEMENT; LOGISTICS; FRAMEWORK; AWARENESS; DESIGN; TOOL,Não,Não,Igual,EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 atendido: O foco parece ser exclusivamente em um setor excluído (por exemplo, militar, espacial, doméstico).",Ambas,Não,
Web of Science,"Berx, N; Adriaensen, A; Decré, W; Pintelon, L",Assessing System-Wide Safety Readiness for Successful Human-Robot Collaboration Adoption,2022,http://dx.doi.org/10.3390/safety8030048,"Despite their undisputed potential, the uptake of collaborative robots remains below expectations. Collaborative robots (cobots) are used differently from conventional industrial robots. The current safety focus of collaborative workspaces is predominantly on the technological design; additional factors also need to be considered to cope with the emerging risks associated with complex systems. Cobot technologies are characterized by an inherent tradeoff between safety and efficiency. They introduce new, emergent risks to organizations and can create psychosocial impacts on workers. This leads to a confusing body of information and an apparent contradiction about cobot safety. Combined with a lack of safety knowledge, this impedes the introduction of cobots. A multi-step methodology was used, including a literature review and conceptual modeling. This article argues for the need for a system-wide safety awareness readiness assessment in the consideration phase of cobot implementation to alleviate the knowledge deficit and confusion. This work will benefit both researchers and practitioners. In addition, it defends the appropriateness of a maturity grid model for a readiness assessment tool. The building blocks for an easy-to-use and practically applicable tool are proposed, as well as an agenda for the next steps.",MODEL-PREDICTIVE CONTROL; OBSTACLE AVOIDANCE; ALGORITHM; OPTIMIZATION; DISTANCE; ROADMAPS,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.). ; EC4 met: Article appears to be a review/survey/meta-analysis (excluded).,"EC4 atendido: A publicação parece ser uma revisão, survey ou outro tipo excluído.",Ambas,Não,
Web of Science,"Gafur, N; Kanagalingam, G; Wagner, A; Ruskowski, M",Dynamic Collision and Deadlock Avoidance for Multiple Robotic Manipulators,2022,http://dx.doi.org/10.1109/ACCESS.2022.3176626,"A flexible operation of multiple robotic manipulators operating in a dynamic environment requires online trajectory planning to ensure collision-free trajectories. In this work, we propose a real-time capable motion control algorithm, based on nonlinear model predictive control, which accounts for static and dynamic obstacles. The proposed algorithm is realized in a distributed scheme, where each robot optimizes its own trajectory with respect to the related objective and constraints. We propose a novel approach for collision avoidance between multiple robotic manipulators, where each robot accounts for the predicted movement of the neighboring robots. Additionally, we propose a method to reliably detect and resolve deadlocks occurring in a setup of multiple robotic manipulators. We validate our approach on pick and place scenarios involving multiple robotic manipulators operating in a common workspace in a realistic simulation environment set up in Gazebo. The robots are controlled using the Robot Operating System. Our approach scales up to 4 manipulators and computes a path for each robot in a simultaneous pick and place operation in 94% of all investigated cases without deadlock detection and 100 % of cases with the proposed deadlock resolution algorithm. In contrast, the investigated conventional path planners, such as PRM, PRM*, CHOMP and RRT-Connect, successfully plan a trajectory in at most 54% of all investigated cases for a simultaneous operation of 4 robotic manipulators hindering their application in setups of multiple manipulators.",COLLISION-FREE NAVIGATION; WIRELESS SENSOR; PATH; TRACKING; GUIDANCE; VEHICLE; SEARCH,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC3 potentially met: Abstract mentions simulation without evidence of real-world application or validated prototype.,"EC2 atendido: O foco parece ser exclusivamente em um setor excluído (por exemplo, militar, espacial, doméstico).",Ambas,Não,
Web of Science,"Li, H; Savkin, AV",An algorithm for safe navigation of mobile robots by a sensor network in dynamic cluttered industrial environments,2018,http://dx.doi.org/10.1016/j.rcim.2018.05.008,"Mobile robots have been widely implemented in industrial automation and smart factories. Different types of mobile robots work cooperatively in the workspace to complete some complicated tasks. Therefore, the main requirement for multi-robot systems is collision-free navigation in dynamic environments. In this paper, we propose a sensor network based navigation system for ground mobile robots in dynamic industrial cluttered environments. A range finder sensor network is deployed on factory floor to detect any obstacles in the field of view and perform a global navigation for any robots simultaneously travelling in the factory. The obstacle detection and robot navigation are integrated into the sensor network and the robot is only required for a low-level path tracker. The novelty of this paper is to propose a sensor network based navigation system with a novel artificial potential field (APF) based navigation algorithm. Computer simulations and experiments confirm the performance of the proposed method.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC5 não satisfeito: O ano de publicação é 2018, fora do intervalo de 2020–2025.",Ambas,Não,
Web of Science,"Kang, Y; Kim, D; Yun, DW",Manipulator Collision Avoidance System Based on a 3D Potential Field With ISO 15066,2022,http://dx.doi.org/10.1109/ACCESS.2022.3221182,"Recently, various intelligent technological innovations are being applied to smart factories. As manipulators are widely used in smart factories, the manipulator and the workspace of humans overlap, and interest in cooperative robots and human safety has increased. In relation to this, a collision-avoidance control algorithm applicable in three dimensions (3D) and that also meets existing safety standards for humans and robots is required. In this paper, we propose a 3D potential field-based manipulator collision avoidance algorithm that meets the requirements of the ISO 15066 standard. This algorithm applies Speed and Separation Monitoring(SSM) according to the distance between the manipulator and the obstacle and controls the speed of the manipulator slowly as the risk is higher. This allows us to overcome the limitations that existing studies have not been conducted on 3D potential field-based obstacle avoidance and that it is difficult to apply to the field without considering ISO 15066. The proposed system was verified through simulation and experiments, and through comparison with the existing algorithm, we verified that SSM was well applied to the proposed system.",COST FUNCTION,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 atendido: O foco parece ser exclusivamente em um setor excluído (por exemplo, militar, espacial, doméstico).",Ambas,Não,
Web of Science,"Wang, WT; Li, R; Diekel, ZM; Jia, YY",Robot action planning by online optimization in human-robot collaborative tasks,2018,http://dx.doi.org/10.1007/s41315-018-0054-x,"Collaborative robots are widely used in strict and complex hybrid assembly tasks in the context of intelligent manufacturing. However, the task efficiency and task cost evaluation, which are very significant in the robot action planning to ensure and enhance the task quality in the human-robot collaboration process, are rarely studied in previous works. In this paper, we propose a novel and practical approach based on online optimization for the robot to plan its actions in human-robot collaboration to address this challenge. First, we extract the task model by graphical representations and design the collaboration cost functions which incorporate time consumption and human efforts. After that, the robot action planning algorithms are developed to online plan robot actions by optimizing the collaborative assembly cost. In addition, appropriate robot actions can be planned by the proposed algorithms to ensure the accomplishment of assembly process when the human happens to conduct wrong actions during the collaboration. We performed studies through hybrid assembly tasks with different types of human-robot collaboration scenarios to verify the advantages of our robot action planning algorithms. Experimental results suggested that the proposed algorithms can successfully generate the optimal actions for the robot to guarantee the efficiency in human-robot collaborative assembly.",RECOGNITION; MANIPULATOR; INTERFACE; TRACKING; SYSTEMS,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC5 não satisfeito: O ano de publicação é 2018, fora do intervalo de 2020–2025.",Ambas,Não,
Web of Science,"Zhou, DJ; Shi, MH; Chao, F; Lin, CM; Yang, LZ; Shang, CJ; Zhou, CL",Use of human gestures for controlling a mobile robot via adaptive CMAC network and fuzzy logic controller,2018,http://dx.doi.org/10.1016/j.neucom.2017.12.016,"Mobile robots with manipulators have been more and more commonly applied in extreme and hostile environments to assist or even replace human operators for complex tasks. In addition to autonomous abilities, mobile robots need to facilitate the human-robot interaction control mode that enables human users to easily control or collaborate with robots. This paper proposes a system which uses human gestures to control an autonomous mobile robot integrating a manipulator and a video surveillance platform. A human user can control the mobile robot just as one drives an actual vehicle in the vehicle's driving cab. The proposed system obtains human's skeleton joints information using a motion sensing input device, which is then recognized and interpreted into a set of control commands. This is implemented, based on the availability of training data set and requirement of in-time performance, by an adaptive cerebellar model articulation controller neural network, a finite state machine, a fuzzy controller and purposely designed gesture recognition and control command generation systems. These algorithms work together implement the steering and velocity control of the mobile robot in real-time. The experimental results demonstrate that the proposed approach is able to conveniently control a mobile robot using virtual driving method, with smooth manoeuvring trajectories in various speeds. (C) 2017 Elsevier B.V. All rights reserved.",,Não,Não,Igual,IC5 not satisfied: Could not find a publication year between 2020 and 2025 in the record.,"IC5 não satisfeito: O ano de publicação é 2018, fora do intervalo de 2020–2025.",Ambas,Não,
Web of Science,"Ha, QP; La, HM; Wang, S; Balaguer, C",Special issue on recent advances in field and service robotics: handling harsh environments and cooperation,2023,http://dx.doi.org/10.1017/S0263574722000510,This Special Issue of the Robotica is on recent advances in field and service robotics with a focus on the use of robotic and autonomous technologies to handle tasks in harsh environments and tasks that involve the multirobot cooperation and human-robot interactions.,,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 não satisfeito: O título/resumo não indicam claramente um setor alvo (logística, saúde, serviços de campo).",Ambas,Não,
Web of Science,"Ding, IJ; Juang, YC",Hand-gesture-control-based Navigation Using Wearable Armband with Surface Electromyography and Inertial Measurement Unit Sensor Data for Autonomous Guided Vehicles with Robot Operation System-based Simultaneous Localization and Mapping Navigation in Smart Manufacturing,2022,http://dx.doi.org/10.18494/SAM4045,"Autonomous guided vehicles (AGVs) with a robot operation system (ROS)-based platform have been widely used in automation-assisted manufacturing. AGV robots in smart manufacturing are mainly used to handle materials. Such AGV robots with an ROS are generally capable of simultaneous localization and mapping (SLAM) and can therefore perform autonomous navigation (the well-known ROS-based SLAM navigation). From the viewpoint of smart manufacturing, which is expected to have richer artificial intelligence and human-robot interaction (HRI), an AGV robot with only ROS-based SLAM autonomous navigation is extremely restricted in functions and human-robot interactions. In this work, to increase HRIs and the flexibility of usage of AGVs with only ROS-based SLAM autonomous navigation, a hand-gesture-control-based navigation approach using a wearable armband with sensor data from both surface electromyography (SEMG) and an inertial measurement unit (IMU) is presented. The developed hand-gesture-control-based navigation with artificial neural network (ANN) hand gesture command recognition can be incorporated into a typical AGV operation with SLAM autonomous navigation. The hand-gesture-control-based navigation for AGVs proposed in this study mainly consists of two calculation phases: the detection of the significant hand gesture for the corresponding gesture operation command by the analysis of eight-axis SEMG data, and the recognition of hand gesture commands from the operator using an ANN with nine-axis IMU data. To appropriately combine the detection and recognition of hand gestures, two strategies were developed for the navigation control of an AGV in a certain continuous time period: ANN recognition by the IMU in a fixed decision window with an SEMG system wake-up, and ANN recognition by the IMU in a variable decision window with both a system wake-up and end. A series of online test experiments on AGV navigation by hand gesture control demonstrated that the presented approach has a competitive performance, particularly for short-path navigation.",SOURCE LOCALIZATION,Sim,Não,Diferente,"Meets all inclusion criteria: discusses collaborative/multifunction robots in target sector(s), includes practical evaluation/deployment info, peer-reviewed conference/journal, English, and published between 2020–2025.","IC1 não satisfeito: O título/resumo não indicam claramente um setor alvo (logística, saúde, serviços de campo).",,Sim,
Web of Science,"Chen, CC; Liu, Y",Research on Door-Opening Strategy Design of Mobile Manipulators Based on Visual Information and Azimuth,2022,http://dx.doi.org/10.1155/2022/6156558,"At present, the manipulator has become an important auxiliary tool in the production and processing operations, so new requirements are put forward for the control strategy of the manipulator. In production, because traditional manipulators can only perform tasks according to the set procedures and cannot fully realize the intelligence and collaboration of control, how to improve the operating efficiency of manipulators has become an urgent problem to be solved. The autonomous door-opening control of robots is a challenging research topic in the field of automation. In the robot movement, target recognition and positioning and the coordinated control of manipulators and mobile platforms are difficult points in the research of autonomous door-opening control. Through the research on autonomous door-opening control, the robot has a broader working space, which greatly improves the robot's ability to serve humans and has important theoretical value and practical significance.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 atendido: O foco parece ser exclusivamente em um setor excluído (por exemplo, militar, espacial, doméstico).",Ambas,Não,
Web of Science,"Scimmi, LS; Melchiorre, M; Mauro, S; Pastorelli, SP",Implementing a vision-based collision avoidance algorithm on a UR3 Robot,2019,http://dx.doi.org/10.1109/icmect.2019.8932105,"Collaborative robotics implies the possibility for robots and humans to cooperate to perform a common task. A fundamental element to make collaboration possible is to ensure the safety of the human operators. In this paper a collision avoidance algorithm designed for a robotic redundant task is presented. This algorithm permits the robot to avoid collisions with obstacles (e.g. human operators) and in the same time to achieve the planned task when possible. The algorithm was tested with a UR3 robot of Universal Robots company, considering only tool centre point (TCP) position in order to obtain kinematic redundancy. The robot is controlled by an external PC that communicates with the controller of the robot via Ethernet network. The communication and control algorithms are written in the Matlab environment. The PC-UR communication functions permit to send joint velocities commands from the PC to the controller of the robot and feedback data from the UR to the PC. Control functions estimate the distances between an obstacle (whose position was acquired by a system of motion capture) and the robot and calculate the needed joints velocities to avoid any collision. The functions developed in Matlab will be explained in detail. Results of the experimental tests conducted to verify the effectiveness of the collision avoidance system are reported.",LOAD-CARRYING CAPACITY; DYNAMIC INTERACTION; TRACKING CONTROL; ENVIRONMENT; ROBOT; KINEMATICS,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC5 não satisfeito: O ano de publicação é 2019, fora do intervalo de 2020–2025.",Ambas,Não,
Web of Science,"Deepak, BBVL; Parhi, DR",Control of an automated mobile manipulator using artificial immune system,2016,http://dx.doi.org/10.1080/0952813X.2015.1132261,"This paper addresses the coordination and control of a wheeled mobile manipulator (WMM) using artificial immune system. The aim of the developed methodology is to navigate the system autonomously and transport jobs and tools in manufacturing environments. This study integrates the kinematic structures of a four-axis manipulator and a differential wheeled mobile platform. The motion of the developed WMM is controlled by the complete system of parametric equation in terms of joint velocities and makes the robot to follow desired trajectories by the manipulator and platform within its workspace. The developed robot system performs its action intelligently according to the sensed environmental criteria within its search space. To verify the effectiveness of the proposed immune-based motion planner for WMM, simulations as well as experimental results are presented in various unknown environments.",PEDESTRIAN DETECTION,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC5 não satisfeito: O ano de publicação é 2016, fora do intervalo de 2020–2025.",Ambas,Não,
Web of Science,"Terreran, M; Lamon, E; Michieletto, S; Pagello, E",Low-cost Scalable People Tracking System for Human-Robot Collaboration in Industrial Environment,2020,http://dx.doi.org/10.1016/j.promfg.2020.10.018,"Human-robot collaboration is one of the key elements in the Industry 4.0 revolution, aiming to a close and direct collaboration between robots and human workers to reach higher productivity and improved ergonomics. The first step toward such kind of collaboration in the industrial context is the removal of physical safety barriers usually surrounding standard robotic cells, so that human workers can approach and directly collaborate with robots. Anyway, human safety must be granted avoiding possible collisions with the robot. In this work, we propose the use of a people tracking algorithm to monitor people moving around a robot manipulator and recognize when a person is too close to the robot while performing a task. The system is implemented by a camera network system positioned around the robot workspace, and thoroughly evaluated in different industry-like settings in terms of both tracking accuracy and detection delay. (C) 2020 The Authors. Published by Elsevier Ltd.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"EC2 atendido: O foco parece ser exclusivamente em um setor excluído (por exemplo, militar, espacial, doméstico).",Ambas,Não,
Web of Science,"Jeon, S; Lee, J; Kim, J",Multi-Robot Task Allocation for Real-Time Hospital Logistics,2017,,"Autonomous mobile robots have been deployed at hospitals to cope with numerous delivery services. Robots deliver items from point to point through autonomous navigation. Conventional robots work individually conducting only one task at a time. This paper proposes a fleet optimization method to maximize the advantages of operating a group of robots concurrently by assigning multiple tasks to a robot. The server selects an appropriate robot for a delivery task based on the cost for conducting the delivery task of each robot. The robot with the minimum cost is assigned for the new delivery task. This way, a robot is assigned to conduct multiple tasks. The scheduler finds the minimum routing path for visiting multiple delivery locations. The shortest path for visiting multiple delivery locations is derived from a combinatorial search approach. This paper proposes an algorithm that reduces the computational burden for finding the path combinations. Because this procedure takes a short amount of time, the allocation of a robot can be conducted in real-time. The proposed algorithm is tested in the simulation, and the results show that it increases the efficiency when using multiple robots. In addition, by running the simulation and reviewing the performance results, the management group of a hospital can determine the number of robots required at their site.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"EC4 atendido: A publicação parece ser uma revisão, survey ou outro tipo excluído.",Ambas,Não,
Web of Science,"Darvish, K; Bruno, B; Simetti, E; Mastrogiovanni, F; Casalino, G","Interleaved Online Task Planning, Simulation, Task Allocation and Motion Control for Flexible Human-Robot Cooperation",2018,,"Modern manufacturing paradigms introduce the need for robots able to naturally cooperate with humans in an unstructured and dynamic environment. In this article we extend FlexHRC, an architecture for flexible and collaborative manufacturing robots, with an online perception-simulation-planning framework that allows the robot to assess the status of the workspace, keeping track at all times of the stage at which the cooperative manufacturing process is, to identify its next action, to simulate it to check its feasibility and, as a consequence, to dynamically allocate tasks to itself or the human operator. We have tested the FlexHRC with a dual-arm manipulator cooperating with a person to assemble a table with one tabletop and four legs.",MANIPULATION,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC3 potentially met: Abstract mentions simulation without evidence of real-world application or validated prototype.,"IC5 não satisfeito: O ano de publicação é 2018, fora do intervalo de 2020–2025.",Ambas,Não,
Web of Science,"Akbari, A; Muhayyuddin; Rosell, J",Knowledge-oriented task and motion planning for multiple mobile robots,2019,http://dx.doi.org/10.1080/0952813X.2018.1544280,"Robotic systems composed of several mobile robots moving in human environments pose several problems at perception, planning and control levels. In these environments, there may be obstacles obstructing the paths, which robots can remove by pushing or pulling them. At planning level, therefore, an efficient combination of task and motion planning is required. Even more if we assume a cooperative system in which robots can collaborate with each other by e.g. pushing together a heavy obstacle or by one robot clearing the way to another one. In this paper, we cope with this problem by proposing -TMP, a smart combination of an heuristic task planner based on the Fast Forward method, a physics-based motion planner, and reasoning processes over the ontologies that code the knowledge on the problem. The significance of the proposal relies on how geometric and physics information is used within the computation of the heuristics in order to guide the symbolic search, i.e. how an artificial intelligence planning method is combined with low-level motion planning to achieve a feasible sequence of actions (composed of collision-free motions plus physically-feasible push/pull actions). The proposal has been validated with several simulated scenarios (using up to five robots that need to collaborate with each other to reach the goal state), showing how the method is able to solve challenging situations and also find an efficient solution in terms of power.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC5 não satisfeito: O ano de publicação é 2019, fora do intervalo de 2020–2025.",Ambas,Não,
Web of Science,"Vorotnikov, S; Ermishin, K; Nazarova, A; Yuschenko, A",Multi-agent Robotic Systems in Collaborative Robotics,2018,http://dx.doi.org/10.1007/978-3-319-99582-3_28,"This paper describes the principles of control of multi-agent robotic systems. It is a new area of robotics oriented for introduction of robotic not only into industry but into life of human. The main principles of collaborative robotics are the safety of human and easiness of robot control. The problem is how to control not a single robot but a group of robots working together. It is most important for such tasks as rescue operations, environment monitoring etc. Some approaches to solve the task of human control of a group of robots are presented in the paper.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC5 não satisfeito: O ano de publicação é 2018, fora do intervalo de 2020–2025.",Ambas,Não,
Web of Science,"Vinod, B; Bindu, B; Karan, GNK; Akash, VEJ; Kumar, SD",Design and implementation of the 6-DoF robotic manipulator using robot operating system,2021,http://dx.doi.org/10.22075/ijnaa.2021.5882,Material handling robots are replacing human workers in most of the manufacturing shop floors. Robot operating system is an open-source framework that enables visualization and implements various complex robots and their functions. A 6-DoF robotic manipulator with a gripper is designed to perform the pick and place operations. The aim is to integrate the designed robot with the robot operating system. The integrated system is then visualized and controlled using a gazebo and RViz to perform pick and place operations.,,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 não satisfeito: O título/resumo não indicam claramente um setor alvo (logística, saúde, serviços de campo).",Ambas,Não,
Web of Science,"Rothomphiwat, K; Harnkhamen, A; Tothong, T; Suthisomboon, T; Dilokthanakul, N; Manoonpong, P",Advanced Collaborative Robots for the Factory of the Future,2021,http://dx.doi.org/10.1109/IEEECONF49454.2021.9382664,"This paper presents an integrated robotic platform for advanced collaborative robots and demonstrates an application of multiple robots collaboratively transporting an object to different positions in a factory environment. The proposed platform integrates a drone, a mobile manipulator robot, and a dual-arm robot to work autonomously, while also collaborating with a human worker.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 não satisfeito: O título/resumo não indicam claramente um setor alvo (logística, saúde, serviços de campo).",Ambas,Não,
Web of Science,"Saenz, J; Fassi, I; Prange-Lasonder, GB; Valori, M; Bidard, C; Lassen, AB; Bessler-Etten, J",COVR Toolkit - Supporting safety of interactive robotics applications,2021,http://dx.doi.org/10.1109/ICHMS53169.2021.9582659,"Collaborative robots (cobots) are increasingly finding use beyond the traditional domain of manufacturing, in areas such as healthcare, rehabilitation, agriculture and logistics. This development greatly increases the size and variations in the level of expertise of cobot stakeholders. This becomes particularly critical considering the role of human safety for collaborative robotics applications. In order to support the wide range of cobot stakeholders, the EU-funded project COVR Being safe around collaborative and versatile robots in shared spaces has developed a freely available, web-based Toolkit that offers support to understand how to consider the safety of cobot applications. This paper describes the state of the art for ensuring safety across various life cycle phases in the development and implementation of collaborative robotics applications and highlights how the Toolkit provides practical support during these tasks. The Toolkit aims to be the most comprehensive resource for supporting cobot stakeholders in ensuring the safety of their applications.",AUGMENTED REALITY; AUTOMATION; OIL,Não,Sim,Diferente,EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"Forte alinhamento com todos os critérios de inclusão. O estudo parece discutir robôs colaborativos/multifuncionais em um setor alvo e foca em aplicações práticas, design, avaliação ou desafios de implementação.",,Sim,
Web of Science,"Ni, JN; Balyan, V",RESEARCH ON MOBILE USER INTERFACE FOR ROBOT ARM REMOTE CONTROL IN INDUSTRIAL APPLICATION,2021,http://dx.doi.org/10.12694/scpe.v22i2.1900,"The mobile interfaced robot arms are majorly being used nowadays in order to provide the remote-control applicability for various industrial and manufacturing applications. This article proposes a robotic arm platform for controlling the industrial application. The proposed system includes various modules like a robot arm, a controller module and a remote mobile operating application for visualizing the robot arm angles having real time applicability. Augmented reality (AR) is utilized for robot control WIFI communication and the robot angle information is obtained for varying real time environment. This novel approach incorporated the AR technology into mobile application which allow the real time virtual coordination with physical platform. The feasible trajectories are generated using the proposed methodology and a comparison is made between the desired and real trajectory paths. The simulation results are obtained for various assessment indicators and effectual outcomes are achieved with 98.03% accuracy value and 0. 185, 0.180 of error and loss values for training phase. The accuracy value of 97.65% is achieved for testing phase with corresponding 0.209 and 0.190 minimum error and loss values. The proposed platform provides the feasible and reliable outcomes in the real time environment for real time manufacturing industry applications.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots.",Ambas,Não,
Web of Science,"Lipovanu, I; Pascal, C","A rule-based enhancement of a vision guided, collision-free robotic application",2021,http://dx.doi.org/10.1109/ICSTCC52150.2021.9607077,"This paper presents a rule-based method to solve a collision issue for an industrial robot manipulator. The approach applies a set of rules over the information received from a vision system to consider an extended set of constraints for end-of-arm tooling. Collision-free, finding objects that are safe for gripping or the order of operation are based on a graph dependency mechanism. The interaction among a robot, a vision system, and the developed module is obtained through an IoT system extension. Validated on a real manufacturing system, our method can simplify and improve several robotized applications.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots.",Ambas,Não,
Web of Science,"Brogårdh, T",Robot Control Overview: An Industrial Perspective,2009,http://dx.doi.org/10.4173/mic.2009.3.7,"One key competence for robot manufacturers is robot control, defined as all the technologies needed to control the electromechanical system of an industrial robot. By means of modeling, identification, optimization, and model-based control it is possible to reduce robot cost, increase robot performance, and solve requirements from new automation concepts and new application processes. Model-based control, including kinematics error compensation, optimal servo reference-and feed-forward generation, and servo design, tuning, and scheduling, has meant a breakthrough for the use of robots in industry. Relying on this breakthrough, new automation concepts such as high performance multi robot collaboration and human robot collaboration can be introduced. Robot manufacturers can build robots with more compliant components and mechanical structures without loosing performance and robots can be used also in applications with very high performance requirements, e. g., in assembly, machining, and laser cutting. In the future it is expected that the importance of sensor control will increase, both with respect to sensors in the robot structure to increase the control performance of the robot itself and sensors outside the robot related to the applications and the automation systems. In this connection sensor fusion and learning functionalities will be needed together with the robot control for easy and intuitive installation, programming, and maintenance of industrial robots.",,Não,Não,Igual,IC5 not satisfied: Could not find a publication year between 2020 and 2025 in the record. ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2009) is outside 2020–2025.,Ambas,Não,
Web of Science,"Dewi, T; Rusdianasari; Kusumanto, RD; Siproni",Workspace and Collaboration System Design of Two Robot Manipulators,2021,,"Robots working in industries are increasingly in numbers and complexity. These robots need to be collaborated with human or another robot. Therefore, it is necessary to study and design the workspace and collaboration system of two robot manipulators to ensure minimal human intervention in accomplishing their assigned tasks. This paper presents the workspace and collaboration design of two robot manipulators. The kinematics analysis is given to show the workspace design. The safety of two robots is ensure by the application of proximity sensors which are modeled as a spring-damper system. This paper is intended to show the possibility of realizing two robot manipulators collaboration system, which is applicable in industries and agriculture environment.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Peng, JH; Li, IH; Chien, YH; Hsu, CC; Wang, WY",Multi-Robot Path Planning Based on Improved D* Lite Algorithm,2015,,"This paper proposes an improved multi-robot path planning algorithm for finding the path via interacting with multiple robots. The task is to find the path with a minimum amount of computation time by using fast re-planning algorithm. To solve multi-robot path planning problem which cannot be executed in real-time, we regard other robots, exclusive the origin robot, as obstacles. Therefore, the robot uploads location information to the MySQL server to plan a safe distance between robots.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2015) is outside 2020–2025.",Ambas,Não,
Web of Science,"Matoui, F; Boussaid, B; Metoui, B; Frej, GB; Abdelkrim, MN",Path planning of a group of robots with potential field approach: decentralized architecture,2017,http://dx.doi.org/10.1016/j.ifacol.2017.08.1822,"This paper deals with the path planning problem of a group of autonomous Wheeled Mobile Robots in a very dynamic workspace. The idea consists of considering the system of group of robots as a robot network with decentralized architecture. Each robot plans its trajectory according to its actual position, the position of the other neighbor robots, the position of the obstacles and the position of its target point. So each robot should interact with the other robots in the network to cooperate together in order to plan each robot trajectory. The path planning for every robot is planned based on the potential field approach. The network reacts with the changes of workspace in real time by updating the system equations associated for each robot. The main objective of this work is to avoid collision between robots and obstacles in order to ensure the safety of robots. The solution is tested and simulated with Matlab/Simulink and Solidworks/Simmechanics. (C) 2017, IFAC (International Federation of Automatic Control) Hosting by Elsevier Ltd. All rights reserved.",PARALLEL MANIPULATOR; SURFACE-TREATMENT; CONTROL DESIGN; FUZZY CONTROL; OPTIMIZATION; PRECISION; COMPENSATION; ALGORITHM; POSITION; SPEED,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2017) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Guo, WJ; Li, RF; Zhu, YG; Yang, T; Qin, R; Hu, ZX",A Robotic Deburring Methodology for Tool Path Planning and Process Parameter Control of a Five-Degree-of-Freedom Robot Manipulator,2019,http://dx.doi.org/10.3390/app9102033,"Industrial robotics is a continuously developing domain, as industrial robots have demonstrated to possess benefits with regard to robotic automation solutions in the industrial automation field. In this article, a new robotic deburring methodology for tool path planning and process parameter control is presented for a newly developed five-degree-of-freedom hybrid robot manipulator. A hybrid robot manipulator with dexterous manipulation and two experimental platforms of robot manipulators are presented. A robotic deburring tool path planning method is proposed for the robotic deburring tool position and orientation planning and the robotic layered deburring planning. Also, a robotic deburring process parameter control method is proposed based on fuzzy control. Furthermore, a dexterous manipulation verification experiment is conducted to demonstrate the dexterous manipulation and the orientation reachability of the robot manipulator. Additionally, two robotic deburring experiments are conducted to verify the effectiveness of the two proposed methods and demonstrate the highly efficient and dexterous manipulation and deburring capacity of the robot manipulator.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2019) is outside 2020–2025.",Ambas,Não,
Web of Science,"Aliev, K; Antonelli, D",Analysis of Cooperative Industrial Task Execution by Mobile and Manipulator Robots,2019,http://dx.doi.org/10.1007/978-3-030-18715-6_21,"The emergence of mobile robots as a flexible upgrade of industrial AGVs and the simultaneous diffusion of collaborative manipulators pose new problems for the organization of work in industrial plants. The new robots address work environments characterized by limited automation and unstructured layouts. Present study is aimed at demonstrating that, using commercially available technologies, it is possible to assure a fruitful collaborative interaction among three main actors of the factory of tomorrow: the human operator, the mobile robot and the manipulator.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2019) is outside 2020–2025.",Ambas,Não,
Web of Science,"Kuzin, S; Sziebig, G","SROS: Educational, Low-cost Autonomous Mobile Robot Design Based on ROS",2020,http://dx.doi.org/10.1109/sii46433.2020.9025974,"The paper describes the design process of a low-cost mobile robot based on the Arduino platform and powered by the Robot Operating System (ROS) to perform autonomous navigation, with a special focus on education. The paper contains an overview of the Robot Operation System structure, working principles, and application to real mobile robots. At the same time, consider the theory of Simultaneous Localization and Mapping (SLAM) and ways of its implementation in the practice. The practical part contains the description of the construction process of a differential drive mobile robot, the establishment of remote control and full integration process of Robot Operating System to the robot for self-localization, indoor mapping, and autonomous navigation purpose. The test results and performance are discussed and analysed.",DESIGN,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots.",Ambas,Não,
Web of Science,"Cao, BS; Sun, K; Gu, YK; Jin, MH; Liu, H",Humanoid Robot Torso Motion Planning Based on Manipulator Pose Dexterity Index,2020,http://dx.doi.org/10.1088/1757-899X/853/1/012040,"Humanoid robot operation task is mainly executed with arm-torso system. The torso system can effectively increase humanoid robot arm operation range and vision range of the humanoid robot, but it also increases the difficulty of the humanoid robot motion planning. Humanoid robot torso increases humanoid robot arm operation range by changing the pose of the robot arm base and it also reconstruct humanoid robot arm workspace pose dexterity. Humanoid robot torso position is optimized with manipulator pose dexterity in different humanoid robot arm sub-workspace. For different operation tasks, the indicators to be considered for the position of the torso joint include: whether the robot arm can grasp the target position, whether the specified motion trajectory can be reached, and whether it has higher dexterity in specified motion trajectory. In this paper, we consider higher manipulator pose dexterity sub-workspace is better operation position, and we introduce a scheme to optimize torso joint position.",SIMULTANEOUS LOCALIZATION,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Luo, RC; Lee, SL; Wen, YC; Hsu, CH",Modular ROS Based Autonomous Mobile Industrial Robot System for Automated Intelligent Manufacturing Applications,2020,,"The objective of this paper is to develop a modular Robot Operating System (ROS) based autonomous mobile industrial robot system for automated intelligent manufacturing applications. We propose a finite state machine based method to integrate and manage various modular functions on the mobile manipulator which makes it have a great talent on mobility and manipulation. For mobility, we perform simultaneous localization and mapping (SLAM) on our robot to build a map and locate itself. We also develop navigation and collision avoidance strategies, so that it can navigate to anywhere it plans in the indoor environment. For manipulation, we use an RGB-D camera on the end effector to perform eye-in-hand system which given an image and point cloud, leveraging the learning-based object detection and shape-based grasping pose estimation to achieve flexible manipulation capabilities. In the experiments, we have developed an Autonomous Mobile Industrial Robot (AMIR) with a carefully designed mechanism and a fully modular ROS environment in our robotics lab at NTU. In the experiments, we construct an intelligent industrial scenario: collecting materials and delivering products from one place to another. Using our ROS based architecture to control the data/command flow between functions, we have successfully completed the demonstration of the system and proved the stability of the system.",OBSTACLE AVOIDANCE; MOTION; ENVIRONMENT; NAVIGATION,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots.",Ambas,Não,
Web of Science,"Ouyang, F; Zhang, T",Virtual Velocity Vector-based Offline Collision-free Path Planning of Industrial Robotic Manipulator,2015,http://dx.doi.org/10.5772/60127,"Currently, industrial robotic manipulators are applied in many manufacturing applications. In most cases, an industrial environment is a cluttered and complex one where moving obstacles may exist and hinder the movement of robotic manipulators. Therefore, a robotic manipulator not only has to avoid moving obstacles, but also needs to fulfill the manufacturing requirements of smooth movement in fixed tact time. Thus, this paper proposes a virtual velocity vector-based algorithm of offline collisionfree path planning for manipulator arms in a controlled industrial environment. The minimum distance between a manipulator and a moving obstacle can be maintained at an expected value by utilizing our proposed algorithm with established offline collision-free path-planning and trajectory-generating systems. Furthermore, both joint space velocity and Cartesian space velocity of generated time-efficient trajectory are continuous and smooth. In addition, the vector of detour velocity in a 3D environment is determined and depicted. Simulation results indicate that detour velocity can shorten the total task time as well as escaping the local minimal effectively. In summary, our approach can fulfill both safety requirements of collision avoidance of moving obstacles and manufacturing requirements of smooth movement within fixed tact time in an industrial environment.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2015) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Ling, C; Xing, XY; Liu, LW; Zhang, L; Bai, XQ; Liu, CF",Design and Research of The Multifunctional Mobile Manipulator Based on ROS,2020,http://dx.doi.org/10.1109/AUTEEE50969.2020.9315546,"The mobile manipulator is a composite robot which has the characteristics of the mobile base and the manipulator, achieves the functions of each separate platform and completes more complex tasks. This paper proposes a multifunctional configuration of a mobile manipulator which could achieve multiple functions, including navigation and positioning, manipulator control, object pose estimation, indoor planar environment detection and object grasping. It could be widely used in the field of logistics sorting and complex assembly tasks.",,Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract. ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).","IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges.",Ambas,Não,
Web of Science,"Hernandez, W; Hilarion, A; Martinez, C",A Collaborative Vacuum Tool for Humans and Robots,2020,http://dx.doi.org/10.1007/978-3-030-40309-6_13,"This paper presents the design and implementation of a tool for Human-Robot collaborative tasks. Industry 4.0 proposes a new scenario where robots can safely work in direct cooperation with humans, within a defined workspace. These robots are called collaborative robots or COBOTS. In this paper, we propose a tool that can be used by a robot and/or an operator for pick and place tasks. The tool was designed to meet certain criteria for the robot, so that it can identify it, hold it, and perform the task. Additionally, it was designed to comply with ergonomic parameters for the human operator. A prototype of the tool was printed with a FusedForm 3D printer. This prototype was used for a test where a robot and an operator will use the tool for picking plastic bottles from a worktable. An UR3 robot was used in the test. It was equipped with a camera in charge of identifying and estimating the position of the tool using ArUco codes placed on the tool. Results show the functionality of the tool for both the robot and the human operator. Additionally, ergonomic tests provided insights to improve the handling system of the tool for the human operator.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Noh, S; Park, J",System Design for Automation in Multi-Agent-Based Manufacturing Systems,2020,http://dx.doi.org/10.23919/iccas50221.2020.9268357,"This paper proposes a system design for automation in multi-agent-based manufacturing systems to conduct a given complex task automatically by controlling multiple robotic manipulators in a systematic manner. To this end, the proposed system is designed with three-module configurations: environmental perception, task planning, and motion planning. The environmental perception module utilizes a vision sensor to recognize all objects placed on the workspace and extract their unique ID, size, and pose. The task planning module divides a given task into primitive skill levels and distributes each primitive skill to the associated robotic manipulator with the relevant object information in a systematic manner for robotic manipulators not to collide with each other. The motion planning module determines the motion of a robotic arm and a robotic hand by solving inverse kinematics for the robotic arm and by opening or closing two fingers. The proposed system has been tested and verified in real robot environments through a complex task peg in hole that requires at least two robotic manipulators.",SYSTEMS,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Diankov, R; Srinivasa, SS; Ferguson, D; Kuffner, J",Manipulation Planning with Caging Grasps,2008,,"We present a novel motion planning algorithm for performing constrained tasks such as opening doors and drawers by robots such as humanoid robots or mobile manipulators. Previous work on constrained manipulation transfers rigid constraints imposed by the target object motion directly into the robot configuration space. This often unnecessarily restricts the allowable robot motion, which can prevent the robot from performing even simple tasks, particularly if the robot has limited reachability or low number of joints. Our method computes caging grasps specific to the object and uses efficient search algorithms to produce motion plans that satisfy the task constraints. The major advantages of our technique significantly increase the range of possible motions of the robot by not having to enforce rigid constraints between the end-effector and the target object. We illustrate our approach with experimental results and examples running on two robot platforms.",ARM,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2008) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Zhao, LJ; Liu, YH; Wang, K; Liang, PD; Li, RF",An Intuitive Human Robot Interface for Tele-operation,2016,,"This paper proposed an intuitive human robot interface for real-time tele-operation, where human operator can operate the Baxter robot to implement complicated tasks in unstructured and uncertain environment intuitively and efficiently. Firstly, In this paper a new method for building an human robot interaction interface is proposed. In addition, workspace mapping between master and slave manipulator is a key problem of human robot interaction (HRI) when there are huge difference in size and structure of human and robot's manipulators. So, the workspace mapping method between human arm and Baxter Robot manipulator and the inverse kinematics approach for solving 7-DOF redundant manipulator by using Kinect sensor were also discussed in detail. In the end, an experiment was employed to validate the performance of proposed interface.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC5 Not Satisfied: Year (2016) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Apoorva; Gautam, R; Kala, R",Motion Planning for a Chain of Mobile Robots Using A* and Potential Field,2018,http://dx.doi.org/10.3390/robotics7020020,"Traditionally, motion planning involved navigating one robot from source to goal for accomplishing a task. Now, tasks mostly require movement of a team of robots to the goal site, requiring a chain of robots to reach the desired goal. While numerous efforts are made in the literature for solving the problems of motion planning of a single robot and collective robot navigation in isolation, this paper fuses the two paradigms to let a chain of robot navigate. Further, this paper uses SLAM to first make a static map using a high-end robot, over which the physical low-sensing robots run. Deliberative Planning uses A* algorithm to plan the path. Reactive planning uses the Potential Field Approach to avoid obstacles and stay as close to the initial path planned as possible. These two algorithms are then merged to provide an algorithm that allows the robot to reach its goal via the shortest path possible while avoiding obstacles. The algorithm is further extended to multiple robots so that one robot is followed by the next robot and so on, thus forming a chain. In order to maintain the robots in a chain form, the Elastic Strip model is used. The algorithm proposed successfully executes the above stated when tested on Amigobot robots in an office environment using a map made by the Pioneer LX robot. The proposed algorithm works well for moving a group of robots in a chain in a mapped environment.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2018) is outside 2020–2025.",Ambas,Não,
Web of Science,"Miranda, DSS; de Souza, LE; Bastos, GS",A ROSPlan-based multi-robot navigation system,2018,http://dx.doi.org/10.1109/LARS/SBR/WRE.2018.00053,"Multi-robot systems is a growing research field in robotics and artificial intelligence. Applying multiple robots on single robot systems, generally increase the execution robustness while minimizing its time. Besides this, if the execution requires joint or cooperative actions there isn't better option. This paper proposes a multi-robot version of RosPlan, which that is a framework for embedding a generic task planner in a ROS system. The main contributions include a new method to dispatch the actions; a system to ensure that each robot execute only its actions and a new ROS Package for multi-robot navigation.",TORQUE,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2018) is outside 2020–2025.",Ambas,Não,
Web of Science,"Borst, C; Wimböck, T; Schmidt, F; Fuchs, M; Brunner, B; Zacharias, F; Giordano, PR; Konietschke, R; Sepp, W; Fuchs, S; Rink, C; Albu-Schäffer, A; Hirzinger, G",Rollin' Justin - Mobile Platform with Variable Base,2009,,"Research on humanoid robots for use in servicing tasks, e.g. fetching and delivery, attracts steadily more interest. With Rollin' Justin a mobile robotic system and research platform is presented that allows sophisticated control algorithms and dexterous manipulation. This video gives an overview of the mobile humanoid robotic system Rollin' Justin with special emphasis on mechanical design features, control issues and high-level system capabilities such as human robot interaction.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2009) is outside 2020–2025.",Ambas,Não,
Web of Science,"Yuan, F; Zhang, L; Zhang, HY; Li, DZ; Zhang, TW",Distributed Teleoperation System for Controlling Heterogeneous Robots Based on ROS,2019,http://dx.doi.org/10.1109/arso46408.2019.8948758,"In this paper, we propose a distributed teleoperation system for controlling heterogeneous robots, which improve the problem of the communication of different kinds of robots based on the robot operating system (ROS). The system includes modules for massive data management and multi-level communication, which improves the reuse rate of software code and the flexibility of the robot hardware system by adjusting the overall architecture of the system and decoupling of software and hardware. In our experiments, the distributed control system of the heterogeneous robot was used on the distributed communication and control of the wheeled mobile robot and the humanoid robot, and the remote operation of the heterogeneous robot in the wireless network was successfully realized through the keyboard.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2019) is outside 2020–2025.",Ambas,Não,
Web of Science,"Garcia, I; Gonçalves, F; Ribeiro, T; Fernandes, P; Rocha, C; Boucinha, R; Lopes, G; Ribeiro, AF",Autonomous 4DOF Robotic Manipulator Prototype for Industrial Environment and Human Cooperation,2019,http://dx.doi.org/10.1109/icarsc.2019.8733639,"This paper describes the design and development of an autonomous robotic manipulator with four degrees of freedom. The manipulator is named RACHIE - Robotic Arm for Collaboration with Humans in Industrial Environment. The idea was to create a smaller version of the industrial manipulators available on the market. The mechanical and electronic components are presented as well as the software algorithms implemented on the robot. The manipulator has as its primary goal the detection and organization of cans by color and defects. The robot can detect a human operator so it can deliver defective cans by collaborating with him/her on an industrial environment. To be able to perform such task, the robot has implemented a machine learning algorithm, a Haar feature-based cascade classifier, on its vision system to detect cans and humans. On the handler motion, direct and inverse kinematics were calculated and implemented, and its equations are described in this paper. This robot presents high reliability and robustness in the task assigned. It is low-cost as it is a small version of commercial ones, making it optimized for smaller tasks.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2019) is outside 2020–2025.",Ambas,Não,
Web of Science,"He, ZM; Yuan, F; Chen, DS; Wang, M",Dynamic Obstacle Avoidance Planning for Manipulators of Home,2019,,"With the maturity of robotics and serious aging situation, home service robots have been prevailing around the world, which requires the robotic arm of home service robots to be flexible for obstacle avoidance to work in complex and changing home environment. Based on the actual requirements of home service robots, this paper proposes an obstacle avoidance planning algorithm based on improved artificial potential field method for dynamic obstacle avoidance of redundant manipulators. The velocity of the target object and obstacle were introduced into the end-planned field structure to plan a collision-free path for the end of the arm and track the dynamic target point. Meanwhile, the deviation speed of the arm member in the obstacle repulsive field was added to ensure obstacle avoidance. Finally, the effectiveness of the algorithm was verified in the simulation environment.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC3 potentially met: Abstract mentions simulation without evidence of real-world application or validated prototype.,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2019) is outside 2020–2025.",Ambas,Não,
Web of Science,"Xing, Y; Tan, JTC; Wang, F; Song, HN",Multi-Object Grasp Planning in High Distribution Density of Service Robot using Inverse Reachability Map and Base Repositioning,2019,http://dx.doi.org/10.1109/arso46408.2019.8948718,"For tasks as object grasping, it is important for service robot to know the knowledge about where the service robot base pose should be. The inverse reachability map (IRM) contain the potential base pose for the robot. It can be used for the service robot to generate a suitable base pose for grasping. In this paper we propose an approach for service robot to generate autonomous grasping behavior of unknown objects scattered on the ground. IRM is used to generate the final base pose of the robot when grasping multi-object at a high distribution density. Considering the uncertainties of the service robot navigation, a precise movement is used for service robot to reach the final base pose. This approach uses a pre-defined poses for manipulator to grasping objects and use the motion of the mobile platform to compensate for its inflexibility. The approach is evaluated in the system we modified from Turtlebot, and the experiment with different type objects demonstrate its flexibility and applicability.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2019) is outside 2020–2025.",Ambas,Não,
Web of Science,"Wang, WT; Chen, Y; Diekel, ZM; Jia, YY",Cost Functions based Dynamic Optimization for Robot Action Planning,2018,http://dx.doi.org/10.1145/3173386.3177021,"Human-robot collaboration provides a great solution to the complex hybrid assembly tasks of intelligent manufacturing. In order to augment and guarantee the task quality in the human-robot collaboration process, the collaboration efficiency, including time consumption and human efforts, should be considered in the robot action planning. In this study, we propose a novel and practical approach using cost functions for the robot to plan actions in human-robot collaboration to address this challenge. By this approach, the robot action planning can be dynamically optimized to determine assisted assembly steps in the human-robot co-assembly task. A preliminary experiment is conducted to evaluate the proposed approach. Experimental results suggest that the proposed approach successfully generates the optimal actions for the robot to improve the task efficiency in human-robot collaboration.",PROJECTIVE VIRTUAL-REALITY; CALIBRATION; SYSTEM,Não,Não,Igual,IC5 not satisfied: Could not find a publication year between 2020 and 2025 in the record. ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2018) is outside 2020–2025.",Ambas,Não,
Web of Science,"Fang, HC; Ong, SK; Nee, AYC",Robot Programming using Augmented Reality,2009,http://dx.doi.org/10.1109/CW.2009.14,"Human-robot interaction issues, especially for industrial robots, have largely been confined to finding better ways to reconfigure or program the robots. In this paper, air Augmented Reality based Robot Programming (RPAR-II) system is proposed. A virtual robot, which is a replicate of a real robot, is used in a real environment to perform and simulate the robot trajectory planning process. The RPAR-II system assists the users during the robot programming process from task planning to execution. Stereo vision-based methodologies for virtual objects registration as well as interactive device position tracking are employed in this system. Practical issues concerning the system implementation are discussed.",,Não,Não,Igual,IC5 not satisfied: Could not find a publication year between 2020 and 2025 in the record. ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC5 Not Satisfied: Year (2009) is outside 2020–2025.",Ambas,Não,
Web of Science,"Lin, CJ; Li, MY",Motion planning with obstacle avoidance of an UR3 robot using charge system search,2018,,"For a cyber-physical system (CPS) of a future intelligent factory, a robotic manipulator is requested to co-work with human efficiently and safely in an environment with flexible arrangements. Therefore, an autonomous path planning of robotic manipulator is the most necessary issue to be resolved for the factory automation. For the robotic manipulator, optimizations and artificial intelligence (AI) methods are widely used to investigate the autonomous dynamic path-planning tasks with obstacle avoidance. Among these methods, the Rapidly Exploring Random Tree (RRT) algorithm has been widely used in path planning for a complex environment, because the RRT algorithm has the advantages of perfect expansion, probability completeness, and fast exploring speed. However, for some practical cases, the existing RRT algorithm may obtain a discontinuous solution of the angular trajectory. To solve the above problem, we studied a particle swarm optimization with the charge search system (CSS) to find the optimal path planning with obstacle avoidance. The steps of the proposed method are mentioned as follows: (1) establish the configuration space with the obstacle regions, (2) formulate the motion planning with obstacle using the CSS method and (3) use the PSO method to solve the path planning problem. Finally, the simulation of the path-planning task with obstacle avoidance is visually illustrated using the software RoboDK and the proposed method is implemented by the real-time experiments of the UR3 robot.",FRAMEWORK; MODEL,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2018) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Zabalza, J; Fei, ZX; Wong, CB; Yan, YJ; Mineo, C; Yang, EF; Rodden, T; Mehnen, J; Pham, QC; Ren, JC",Making Industrial Robots Smarter with Adaptive Reasoning and Autonomous Thinking for Real-Time Tasks in Dynamic Environments: A Case Study,2018,http://dx.doi.org/10.1007/978-3-030-00563-4_77,"In order to extend the abilities of current robots in industrial applications towards more autonomous and flexible manufacturing, this work presents an integrated system comprising real-time sensing, path-planning and control of industrial robots to provide them with adaptive reasoning, autonomous thinking and environment interaction under dynamic and challenging conditions. The developed system consists of an intelligent motion planner for a 6 degrees-of-freedom robotic manipulator, which performs pick-and-place tasks according to an optimized path computed in real-time while avoiding a moving obstacle in the workspace. This moving obstacle is tracked by a sensing strategy based on machine vision, working on the HSV space for color detection in order to deal with changing conditions including non-uniform background, lighting reflections and shadows projection. The proposed machine vision is implemented by an off-board scheme with two low-cost cameras, where the second camera is aimed at solving the problem of vision obstruction when the robot invades the field of view of the main sensor. Real-time performance of the overall system has been experimentally tested, using a KUKA KR90 R3100 robot.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2018) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Le, DT; Andulkar, M; Zou, WC; Stidter, JP; Berger, U",Self Adaptive System for Flexible Robot Assembly Operation,2016,,"In this paper a flexible robot system for assembly operations in a semi structured environment is proposed. The system uses a moveable robot equipped with an arbitrarily mounted 3D camera and a 2D camera on the robot gripper for accurate object detection. The system is developed based on the Robot Operating System (ROS) and uses the state of the art trajectory planner Movelt for collision free robot motion planning. The object recognition for the system is performed using a combination of the two camera's and robot end effector and the deviation of objects in the robot workspace is found to be in the range of 2.2 mm along X and Y axes. Furthermore, an implementation procedure of the proposed system for assembly task is explained.",NONLINEAR TRACKING CONTROL; MANIPULATORS,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2016) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Liu, YC; Chopra, N",Semi-Autonomous Teleoperation in Task Space with Redundant Slave Robot under Communication Delays,2011,,"Bilateral teleoperation systems have been extensively utilized for implementing tasks in remote or hazardous environments. However, due to the cognitive limitations of the human operator, efficient teleoperation of complex robotic system operating in cluttered environments has been difficult to achieve. In this paper, we study the control problem of a semi-autonomous teleoperation system, where the redundant slave robot can autonomously satisfy several constraints while tracking the position of the master robot in the task space. Considering heterogeneous master and slave robots, we first develop a control algorithm to ensure task space position and velocity tracking between the master and slave robots in the presence of dynamic uncertainties and communication delays. The redundancy of the slave robot is then utilized for achieving sub-task control, such as singularity avoidance, joint limits, and collision avoidance. The control algorithms for the proposed semi-autonomous teleoperation system are validated using numerical simulations on a non-redundant master and a redundant slave robot.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2011) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Suzuki, T; Sekine, T; Fujii, T; Asama, H; Endo, I",Cooperative formation among multiple mobile robot teleoperation in inspection task,2000,,The paper discusses multi-robot teleoperation system considering cooperation between human operator and multiple robots in inspection task. A prototype of the teleoperation system is developed and implemented on an actual testing platform that consists of multiple onmi-directional mobile robots. Cooperative formations among multiple mobile robots are proposed. Performance of the developed system is examined through the experimental example of an inspection task.,MOBILE ROBOT,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2000) is outside 2020–2025.,Ambas,Não,
Web of Science,"Ishida, S; Ogiya, H; Matsuhira, N",Development of a selectable teleoperated robot system using RSNP,2014,,"A teleoperated robot system communicating through a robot service network protocol (RSNP) has been developed. In this system, robots and operation devices are freely selected among registered robots and operation devices, respectively. Robots can be interchanged to suit the target task. Thus, we aim to build a suitable teleoperated robot system for specified tasks. Here, we introduce the developed system and the results of basic robot surfing experiments. We also discuss a common GUI for multiple robot systems.",ROBOT; TRACKING,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2014) is outside 2020–2025.",Ambas,Não,
Web of Science,"Kim, K; Cha, YS; Park, JM; Lee, JY; You, BJ",Providing Services Using Network-Based Humanoids in a Home Environment,2011,http://dx.doi.org/10.1109/TCE.2011.6131135,"This paper describes the development of network-based humanoids to provide services in the home environment. For successful service in more intelligent and varied environments, various robot sub-systems need to be coordinated effectively. Thus, this paper also introduces a coordinated framework which makes robot-human interaction while executing various tasks by means of various robots. Using a task script, an operator can easily describe tasks and regulate actions of the sub-systems while a robot is performing the task. Furthermore, the control system of a robot must operate efficiently to ensure a coordinated robot system, so the realization of an IEEE-1394 real-time distributed control system and a motor controller for a humanoid robot are introduced. Many algorithms have been developed, and the following technologies are described herein: autonomous biped walking; real-time modification of collision-free paths; and interaction ability with humans and environments, such as face, voice, or object recognition. The results of the demonstration show that humanoids can execute tasks efficiently and are suitable to provide services in human environments, such as restaurants or homes.(1).",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2011) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Yang, Y; Chen, HY; Lou, YJ; Lin, W",Remote Master-Slave Control of A 6D Manipulator for Cardiac Surgery Application,2014,,"Intelligent robots have been using widely in medical field for the high precision, long working period, and lower costs. The integration of teleoperation system into surgical robots makes the remote surgery possible. This paper focuses on the force feedback and intelligent motion planning that enables master-slave control of heterogeneous manipulators. The slave arm works in a different scene from the master manipulator, which means that the arm assembled surgical instruments can't repeat master manipulator motion mechanical. To address the heterogeneous problem, the collision free trajectory is generated based on both manipulators' kinematic model and sample-based path planner. To improve the safety of surgical robots, virtual feedback-force is produced according to the distance between surgical instrument and the edge of surgical safe workspace.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2D014) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Sugar, T; Kumar, V",Control and coordination of multiple mobile robots in manipulation and material handling tasks,2000,,"We describe a framework and control algorithms for coordinating multiple mobile robots with manipulators focusing on tasks that require grasping, manipulation, and transporting large and possibly flexible objects without special purpose fixtures. Because each robot has an independent controller and is autonomous, the coordination and synergy are realized through sensing and communication The robots can cooperatively transport objects and march in a tightly controlled formation, while also having the capability to navigate autonomously. We describe the key aspects of the overall hierarchy and the basic algorithms, with specific applications to our experimental testbed consisting of three robots.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2000) is outside 2020–2025.",Ambas,Não,
Web of Science,"Abou Moughlbay, A; Cervera, E; Martinet, P",Real-Time Model Based Visual Servoing Tasks on a Humanoid Robot,2013,,"Several model based techniques have been used to apply various domestic service tasks on humanoid robots (through teleoperation, learning, ... ). But for many reasons, it is more suitable to study the interaction between the robot and its environment using the Sensor Based Control in these cases. In this paper we present a work of integration of real-time visual servoing techniques in performing self localization and different manipulation tasks on a humanoid robot in closed loop. Real-time model based tracking techniques are used to apply 3D visual servoing tasks on the Nao humanoid robot. Elementary tasks used by the robot to perform a concrete scenario are detailed with their corresponding control laws. Experimental results are presented for the following tasks: self-localization of the robot while walking, head servoing for the visibility task, detection, tracking and manipulation of environment's objects.",COORDINATION; ROBOTS; FUSION,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC2 met: Article focuses on excluded sectors (military/space/domestic/entertainment).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2013) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Cai, YF; Yang, SX",A Survey on Multi-robot Systems,2012,,"This paper reviews the state-of-the-art research on multi-robot systems, with a focus on multi-robot cooperation and coordination. By primarily classifying multi-robot systems into active and passive cooperative systems, three main research topics of multi-robot systems are focused on: task allocation, multi-sensor fusion and localization. In addition, formation control and coordination methods for multi-robots are reviewed.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2012) is outside 2020–2025. EC4 Met: Abstract identifies the paper as a review, survey, thesis, or book chapter.",Ambas,Não,
Web of Science,"Cheng, HT; Chen, HP; Liu, Y; Sheng, WH",Human-Like Indoor Navigation for Autonomous Industrial Mobile Manipulator,2012,,"Autonomous Industrial Mobile Manipulator (AIMM) that combines the advantages of both mobile robot and industrial manipulators and owns great mobility, flexibility and functionality will be the next generation of robots used in industrial automation. Compared to the tractional industrial robots, it is capable of performing various tasks in unstructured or semi-structured environments, thus brings great challenges in autonomous localization & navigation, object identification, control and coordination. In this paper, a novel human-like indoor navigation problem is studied. Instead of predefining a feature map or building a 3D point cloud map, a human-like topological description and realtime corridor identification are utilized. As a fundamental problem, corridor classification stands for a key role in the whole system. A cascade Bayesian classifier is designed to make full use of multi-observations and gets much better confidence and more stable results. The classifier is consisted of a weak incomplete feature extractor and a strong bayesian classifier. Features are extracted from depth maps provided by a Microsoft Kinect sensor. With several observations, the Bayesian classifier fuses all the features and forms the final results. Experiments are performed on a recently built AIMM system, and the results validate the effectiveness of the proposed methodology.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2012) is outside 2020–2025.",Ambas,Não,
Web of Science,"Jia, YY; Liu, Y; Xi, N; Wang, H; Stürmer, P",Design of Robotic Human Assistance Systems Using a Mobile Manipulator,2012,http://dx.doi.org/10.5772/50828,"Robotic systems have been widely used in many areas to assist human beings. Mobile manipulators are among the most popular choices. This paper investigates human assistance systems using a mobile manipulator, for example, to guide the blind and to transport objects. Distinct from existing systems, an integrated dynamic model and controller of the mobile manipulator are designed. Singularity, manipulability and safety are all considered in the system design. Furthermore, two human assistance modes - Robot-Human mode and Teleoperator-Robot-Human mode - are designed and analysed. The Teleoperator-Robot-Human mode can integrate human intelligence into the assistance system to further enhance the system efficiency and safety. The experimental results implemented on a mobile manipulator demonstrated the effectiveness of the designed systems.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2012) is outside 2020–2025.",Ambas,Não,
Web of Science,"Girbacia, F; Duguleana, M; Stavar, A",Off-Line Programming of Industrial Robots Using Co-Located Environments,2012,http://dx.doi.org/10.4028/www.scientific.net/AMR.463-464.1654,"This paper presents a methodology and a prototype system for off-line programming of an industrial robot using augmented reality technology. The system allows to control a virtual model of the industrial robot co-located in the real environment, planning for collision-free paths, generate robot program and simulate the robot actions before the real robot perform the task. The advantage of this system is use of inexpensive equipment for intuitive off-line programming of an industrial robot.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC1 met: Appears focused on single-task / traditional industrial robot tasks (welding/painting/assembly/etc.).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2012) is outside 2020–2025.",Ambas,Não,
Web of Science,"Wang, T; Ramik, DM; Sabourin, C; Madani, K",MACHINE LEARNING FOR HETEROGENEOUS MULTI-ROBOTS SYSTEMS IN LOGISTIC APPLICATION FRAME,2012,,"In this paper, we propose machine learning for heterogeneous multi-robots systems in the logistic application frame. The team's robot is composed by a humanoid robot and three wheeled robots. The goal of the humanoid robot is to lead the wheeled robots according to environment (e.g. obstacle, narrow path, etc..). The aim of the wheeled robots, which move in rigid formation, is to act together in order to carry a cumbersome load. Machine learning allows to give automatically path planning.",SERVICE ROBOT; SOFTWARE,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2012) is outside 2020–2025.",Ambas,Não,
Web of Science,"Mae, Y; Takahashi, H; Ohara, K; Takubo, T; Arai, T",Component-based robot system design for grasping tasks,2011,http://dx.doi.org/10.1007/s11370-010-0072-5,"The paper presents a robot system design with highly reusable components for a component-based robot system for manipulation tasks. The robot system is designed based on the analysis of manipulation tasks using a unified modeling language use case diagram. For a service robot with locomotion and manipulation mechanisms, reusability of robot system components is improved by adopting the proposed design. Our structure consists of scenario, task, robot information management server, data analyzer, sensor hardware controller, skill, and motion hardware controller on a component-based robot system. Based on the proposed robot system, we implemented a component-based robot system and subsequently realized a grasping motion by a service robot.",LOCALIZATION; IMAGES,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2011) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Jafar, FA; Suzuki, Y; Tateno, Y; Yokota, K; Matsuoka, T",AN ENVIRONMENTAL VISUAL FEATURES BASED NAVIGATION METHOD FOR AUTONOMOUS MOBILE ROBOTS,2011,,"Navigation and localization are two important issues which need to be addressed in order to let robots work in the human living environment. We believe that it is not always necessary to build a robot system with a precise and accurate navigation in some situations. For example, those cases where a robot is programmed for guiding way in a building environment or fulfilling a delivery task. With this regard, we propose a navigation method for the autonomous mobile robot where the robot will identify its own position and orientation robustly based on visual features in the environment without any complicated techniques. In our method, the robot takes advantage of the localization process to navigate from a point to a given destination without losing the correct path.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2011) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Kim, D; Kang, JH; Hwang, CS; Park, GT",Mobile robot for door opening in a house,2004,,"A new field of robot applications is emerging. Owing to the relevancy of the robot,people's convenience can be enhanced. In this paper, we study on the task of opening a closed door by the home service robot which is mobile robot equipped with a manipulator. The objective of this research is to successfully accomplish door opening task using the home service robot. In addition, the robot has some advantages as the home service robot for the general use. The proposed robot is small and compact because double active universal joint is adopted for the robotics joint mechanism of the manipulator so it easy to move in a house through doorways. Moreover, cheap force sensors are employed for the information of door opening task instead of expensive JR3 sensor so we can expect cost effectiveness in the robot. Practical experiment has shown that the door opening task can be completed successfully by the proposed home service robot which is small, compact, inexpensive but efficient.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2004) is outside 2020–2025.",Ambas,Não,
Web of Science,"Baca, J; Ferre, M; Collar, M; Fernandez, J; Aracil, R",Synchronizing a Modular Robot Colony for Cooperative Tasks Based on Intra-Inter Robot Communications,2010,http://dx.doi.org/10.1109/CERMA.2010.111,"The implementation of robotic cooperative tasks such as pushing an object toward a desired destination or manipulating an object using mobile robots or robotic arms requires motion coordination between the robot colony. When a robot is built by the union of several robots, such as modular robot systems, it is critical to have the complete coordination of each robot configuration within the colony and also overall robot coordination of the colony. The paper presents a demonstration of parallel motion for modular robot configurations through the combination of two types of communications, i.e., Inter-robot and Intra-robot communications. The two types of communications are described and implemented in a real modular robot system. Experiments are executed to show the performance of the robot colony synchronization.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2010) is outside 2020–2025.",Ambas,Não,
Web of Science,"Kim, YH; Kim, BK",A Multi-Robot Task Planning System Minimizing the Total Execution Time for Hospital Service,2010,,"A multi-robot task planning system is developed to minimize the total execution time for autonomous service robots in hospitals, which is essential for 'autonomous generation of task commands' as an approach toward human-friendly human-robot interaction. In traditional approaches, a task planning system based on STRIPS (Stanford Research Institute Problem Solver) representation is widely used. Also the temporal planning is one of the issues in task planning area, since it still suffers some problems for single robots, and also it is not easy to apply to multi-robot environment yet. For our objective, we propose a new representation, named variable representation, based on STRIPS representation for specifying states and actions. Then we apply the A* algorithm for iterative search and extend for multi-robot task planning system. In order to guarantee safety, the multi-robot task planning system needs to check robots' collisions and should avoid robots' collisions. We propose collision check and avoidance algorithm, and integrate to the multi-robot task planning system.",,Não,Não,Igual,"IC2 not satisfied: No clear mention of practical application, measured impact, HRI analysis, enabling technologies, or implementation challenges in title/abstract.","IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2010) is outside 2020–2025.",Ambas,Não,
Web of Science,"Nagatani, K; Yuta, S",Designing a behavior of a mobile robot equipped with a manipulator to open and pass through a door,1996,http://dx.doi.org/10.1016/0921-8890(95)00061-5,"One approach of how to pass through a doorway by a mobile robot is discussed. In this task-oriented approach, proposed task is to realize a total behavior with opening a door and passing through a doorway by a mobile robot equipped with a manipulator. In this paper, we describe a design of such behavior by a robot, and show a simulation of robot motion series for this task. The key issue for realizing such behavior is cooperation between robot's function sub-systems, such as the locomotion control system, the manipulator control system and the sensor systems.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC3 potentially met: Abstract mentions simulation without evidence of real-world application or validated prototype.,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (1996) is outside 2020–2025.",Ambas,Não,
Web of Science,"Seo, DJ; Ko, NY; Simmons, RG",An elastic force based collision avoidance method and its application to motion coordination of multiple robots,2009,http://dx.doi.org/10.1080/09511920902741083,"A key contribution of robots to a manufacturing system is flexibility and automation. The robots can handle part batches of varying size and mix and can adapt to process variations and uncertainties in the working environment. This paper proposes a method for the collision-free motion coordination of multiple robots in a common working environment. The method uses an improved elastic force based method for collision avoidance. For the motion coordination of multiple robots, prioritisation-and-avoidance is used. Priority is assigned to each robot with a robot of lower priority avoiding the robots of higher priority. Without priority, every robot takes pains to avoid all the other robots. This degrades the overall performance of the coordinated motion. In addition, priority allows a robot with an urgent job to perform its job quicker. For collision avoidance, elastic force as well as potential field force is used. Compared with the method using only the potential field force, the robot can keep its configuration while avoiding other robots. Moreover, by adjusting the elastic force, task-consistent motion is possible. This method is tested by simulation and results in a smooth and adaptive coordination in an environment with different types of robots. Also the proposed method is compared with a method using the conventional elastic strip based method. The method can be used to coordinate the motion of multiple robots in a common working environment of a CIM system without interference.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC3 potentially met: Abstract mentions simulation without evidence of real-world application or validated prototype.,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2009) is outside 2020–2025.",Ambas,Não,
Web of Science,"Yamazaki, K; Tomono, M; Tsubouchi, T",Picking up an unknown object through autonomous modeling and grasp planning by a mobile manipulator,2008,,"This paper describes a novel framework for object picking and carrying task by a mobile manipulator. Conventionally, researches on mobile manipulator cope well with object manipulation task with utilizing predefined knowledge or specific tools. So these researches have an essential problem that a new target object cannot be added without relatively many preparation. On the other hand, in our framework of a robot system, because the robot can create the 3D shape model of the object and can plan a grasp pose for the object autonomously under the condition that only the position of the object is given to the robot. Experimental results show the effectiveness of our robot system to be implemented our proposed method.",OBSTACLE AVOIDANCE,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2008) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Ko, N; Seo, D; Simmons, R",Collision-free motion coordination of heterogeneous robots,2008,http://dx.doi.org/10.1007/s12206-008-0718-9,"This paper proposes a method to coordinate the motion of multiple heterogeneous robots on a network. The proposed method uses prioritization and avoidance. Priority is assigned to each robot; a robot with lower priority avoids the robots of higher priority. To avoid collision with other robots, elastic force and potential field force are used. Also, the method can be applied separately to the motion planning of a part of a robot from that of the other parts of the robot. This is useful for application to the robots of the type mobile manipulator or highly redundant robots. The method is tested by simulation, and it results in smooth and adaptive coordination in an environment with multiple heterogeneous robots.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC3 potentially met: Abstract mentions simulation without evidence of real-world application or validated prototype.,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC5 Not Satisfied: Year (2008) is outside 2020–2025.",Ambas,Não,
Web of Science,"Hirukawa, H",Walking biped humanoids that perform manual labour,2007,http://dx.doi.org/10.1098/rsta.2006.1916,"The Humanoid Robotics Project of the Ministry of Economy, Trade and Industry of Japan realized that biped humanoid robots can perform manual labour. The project developed humanoid robot platforms, consisting of humanoid robot hardware and a package of fundamental software, and explored applications of humanoid robots on them. The applications include maintenance tasks of industrial plants, teleoperation of industrial vehicles, cooperative tasks with a human, guarding the home and office and the care of patients in beds.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,"IC1 Not Satisfied: Does not clearly focus on target sectors (Logistics, Healthcare, Field Services). IC1 Not Satisfied: Does not clearly focus on multifunctional or collaborative (cobot/HRI) robots. IC2 Not Satisfied: Abstract lacks focus on practical applications, impacts, HRI analysis, or implementation challenges. IC5 Not Satisfied: Year (2008) is outside 2020–2025. EC2 Met: Focus appears to be on excluded sectors (military, space, domestic, entertainment).",Ambas,Não,
Web of Science,"Cai, CT; Yang, CS; Zhu, QD; Liang, YH",A fuzzy-based collision avoidance approach for multi-robot systems,2007,http://dx.doi.org/10.1109/ROBIO.2007.4522302,"Multi-robot systems have been widely applied to various applications to perform a given task collaboratively and cooperatively. In a multi-robot environment, path-planning or collision avoidance is an imperative problem. For tackling this challenging problem, we mainly deal with the collision avoidance problem between robots and robots as well as between robots and obstacles in multi-robot systems. In this paper, the fuzzy reasoning based on a Step-Forward motion strategy is applied in making decision on motion of robots. The model of autonomous robot, the method of detecting dynamic speed of robot and the risk degree surrounding with a robot are discussed. The simulation results show that the fuzzy-based control strategies are effective and useful for making decisions on collision avoidance in multi-robot systems.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services). ; EC3 potentially met: Abstract mentions simulation without evidence of real-world application or validated prototype.,IC5 não satisfeito: O ano de publicação (2007) está fora do período de 2020–2025.,Ambas,Não,
Web of Science,"Shan, WL; Nagatani, K; Tanaka, Y",Motion planning for mobile manipulator to pick up an object while base robot's moving,2004,,"Our research goal is to realize a motion planning for an intelligent mobile manipulator to pick up an object while the mobile base is moving. This motion is very easy for human. However it includes many technical challenges for robotic research. In this research, we propose a motion planning method for a mobile manipulator with considering the manipulator's manipulability. In this paper, we describe our motion planning algorithm and introduce a performance of planned motion using three dimensional motion simulator and our actual mobile manipulator.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,IC5 não satisfeito: O ano de publicação (2004) está fora do período de 2020–2025.,Ambas,Não,
Web of Science,"Lee, JM; Park, BS; Lee, YS; Ahn, JS; Lee, SH; Lim, SJ; Han, CS",The development of the robot manipulator for an intelligent service robot,2006,,"The Manipulator, much higher intelligence and technology for realizing environment are required to carry objects in case the intelligent service robot assists or substitutes human works. The manipulator of them executes works gripping or carrying object at any position in various environments. The manipulator of household service robot should be able to accomplish the task carrying small thing, a glass and stationery. And human-friendly design reducing a possibility of danger is required to execute orders and reduce an unpleasant feeling. Therefore, the robot manipulator making use of human-friendly design and implementing human's arm motions is presented in this paper. And the design process for each joint of the manipulator is introduced. Also the manipulator executes tasks carrying object at any position, which is verified in this paper.",,Não,Não,Igual,IC1 not fully satisfied: Title/abstract do not clearly indicate multifunctional robots or collaborative robots in the target sectors (logistics/healthcare/field services).,IC5 não satisfeito: O ano de publicação (2006) está fora do período de 2020–2025.,Ambas,Não,